# Your First Project

In this guide, you'll create your first project with ABI-Core step by step. By the end, you'll have a working agent you can query.

## What You'll Build

A simple project with:
- ‚úÖ An AI agent
- ‚úÖ Language model (qwen2.5:3b)
- ‚úÖ Interface for queries

**Estimated time**: 10 minutes

## Step 1: Create the Project

Open your terminal and run:

```bash
abi-core create project my-first-project
```

**What does this command do?**
- Creates directory structure
- Configures Docker
- Prepares environment

**Expected output**:
```
üöÄ Creating ABI project: my-first-project
‚úÖ Project structure created
‚úÖ Docker configuration created
‚úÖ Runtime configuration created

üìÅ Project created at: ./my-first-project

Next steps:
  cd my-first-project
  abi-core provision-models
```

## Step 2: Navigate to Project

```bash
cd my-first-project
```

**Created structure**:
```
my-first-project/
‚îú‚îÄ‚îÄ agents/              # Your agents will go here
‚îú‚îÄ‚îÄ services/            # Support services
‚îú‚îÄ‚îÄ compose.yaml         # Docker configuration
‚îú‚îÄ‚îÄ .abi/
‚îÇ   ‚îî‚îÄ‚îÄ runtime.yaml     # Project configuration
‚îî‚îÄ‚îÄ README.md
```

## Step 3: Provision Models

This step downloads the AI model your agent will use:

```bash
abi-core provision-models
```

**What does this command do?**
1. Starts Ollama service
2. Downloads `qwen2.5:3b` (~2GB)
3. Downloads embedding model
4. Updates configuration

**Expected output**:
```
üöÄ Starting model provisioning...
üì¶ Model serving mode: centralized
üîÑ Starting Ollama service...
‚úÖ Ollama service started

üì• Downloading qwen2.5:3b...
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
‚úÖ qwen2.5:3b downloaded successfully

üì• Downloading nomic-embed-text:v1.5...
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
‚úÖ nomic-embed-text:v1.5 downloaded successfully

‚úÖ Models provisioned successfully
```

**Note**: First time takes several minutes depending on your connection.

## Step 4: Create Your First Agent

Now create an agent:

```bash
abi-core add agent assistant --description "My first AI agent"
```

**What does this command do?**
- Creates agent code
- Configures Dockerfile
- Registers agent in project

**Expected output**:
```
‚úÖ Agent 'assistant' added successfully!
üìÅ Location: agents/assistant
üöÄ Port: 8000
üì¶ Docker service added to compose file
```

**Files created**:
```
agents/assistant/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ agent_assistant.py    # Agent code
‚îú‚îÄ‚îÄ main.py               # Entry point
‚îú‚îÄ‚îÄ models.py             # Data models
‚îú‚îÄ‚îÄ Dockerfile            # Docker configuration
‚îî‚îÄ‚îÄ requirements.txt      # Dependencies
```

## Step 5: Start the System

Start all services:

```bash
abi-core run
```

Or with Docker Compose directly:

```bash
docker-compose up -d
```

**What starts?**
- Ollama service (AI models)
- Your assistant agent

**Verify it's running**:
```bash
docker-compose ps
```

You should see:
```
NAME                          STATUS    PORTS
my-first-project-ollama       Up        0.0.0.0:11434->11434/tcp
assistant-agent               Up        0.0.0.0:8000->8000/tcp
```

## Step 6: Test Your Agent

### Option 1: With curl

```bash
curl -X POST http://localhost:8000/stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Hello, how are you?",
    "context_id": "test-001",
    "task_id": "task-001"
  }'
```

**Expected response**:
```json
{
  "content": "Hello! I'm doing well, thank you for asking. I'm your AI assistant. How can I help you today?",
  "response_type": "text",
  "is_task_completed": true
}
```

### Option 2: With Python

Create a file `test_agent.py`:

```python
import requests

response = requests.post(
    "http://localhost:8000/stream",
    json={
        "query": "What is artificial intelligence?",
        "context_id": "test-001",
        "task_id": "task-001"
    }
)

print(response.json())
```

Run:
```bash
python test_agent.py
```

### Option 3: Browser

Open your browser and go to:
```
http://localhost:8000/docs
```

You'll see the Swagger interface where you can test the agent interactively.

## Step 7: View Logs

To see what your agent is doing:

```bash
# View logs of all services
docker-compose logs -f

# View only agent logs
docker-compose logs -f assistant-agent

# View only Ollama logs
docker-compose logs -f my-first-project-ollama
```

## Step 8: Stop the System

When you're done:

```bash
# Stop services
docker-compose down

# Stop and remove volumes (models)
docker-compose down -v
```

## Next Steps

Congratulations! You have your first project running. Now you can:

1. [Create a more complex chatbot](../single-agent/02-simple-chatbot.md)
2. [Add tools to your agent](../single-agent/03-agents-with-tools.md)
3. [Add conversational memory](../single-agent/04-agents-with-memory.md)

---

**Created by [Jos√© Luis Mart√≠nez](https://github.com/Joselo-zn)** | jl.mrtz@gmail.com
