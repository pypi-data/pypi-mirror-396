{
  "id": "7cbcec68-7fa6-47bb-a38a-da689949a001",
  "revision": 0,
  "last_node_id": 191,
  "last_link_id": 298,
  "nodes": [
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [-400, 390],
      "size": [337.76861572265625, 58],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [61, 223]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": ["ae.safetensors"]
    },
    {
      "id": 38,
      "type": "DualCLIPLoader",
      "pos": [-400, 210],
      "size": [337.76861572265625, 130],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [59]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "DualCLIPLoader",
        "models": [
          {
            "name": "clip_l.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
            "directory": "text_encoders"
          },
          {
            "name": "t5xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp8_e4m3fn_scaled.safetensors",
        "flux",
        "default"
      ]
    },
    {
      "id": 135,
      "type": "ConditioningZeroOut",
      "pos": [250, 200],
      "size": [240, 26],
      "flags": {
        "collapsed": false
      },
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 237
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [238]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "ConditioningZeroOut"
      },
      "widgets_values": []
    },
    {
      "id": 173,
      "type": "PreviewImage",
      "pos": [320, 860],
      "size": [420, 310],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 289
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 136,
      "type": "SaveImage",
      "pos": [760, 510],
      "size": [650, 660],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 240
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": ["ComfyUI"]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [530, 350],
      "size": [190, 46],
      "flags": {
        "collapsed": false
      },
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 52
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 61
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [240]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 124,
      "type": "VAEEncode",
      "pos": [-20, 400],
      "size": [240, 50],
      "flags": {
        "collapsed": false
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 222
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 223
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [291, 293]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 42,
      "type": "FluxKontextImageScale",
      "pos": [-50, 570],
      "size": [270, 30],
      "flags": {
        "collapsed": false
      },
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 251
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [222, 289]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxKontextImageScale"
      },
      "widgets_values": []
    },
    {
      "id": 146,
      "type": "ImageStitch",
      "pos": [-390, 570],
      "size": [270, 150],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "image1",
          "type": "IMAGE",
          "link": 297
        },
        {
          "name": "image2",
          "shape": 7,
          "type": "IMAGE",
          "link": 298
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [251]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "ImageStitch"
      },
      "widgets_values": ["right", true, 0, "white"]
    },
    {
      "id": 35,
      "type": "FluxGuidance",
      "pos": [250, 90],
      "size": [240, 58],
      "flags": {
        "collapsed": false
      },
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 292
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [57]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxGuidance"
      },
      "widgets_values": [2.5]
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [-400, 80],
      "size": [337.76861572265625, 82],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [58]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "flux1-dev-kontext_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": ["flux1-dev-kontext_fp8_scaled.safetensors", "default"]
    },
    {
      "id": 177,
      "type": "ReferenceLatent",
      "pos": [10, 140],
      "size": [197.712890625, 46],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 294
        },
        {
          "name": "latent",
          "shape": 7,
          "type": "LATENT",
          "link": 293
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [292]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "ReferenceLatent"
      },
      "widgets_values": []
    },
    {
      "id": 188,
      "type": "EmptySD3LatentImage",
      "pos": [530, -140],
      "size": [310, 106],
      "flags": {},
      "order": 3,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [1024, 1024, 1]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [330, 560],
      "size": [400, 220],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 59
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [237, 294]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Using this elegant style, create a portrait of a swan wearing a pearl tiara and lace collar, maintaining the same refined quality and soft color tones."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 31,
      "type": "KSampler",
      "pos": [530, 40],
      "size": [320, 262],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 58
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 57
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 238
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 291
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [52]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        784381637916598,
        "randomize",
        20,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 175,
      "type": "MarkdownNote",
      "pos": [-50, 640],
      "size": [320, 88],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "How to enable multiple image input",
      "properties": {},
      "widgets_values": [
        "Click on the purple (bypassed) **Load image** node and use **Ctrl + B** to enable multiple image input support."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 184,
      "type": "MarkdownNote",
      "pos": [-960, 40],
      "size": [510, 400],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {},
      "widgets_values": [
        "[tutorial](http://docs.comfy.org/tutorials/flux/flux-1-kontext-dev)\n\n**diffusion model**\n\n- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)\n\n**text encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â””â”€â”€ flux1-dev-kontext_fp8_scaled.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ ae.safetensor\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â”œâ”€â”€ clip_l.safetensors\nâ”‚       â””â”€â”€ t5xxl_fp16.safetensors æˆ–è€… t5xxl_fp8_e4m3fn_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 178,
      "type": "MarkdownNote",
      "pos": [-30, -150],
      "size": [540, 150],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About multiple images reference",
      "properties": {},
      "widgets_values": [
        "[English] In addition to using **Image Stitch** to combine two images at a time, you can also encode individual images, then concatenate multiple latent conditions using the **ReferenceLatent** node, thus achieving the purpose of referencing multiple images. You can use the **EmptySD3LatentImage** node on the right to connect to **KSamper** and customize the size of the **latent_image**."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 190,
      "type": "LoadImage",
      "pos": [-380, 800],
      "size": [280, 330],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [297]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["flux_kontext_dev_basic_input_image.jpg", "image"]
    },
    {
      "id": 191,
      "type": "LoadImage",
      "pos": [-40, 800],
      "size": [280, 330],
      "flags": {},
      "order": 9,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [298]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.64",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["flux_kontext_dev_basic_input_image.jpg", "image"]
    },
    {
      "id": 186,
      "type": "MarkdownNote",
      "pos": [-960, 500],
      "size": [510, 670],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext Prompt Techniques",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext Prompt Techniques\n\n### 1. Basic Modifications\n- Simple and direct: `\"Change the car color to red\"`\n- Maintain style: `\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. Style Transfer\n**Principles:**\n- Clearly name style: `\"Transform to Bauhaus art style\"`\n- Describe characteristics: `\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- Preserve composition: `\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. Character Consistency\n**Framework:**\n- Specific description: `\"The woman with short black hair\"` instead of \"she\"\n- Preserve features: `\"while maintaining the same facial features, hairstyle, and expression\"`\n- Step-by-step modifications: Change background first, then actions\n\n### 4. Text Editing\n- Use quotes: `\"Replace 'joy' with 'BFL'\"`\n- Maintain format: `\"Replace text while maintaining the same font style\"`\n\n## Common Problem Solutions\n\n### Character Changes Too Much\nâŒ Wrong: `\"Transform the person into a Viking\"`\nâœ… Correct: `\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### Composition Position Changes\nâŒ Wrong: `\"Put him on a beach\"`\nâœ… Correct: `\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### Style Application Inaccuracy\nâŒ Wrong: `\"Make it a sketch\"`\nâœ… Correct: `\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## Core Principles\n\n1. **Be Specific and Clear** - Use precise descriptions, avoid vague terms\n2. **Step-by-step Editing** - Break complex modifications into multiple simple steps\n3. **Explicit Preservation** - State what should remain unchanged\n4. **Verb Selection** - Use \"change\", \"replace\" rather than \"transform\"\n\n## Best Practice Templates\n\n**Object Modification:**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**Style Transfer:**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**Background Replacement:**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**Text Editing:**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **Remember:** The more specific, the better. Kontext excels at understanding detailed instructions and maintaining consistency. "
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [52, 31, 0, 8, 0, "LATENT"],
    [57, 35, 0, 31, 1, "CONDITIONING"],
    [58, 37, 0, 31, 0, "MODEL"],
    [59, 38, 0, 6, 0, "CLIP"],
    [61, 39, 0, 8, 1, "VAE"],
    [222, 42, 0, 124, 0, "IMAGE"],
    [223, 39, 0, 124, 1, "VAE"],
    [237, 6, 0, 135, 0, "CONDITIONING"],
    [238, 135, 0, 31, 2, "CONDITIONING"],
    [240, 8, 0, 136, 0, "IMAGE"],
    [251, 146, 0, 42, 0, "IMAGE"],
    [289, 42, 0, 173, 0, "IMAGE"],
    [291, 124, 0, 31, 3, "LATENT"],
    [292, 177, 0, 35, 0, "CONDITIONING"],
    [293, 124, 0, 177, 1, "LATENT"],
    [294, 6, 0, 177, 0, "CONDITIONING"],
    [297, 190, 0, 146, 0, "IMAGE"],
    [298, 191, 0, 146, 1, "IMAGE"]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1- Load models",
      "bounding": [-410, 10, 360, 450],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 2 - Upload images",
      "bounding": [-410, 480, 700, 680],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 5,
      "title": "Step 3 - Prompt",
      "bounding": [310, 480, 430, 330],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 6,
      "title": "Conditioning",
      "bounding": [-30, 10, 540, 250],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.5909232551952691,
      "offset": [1279.4241547910187, 33.095262680409]
    },
    "frontendVersion": "1.28.7",
    "groupNodes": {},
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}

