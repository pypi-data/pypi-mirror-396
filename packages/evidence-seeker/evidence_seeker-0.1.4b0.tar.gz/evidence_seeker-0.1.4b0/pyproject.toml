[build-system]
requires = ["hatchling>=1.13.0"]
build-backend = "hatchling.build"

[project]
name = "evidence-seeker"
dynamic = ["version"]
description = 'EvidenceSeeker Boilerplate'
# >=3.11: Using typing.SELF
requires-python = ">=3.12"
license = "MIT"
keywords = []
authors = [
  { name = "Gregor Betz", email = "3662782+ggbetz@users.noreply.github.com" },
  { name = "Sebastian Cacean"},
  { name = "Leonie Wahl"}
]
classifiers = [
  "Development Status :: 4 - Beta",
  "Programming Language :: Python",
  #"Programming Language :: Python :: 3.8",
  #"Programming Language :: Python :: 3.9",
  #"Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: Implementation :: CPython",
  "Programming Language :: Python :: Implementation :: PyPy",
]
dependencies = [
  "python-dotenv",
  "loguru",
  # we use the newer workflow-context storage methods  
  # see: https://github.com/run-llama/workflows-py/releases/tag/v2.0.0
  "llama-index-workflows>=2.0.0",
  # Use llama-index-core with specific component packages
  # Note: llama-index-core provides the namespace package structure
  "llama-index-core>=0.14.0",
  "llama-index-llms-openai",
  "llama-index-llms-openai-like",
  # Note: text-embeddings-inference has compatibility issues with
  # llama-index-utils-huggingface, so we explicitly manage both
  "llama-index-embeddings-text-embeddings-inference>=0.4.0",
  "llama-index-utils-huggingface>=0.4.0",
  "llama-index-embeddings-huggingface",
  "llama-index-embeddings-ollama",
  "llama-index-readers-file",
  "huggingface_hub",
  "numpy",
  "pydantic",
  "wrapt",
  "httpx",
  "jinja2",
  "pygithub",
  "gradio",
  "argon2-cffi",
  "llama-index-vector-stores-postgres",
]

[project.readme]
text = """
A code template for an RAG-based LLM workflow for disambiguating claims and fact-checking them relative to a given database. 

For details, see the <https://github.com/debatelab/evidence-seeker>.
"""
content-type = "text/markdown"

[project.urls]
Documentation = "https://github.com/debatelab/evidence-seeker#readme"
Issues = "https://github.com/debatelab/evidence-seeker/issues"
Source = "https://github.com/debatelab/evidence-seeker"

[project.scripts]
evse = "evidence_seeker.cli.evse_cli:main"

[tool.hatch.env]
requires = [
    "hatch-pip-compile"
]

[tool.hatch.version]
path = "src/evidence_seeker/__about__.py"


# not needed since we use hatch to build the pkg
# [tool.setuptools.package-data]
# "evidence_seeker.package_data" = ["*.yml", "*.py","*.json", "*.txt", "*.csv", "*.md"]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/README.md",
    "/LICENSE*",
]

[tool.hatch.build.targets.wheel]
packages = ["src/evidence_seeker"]

[tool.hatch.envs.default]
dependencies = [
  "jupyter",
  "ipywidgets",
  "llama-index-callbacks-arize-phoenix",
  "llama-index-utils-workflow",
  "pip-tools",
  "pytest",
]

[tool.hatch.envs.evse-dev_env]
#type = "pip-compile"
#lock-filename = "locks/{env_name}.lock"
dependencies = [
  "jupyter",
  "ipywidgets",
  #"llama-index-callbacks-arize-phoenix",
  #"llama-index-utils-workflow",
  #"pip-tools",
  #"pytest",
  "llama-index-embeddings-huggingface",
  "llama_index.embeddings.ollama",
  #"llama-index-embeddings-instructor",
  "llama-index-llms-openai-like",
  #"gradio==5.38.2",
  "gradio",
  "pygithub",
  "python-dotenv",
  "jinja2",
  # used by the snowflake-arctic-embed-m-v2.0 embed model
  "xformers",
  "llama-index-vector-stores-postgres",
]

[[tool.hatch.envs.evse-dev_env.matrix]]
python = ["3.11", "3.12"]

[tool.hatch.envs.types]
extra-dependencies = [
  "mypy>=1.0.0",
]
[tool.hatch.envs.types.scripts]
check = "mypy --install-types --non-interactive {args:src/evidence_seeker tests}"

[tool.coverage.run]
source_pkgs = ["evidence_seeker", "tests"]
branch = true
parallel = true
omit = [
  "src/evidence_seeker/__about__.py",
]

[tool.coverage.paths]
evidence_seeker = ["src/evidence_seeker", "*/evidence-seeker/src/evidence_seeker"]
tests = ["tests", "*/evidence-seeker/tests"]

[tool.coverage.report]
exclude_lines = [
  "no cov",
  "if __name__ == .__main__.:",
  "if TYPE_CHECKING:",
]

# used by `uv`
[dependency-groups]
dev = [
    "ipykernel>=7.1.0",
    "pytest>=8.4.2",
]
