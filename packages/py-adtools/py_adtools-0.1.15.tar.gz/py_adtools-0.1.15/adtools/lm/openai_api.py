"""
Copyright (c) 2025 Rui Zhang <rzhang.cs@gmail.com>

NOTICE: This code is under MIT license. This code is intended for academic/research purposes only.
Commercial use of this software or its derivatives requires prior written permission.
"""

import os
from typing import List, Optional

import openai.types.chat

from adtools.lm.lm_base import LanguageModel


class OpenAIAPI(LanguageModel):
    def __init__(
        self,
        model: str,
        base_url: str = None,
        api_key: str = None,
        **openai_init_kwargs,
    ):
        super().__init__()
        # If base_url is set to None, find 'OPENAI_BASE_URL' in environment variables
        if base_url is None:
            if "OPENAI_BASE_URL" not in os.environ:
                raise RuntimeError(
                    'If "base_url" is None, the environment variable OPENAI_BASE_URL must be set.'
                )
            else:
                base_url = os.environ["OPENAI_BASE_URL"]

        # If api_key is set to None, find 'OPENAI_API_KEY' in environment variables
        if api_key is None:
            if "OPENAI_API_KEY" not in os.environ:
                raise RuntimeError('If "api_key" is None, OPENAI_API_KEY must be set.')
            else:
                api_key = os.environ["OPENAI_API_KEY"]

        self._model = model
        self._client = openai.OpenAI(
            api_key=api_key, base_url=base_url, **openai_init_kwargs
        )

    def chat_completion(
        self,
        message: str | List[openai.types.chat.ChatCompletionMessageParam],
        max_tokens: Optional[int] = None,
        timeout_seconds: Optional[float] = None,
        *args,
        **kwargs,
    ):
        """Send a chat completion query with OpenAI format to the vLLM server.
        Return the response content.

        Args:
            message: The message in str or openai format.
            max_tokens: The maximum number of tokens to generate.
            timeout_seconds: The timeout seconds.
        """
        if isinstance(message, str):
            message = [{"role": "user", "content": message.strip()}]

        response = self._client.chat.completions.create(
            model=self._model,
            messages=message,
            stream=False,
            max_tokens=max_tokens,
            timeout=timeout_seconds,
            *args,
            **kwargs,
        )
        return response.choices[0].message.content
