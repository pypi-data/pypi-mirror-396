name: Run Tests

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:
    # Allow manual triggering

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # Installing ollama model in GitHub Actions runner requires significant disk space.
        # It reduces the space available for browser-based tests
        test-type: ["unit", "integration", "ollama_local"]
        include:
          - test-type: "unit"
            pytest-args: "-m 'unit'"
          - test-type: "integration"
            pytest-args: "-m 'integration'"
          - test-type: "ollama_local"
            pytest-args: "-m 'ollama_local'"


    steps:

      # Keeping it here when we need to free up space in future
      # - name: Free up space
      #   uses: jlumbroso/free-disk-space@main
      #   with:
      #     tool-cache: true
      #     android: true
      #     dotnet: true
      #     haskell: true
      #     large-packages: true

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Set up Docker Buildx
        if: matrix.test-type != 'unit'
        uses: docker/setup-buildx-action@v3

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock pytest-asyncio pytest-xdist pytest-rerunfailures

      - name: Install package in development mode
        run: |
          pip install -e .

      - name: Build Docker images for integration tests
        if: matrix.test-type != 'unit'
        run: |
          # Build the shell server image needed for Docker tests
          docker build -f src/microbots/environment/local_docker/image_builder/Dockerfile -t kavyasree261002/shell_server:latest .

      - name: Check disk space before ollama installation
        if: matrix.test-type == 'ollama_local'
        run: df -h

      - name: Run model
        uses: ai-action/ollama-action@v1
        id: model
        if: matrix.test-type == 'ollama_local'
        with:
          model: qwen2.5-coder:latest
          prompt: Hi, Are you running? What is your model name?

      - name: Check disk space after ollama installation
        if: matrix.test-type == 'ollama_local'
        run: df -h

      - name: Print response
        run: echo "$response"
        env:
          response: ${{ steps.model.outputs.response }}

      - name: Run ${{ matrix.test-type }} tests
        env:
          # OpenAI API Configuration
          OPEN_AI_KEY: ${{ secrets.OPEN_AI_KEY }}
          OPEN_AI_DEPLOYMENT_NAME: ${{ secrets.OPEN_AI_DEPLOYMENT_NAME }}
          OPEN_AI_END_POINT: ${{ secrets.OPEN_AI_END_POINT }}
          # Azure OpenAI API Configuration
          AZURE_OPENAI_API_VERSION: ${{ secrets.AZURE_OPENAI_API_VERSION }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          BROWSER_USE_LLM_MODEL: "gpt-5"
          BROWSER_USE_LLM_TEMPERATURE: 1
          #Anthrpic API Configuration
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ANTHROPIC_DEPLYMENT_NAME: ${{ secrets.ANTHROPIC_DEPLOYMENT_NAME }}
          ANTHROPIC_END_POINT: ${{ secrets.ANTHROPIC_END_POINT }}
        run: |
          python -m pytest ${{ matrix.pytest-args }} \
            -n auto \
            --dist loadgroup \
            --reruns 1 \
            --reruns-delay 5 \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=test-results-${{ matrix.test-type }}.xml \
            -v \
            -o log_cli=true \
            -o log_cli_level=DEBUG \
            -o log_cli_format="%(asctime)s [%(levelname)s] %(name)s: %(message)s" \
            -o log_cli_date_format="%Y-%m-%d %H:%M:%S"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-type }}
          path: test-results-*.xml

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-${{ matrix.test-type }}
          path: coverage.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: ${{ matrix.test-type }}
          name: codecov-${{ matrix.test-type }}
          fail_ci_if_error: false

  test-summary:
    runs-on: ubuntu-latest
    needs: [test]
    if: always()
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true

      - name: Test Summary
        if: always()
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY