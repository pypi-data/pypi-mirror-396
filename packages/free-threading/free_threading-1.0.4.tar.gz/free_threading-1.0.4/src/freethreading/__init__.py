"""
:mod:`freethreading` is a lightweight wrapper that provides a unified API for true
parallel execution in Python. It automatically uses :mod:`threading` on free-threaded
Python builds (where the GIL is disabled) and falls back to :mod:`multiprocessing` on
standard ones. This enables true parallelism across Python versions while preferring the
efficiency of threads over processes whenever possible.

:mod:`freethreading` is a drop-in replacement for *most* pre-existing :mod:`threading`
and :mod:`multiprocessing` code. To achieve this, the module exposes only non-deprecated
common functionality shared between both backends while discarding any backend-specific
APIs.

Examples
--------
>>> from freethreading import Worker, WorkerPool, WorkerPoolExecutor, current_worker
>>>
>>> def task():
...     print(f"Hello from {current_worker().name}!")
...
>>> w = Worker(target=task, name="MyWorker")
>>> w.start()
>>> w.join()
Hello from MyWorker!
>>>
>>> def square(x):
...     return x * x
...
>>> with WorkerPool(workers=2) as pool:
...     print(pool.map(square, range(5)))
...
[0, 1, 4, 9, 16]
>>>
>>> with WorkerPoolExecutor(max_workers=2) as executor:
...     # 'Hello from ThreadPoolExecutor-0_0!' or 'Hello from ForkProcess-2!'
...     future = executor.submit(task)
...
Hello from ThreadPoolExecutor-0_0!

Note
----
On Python 3.14 (standard builds), examples using user-defined functions with
:class:`Worker`, :class:`WorkerPool`, or :class:`WorkerPoolExecutor` must be saved to a
``.py`` file to run.

See Also
--------
threading : Threading-based parallelism.
multiprocessing : Process-based parallelism.
concurrent.futures : High-level interface for asynchronous execution.
"""

import pickle
import platform
import sys
from multiprocessing.process import BaseProcess
from threading import Thread
from typing import Literal

_backend: Literal["threading", "multiprocessing"]

if sys._is_gil_enabled() if hasattr(sys, "_is_gil_enabled") else True:
    from concurrent.futures import ProcessPoolExecutor as _WorkerPoolExecutor
    from multiprocessing import Barrier as _Barrier
    from multiprocessing import BoundedSemaphore as _BoundedSemaphore
    from multiprocessing import Condition as _Condition
    from multiprocessing import Event as _Event
    from multiprocessing import JoinableQueue as _Queue
    from multiprocessing import Lock as _Lock
    from multiprocessing import Process as _Worker
    from multiprocessing import RLock as _RLock
    from multiprocessing import Semaphore as _Semaphore
    from multiprocessing import SimpleQueue as _SimpleQueue
    from multiprocessing import active_children as _active_children
    from multiprocessing import current_process as _current_worker
    from multiprocessing.pool import Pool as _WorkerPool
    from os import getpid as _get_ident

    def _active_count():
        return len(_enumerate())

    def _enumerate():
        workers = list(_active_children())
        workers.append(_current_worker())
        return workers

    _backend = "multiprocessing"

else:
    from concurrent.futures import ThreadPoolExecutor as _WorkerPoolExecutor
    from multiprocessing.pool import ThreadPool as _WorkerPool
    from queue import Queue as _Queue
    from queue import SimpleQueue as _SimpleQueue
    from threading import Barrier as _Barrier
    from threading import BoundedSemaphore as _BoundedSemaphore
    from threading import Condition as _Condition
    from threading import Event as _Event
    from threading import Lock as _Lock
    from threading import RLock as _RLock
    from threading import Semaphore as _Semaphore
    from threading import Thread as _Worker
    from threading import active_count as _active_count
    from threading import current_thread as _current_worker
    from threading import enumerate as _enumerate
    from threading import get_ident as _get_ident

    def _active_children():
        children = list(_enumerate())
        children.remove(_current_worker())
        return children

    _backend = "threading"


def _validate_picklability(**kwargs):
    """Validate that all arguments are picklable for multiprocessing compatibility."""
    try:
        pickle.dumps(tuple(kwargs.values()))
    except (AttributeError, TypeError, pickle.PicklingError) as e:
        raise ValueError(
            f"{list(kwargs.keys())} must be picklable for compatibility with "
            f"multiprocessing backend. Error: {e}. "
            f"Use module-level functions instead of lambdas or nested functions."
        ) from e


class Barrier:
    """
    Synchronization barrier for coordinating :class:`Worker` objects.

    A barrier is used to wait for a fixed number of workers to reach a
    common point. Uses :class:`threading.Barrier` or
    :class:`multiprocessing.Barrier` depending on backend.

    Parameters
    ----------
    parties : int
        Number of workers required to pass the barrier.
    action : callable, optional
        Function called by one worker when the barrier is passed.
    timeout : float, optional
        Default timeout for :meth:`wait` calls.

    See Also
    --------
    threading.Barrier : :mod:`threading` implementation.
    multiprocessing.Barrier : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Barrier, Worker
    >>> barrier = Barrier(3)  # Wait for 3 workers
    >>> def synchronized_task(i):
    ...     print(f"Worker {i} reached barrier")
    ...     barrier.wait()
    ...     print(f"Worker {i} past barrier")
    ...
    >>> workers = [Worker(target=synchronized_task, args=(i,)) for i in range(3)]
    >>> for w in workers:
    ...     w.start()
    >>> for w in workers:
    ...     w.join()
    ...
    Worker 0 reached barrier
    Worker 1 reached barrier
    Worker 2 reached barrier
    Worker 0 past barrier
    Worker 1 past barrier
    Worker 2 past barrier
    """

    def __init__(self, parties, action=None, timeout=None):
        self._barrier = _Barrier(parties, action, timeout)

    def wait(self, timeout=None):
        """
        Wait until all parties have reached the barrier.

        Parameters
        ----------
        timeout : float, optional
            Maximum time to wait in seconds.

        Returns
        -------
        int
            The arrival index (0 to parties-1).

        Raises
        ------
        threading.BrokenBarrierError
            If the barrier is broken or reset.
        """
        return self._barrier.wait(timeout)

    def reset(self):
        """Reset the barrier to its initial empty state."""
        self._barrier.reset()

    def abort(self):
        """Put the barrier into a broken state."""
        self._barrier.abort()

    @property
    def parties(self):
        """The number of workers required to trip the barrier."""
        return self._barrier.parties

    @property
    def n_waiting(self):
        """The number of workers currently waiting at the barrier."""
        return self._barrier.n_waiting

    @property
    def broken(self):
        """Whether the barrier is in a broken state."""
        return self._barrier.broken


class BoundedSemaphore:
    """
    A semaphore that prevents releasing more times than acquired.

    A bounded semaphore guards against excessive releases by raising an error if
    released more times than acquired. Uses :class:`threading.BoundedSemaphore` or
    :class:`multiprocessing.BoundedSemaphore` depending on backend.

    Parameters
    ----------
    value : int, default=1
        Initial value for the semaphore counter.

    See Also
    --------
    threading.BoundedSemaphore : :mod:`threading` implementation.
    multiprocessing.BoundedSemaphore : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import BoundedSemaphore
    >>> sem = BoundedSemaphore(1)
    >>> sem.acquire()
    True
    >>> sem.release()
    >>> sem.release()
    Traceback (most recent call last):
        ...
    ValueError: Semaphore released too many times
    """

    def __init__(self, value=1):
        self._semaphore = _BoundedSemaphore(value)

    def acquire(self, blocking=True, timeout=None):
        """
        Acquire the semaphore, decrementing the counter.

        Parameters
        ----------
        blocking : bool, default=True
            If True, block until the semaphore can be acquired. If False, return
            immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        bool
            True if acquired, False if not acquired (non-blocking or timeout).
        """
        return self._semaphore.acquire(blocking, timeout)

    def release(self):
        """
        Release the semaphore, incrementing the counter.

        Raises
        ------
        ValueError
            If released more times than acquired.
        """
        self._semaphore.release()

    def __enter__(self):
        """Enter the runtime context (acquire the semaphore)."""
        return self._semaphore.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (release the semaphore)."""
        return self._semaphore.__exit__(exc_type, exc_val, exc_tb)


class Condition:
    """
    Condition variable for worker coordination.

    A condition variable allows one or more workers to wait until notified by another
    worker. Uses :class:`threading.Condition` or :class:`multiprocessing.Condition`
    depending on backend.

    Parameters
    ----------
    lock : Lock or RLock, optional
        Underlying lock to use. If not provided, a new :class:`RLock` is created.

    See Also
    --------
    threading.Condition : :mod:`threading` implementation.
    multiprocessing.Condition : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Condition, Queue, Worker, current_worker
    >>>
    >>> condition = Condition()
    >>> queue = Queue()
    >>> def producer(data):
    ...     with condition:
    ...         queue.put(data)
    ...         print(f"'{current_worker().name}' sent: {data}")
    ...         condition.notify()
    ...
    >>> def consumer():
    ...     with condition:
    ...         condition.wait()
    ...         print(f"'{current_worker().name}' received: {queue.get()}")
    ...
    >>> c = Worker(name="Consumer", target=consumer)
    >>> p = Worker(name="Producer", target=producer, args=(42,))
    >>> c.start()
    >>> p.start()
    >>> c.join()
    >>> p.join()
    'Producer' sent: 42
    'Consumer' received: 42
    """

    def __init__(self, lock=None):
        self._condition = _Condition(
            lock._lock if isinstance(lock, (Lock, RLock)) else None  # type: ignore[arg-type]
        )

    def acquire(self, blocking=True, timeout=None):
        """
        Acquire the underlying lock.

        Parameters
        ----------
        blocking : bool, default=True
            If True, block until the lock can be acquired. If False, return immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        bool
            True if acquired, False if not acquired (non-blocking or timeout).
        """
        if _backend == "threading":
            if timeout is None or timeout < 0:
                timeout = -1
        else:
            if timeout is not None and timeout < 0:
                timeout = None
        return self._condition.acquire(blocking, timeout)  # type: ignore[call-arg]

    def release(self):
        """
        Release the underlying lock.

        Raises
        ------
        RuntimeError
            When the lock is not held (threading backend).
        AssertionError
            When the lock is not held (multiprocessing backend).
        """
        self._condition.release()

    def wait(self, timeout=None):
        """
        Wait until notified or a timeout occurs.

        Parameters
        ----------
        timeout : float, optional
            Maximum time to wait in seconds. None means wait forever.

        Returns
        -------
        bool
            True if notified, False if timeout occurred.

        Raises
        ------
        RuntimeError
            When the lock is not held (threading backend).
        AssertionError
            When the lock is not held (multiprocessing backend).
        """
        return self._condition.wait(timeout)

    def wait_for(self, predicate, timeout=None):
        """
        Wait until a predicate becomes true.

        Parameters
        ----------
        predicate : callable
            Function that returns a boolean value.
        timeout : float, optional
            Maximum time to wait in seconds. None means wait forever.

        Returns
        -------
        bool
            The last value returned by the predicate.

        Raises
        ------
        RuntimeError
            When the lock is not held (threading backend).
        AssertionError
            When the lock is not held (multiprocessing backend).
        """
        return self._condition.wait_for(predicate, timeout)

    def notify(self, n=1):
        """
        Wake up one or more workers waiting on this condition.

        Parameters
        ----------
        n : int, default=1
            Number of workers to wake up.

        Raises
        ------
        RuntimeError
            When the lock is not held (threading backend).
        AssertionError
            When the lock is not held (multiprocessing backend).
        """
        self._condition.notify(n)

    def notify_all(self):
        """
        Wake up all workers waiting on this condition.

        Raises
        ------
        RuntimeError
            When the lock is not held (threading backend).
        AssertionError
            When the lock is not held (multiprocessing backend).
        """
        self._condition.notify_all()

    def __enter__(self):
        """Enter the runtime context (acquire the lock)."""
        return self._condition.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (release the lock)."""
        return self._condition.__exit__(exc_type, exc_val, exc_tb)


class Event:
    """
    Synchronization primitive for signaling between :class:`Worker` objects.

    An event manages an internal flag that can be set or cleared. Workers can
    wait for the flag to be set. Uses :class:`threading.Event` or
    :class:`multiprocessing.Event` depending on backend.

    See Also
    --------
    threading.Event : :mod:`threading` implementation.
    multiprocessing.Event : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Event, Worker, current_worker
    >>>
    >>> event = Event()
    >>> def wait():
    ...     print(f"'{current_worker().name}': waiting for notification")
    ...     event.wait()
    ...     print(f"'{current_worker().name}': received notification")
    ...
    >>> def notify():
    ...     event.set()
    ...     print(f"'{current_worker().name}': sent notification")
    ...
    >>> waiter = Worker(name="Waiter", target=wait)
    >>> notifier = Worker(name="Notifier", target=notify)
    >>> waiter.start()
    >>> notifier.start()
    >>> waiter.join()
    >>> notifier.join()
    'Waiter': waiting for notification
    'Notifier': sent notification
    'Waiter': received notification
    """

    def __init__(self):
        self._event = _Event()

    def is_set(self):
        """
        Return True if and only if the internal flag is set.

        Returns
        -------
        bool
            True if set, False otherwise.
        """
        return self._event.is_set()

    def set(self):
        """Set the internal flag, waking up all waiting workers."""
        self._event.set()

    def clear(self):
        """Reset the internal flag to false."""
        self._event.clear()

    def wait(self, timeout=None):
        """
        Block until the internal flag is true.

        Parameters
        ----------
        timeout : float, optional
            Maximum time to wait in seconds. None means wait forever.

        Returns
        -------
        bool
            True if the flag is set, False if a timeout occurred.
        """
        return self._event.wait(timeout)


class Lock:
    """
    Mutual exclusion lock for worker synchronization.

    A lock ensures only one worker enters a critical section at a time. Uses
    :class:`threading.Lock` or :class:`multiprocessing.Lock` depending on backend.

    See Also
    --------
    threading.Lock : :mod:`threading` implementation.
    multiprocessing.Lock : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Lock, Worker, current_worker
    >>>
    >>> lock = Lock()
    >>> def critical():
    ...     with lock:
    ...         print(f"'{current_worker().name}': acquired lock")
    ...
    >>> workers = [Worker(name=f"Worker-{i}", target=critical) for i in range(2)]
    >>> for w in workers:
    ...     w.start()
    >>> for w in workers:
    ...     w.join()
    ...
    'Worker-0': acquired lock
    'Worker-1': acquired lock
    """

    def __init__(self):
        self._lock = _Lock()

    def acquire(self, blocking=True, timeout=None):
        """
        Acquire the lock.

        Parameters
        ----------
        blocking : bool, default=True
            If True, block until the lock can be acquired. Otherwise, return
            immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        bool
            True if acquired, False if not acquired (non-blocking or timeout).
        """
        if _backend == "threading":
            if timeout is None or timeout < 0:
                timeout = -1
        else:
            if timeout is not None and timeout < 0:
                timeout = None
        return self._lock.acquire(blocking, timeout)  # type: ignore[call-arg]

    def release(self):
        """
        Release the lock.

        Raises
        ------
        RuntimeError
            When invoked on an unlocked lock (threading backend).
        ValueError
            When invoked on an unlocked lock (multiprocessing backend).
        """
        self._lock.release()

    def locked(self):
        """
        Return True if the lock is currently held.

        Returns
        -------
        bool
            True if locked, False otherwise.
        """
        if hasattr(self._lock, "locked"):
            return self._lock.locked()  # type: ignore[attr-defined]

        # Fallback for Python < 3.14
        if self.acquire(blocking=False):
            self.release()
            return False
        return True

    def __enter__(self):
        """Enter the runtime context (acquire the lock)."""
        return self._lock.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (release the lock)."""
        return self._lock.__exit__(exc_type, exc_val, exc_tb)


class Queue:
    """
    FIFO queue for worker communication.

    A queue supporting task tracking with :meth:`task_done` and :meth:`join`. Uses
    :class:`queue.Queue` or :class:`multiprocessing.JoinableQueue` depending on backend.

    Parameters
    ----------
    maxsize : int, default=0
        Maximum number of items allowed in the queue. 0 means unlimited.

    See Also
    --------
    queue.Queue : :mod:`threading` implementation.
    multiprocessing.JoinableQueue : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Queue, Worker
    >>>
    >>> queue = Queue()
    >>> def producer():
    ...     for value in range(3):
    ...         queue.put(value)
    ...     queue.put(None)  # Sentinel marks completion
    ...
    >>> def consumer():
    ...     while True:
    ...         item = queue.get()
    ...         if item is None:
    ...             queue.task_done()
    ...             break
    ...         print(f"Processing {item}")
    ...         queue.task_done()
    ...
    >>> producer_worker = Worker(name="Producer", target=producer)
    >>> consumer_worker = Worker(name="Consumer", target=consumer)
    >>> producer_worker.start()
    >>> consumer_worker.start()
    >>> queue.join()
    >>> producer_worker.join()
    >>> consumer_worker.join()
    Processing 0
    Processing 1
    Processing 2
    """

    def __init__(self, maxsize=0):
        self._queue = _Queue(maxsize)

    def put(self, item, block=True, timeout=None):
        """
        Put an item into the queue.

        Parameters
        ----------
        item
            Item to add to the queue.
        block : bool, default=True
            If True, block until space is available. Otherwise, return immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Raises
        ------
        queue.Full
            If the queue is full and non-blocking or timeout occurred.
        """
        self._queue.put(item, block=block, timeout=timeout)

    def get(self, block=True, timeout=None):
        """
        Remove and return an item from the queue.

        Parameters
        ----------
        block : bool, default=True
            If True, block until an item is available. Otherwise, return immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        item
            The next item from the queue.

        Raises
        ------
        queue.Empty
            If the queue is empty and non-blocking or timeout occurred.
        """
        return self._queue.get(block=block, timeout=timeout)

    def task_done(self):
        """
        Indicate that a formerly enqueued task is complete.

        Raises
        ------
        ValueError
            If called more times than there were items placed in the queue.
        """
        self._queue.task_done()

    def join(self):
        """Block until all items have been gotten and processed."""
        self._queue.join()

    def qsize(self):
        """
        Return the approximate size of the queue.

        Returns
        -------
        int
            Number of items in the queue.

        Raises
        ------
        NotImplementedError
            On macOS, due to platform limitations (sem_getvalue not implemented).
        """
        if platform.system() == "Darwin":
            raise NotImplementedError(
                "qsize() is not available on macOS due to platform limitations."
            )
        return self._queue.qsize()

    def empty(self):
        """
        Return True if the queue is empty.

        Returns
        -------
        bool
            True if empty, False otherwise.
        """
        return self._queue.empty()

    def full(self):
        """
        Return True if the queue is full.

        Returns
        -------
        bool
            True if full, False otherwise.
        """
        return self._queue.full()

    def put_nowait(self, item):
        """
        Put an item into the queue without blocking.

        Parameters
        ----------
        item
            Item to add to the queue.

        Raises
        ------
        queue.Full
            If queue is full.
        """
        self._queue.put_nowait(item)

    def get_nowait(self):
        """
        Remove and return an item without blocking.

        Returns
        -------
        item
            The next item from the queue.

        Raises
        ------
        queue.Empty
            If queue is empty.
        """
        return self._queue.get_nowait()


class RLock:
    """
    Reentrant lock for worker synchronization.

    A reentrant lock can be acquired multiple times by the same worker without blocking.
    The lock must be released once for each time it was acquired. Uses
    :class:`threading.RLock` or :class:`multiprocessing.RLock` depending on backend.

    See Also
    --------
    threading.RLock : :mod:`threading` implementation.
    multiprocessing.RLock : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import RLock, Worker, current_worker
    >>>
    >>> rlock = RLock()
    >>> def countdown(n):
    ...     with rlock:
    ...         if n > 0:
    ...             print(f"'{current_worker().name}': {n}...")
    ...             countdown(n - 1)
    ...         else:
    ...             print(f"'{current_worker().name}': go!")
    ...
    >>> worker = Worker(name="Worker-0", target=countdown, args=(3,))
    >>> worker.start()
    >>> worker.join()
    'Worker-0': 3...
    'Worker-0': 2...
    'Worker-0': 1...
    'Worker-0': go!
    """

    def __init__(self):
        self._lock = _RLock()

    def acquire(self, blocking=True, timeout=None):
        """
        Acquire the lock, incrementing the recursion level.

        Parameters
        ----------
        blocking : bool, default=True
            If True, block until the lock can be acquired. Otherwise, return
            immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        bool
            True if acquired, False if not acquired (non-blocking or timeout).
        """
        if _backend == "threading":
            if timeout is None or timeout < 0:
                timeout = -1
        else:
            if timeout is not None and timeout < 0:
                timeout = None
        return self._lock.acquire(blocking, timeout)  # type: ignore[call-arg]

    def release(self):
        """
        Release the lock, decrementing the recursion level.

        Raises
        ------
        RuntimeError
            When invoked on an unlocked lock or by a worker other than the owner
            (threading backend).
        AssertionError
            When invoked on an unlocked lock or by a worker other than the owner
            (multiprocessing backend).
        """
        self._lock.release()

    def __enter__(self):
        """Enter the runtime context (acquire the lock)."""
        return self._lock.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (release the lock)."""
        return self._lock.__exit__(exc_type, exc_val, exc_tb)


class Semaphore:
    """
    Counting semaphore for limiting concurrent access.

    A semaphore manages an internal counter decremented by :meth:`acquire` calls
    and incremented by :meth:`release` calls. Uses :class:`threading.Semaphore`
    or :class:`multiprocessing.Semaphore` depending on backend.

    Parameters
    ----------
    value : int, default=1
        Initial value for the semaphore counter.

    See Also
    --------
    threading.Semaphore : :mod:`threading` implementation.
    multiprocessing.Semaphore : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Semaphore, Worker, current_worker
    >>>
    >>> sem = Semaphore(2)
    >>> def limited_resource():
    ...     with sem:
    ...         print(f"'{current_worker().name}': in restricted section")
    ...
    >>> workers = [
    ...     Worker(name=f"Worker-{i}", target=limited_resource) for i in range(3)
    ... ]
    >>> for w in workers:
    ...     w.start()
    >>> for w in workers:
    ...     w.join()
    ...
    'Worker-0': in restricted section
    'Worker-1': in restricted section
    'Worker-2': in restricted section
    """

    def __init__(self, value=1):
        self._semaphore = _Semaphore(value)

    def acquire(self, blocking=True, timeout=None):
        """
        Acquire the semaphore, decrementing the counter.

        Parameters
        ----------
        blocking : bool, default=True
            If True, block until the semaphore can be acquired. Otherwise, return
            immediately.
        timeout : float, optional
            Maximum time to wait in seconds when blocking. None means wait forever.

        Returns
        -------
        bool
            True if acquired, False if not acquired (non-blocking or timeout).
        """
        return self._semaphore.acquire(blocking, timeout)

    def release(self):
        """Release the semaphore, incrementing the counter."""
        self._semaphore.release()

    def __enter__(self):
        """Enter the runtime context (acquire the semaphore)."""
        return self._semaphore.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (release the semaphore)."""
        return self._semaphore.__exit__(exc_type, exc_val, exc_tb)


class SimpleQueue:
    """
    Lightweight FIFO queue for worker communication.

    A simpler queue without task tracking or size limits. Uses
    :class:`queue.SimpleQueue` or :class:`multiprocessing.SimpleQueue` depending
    on backend.

    See Also
    --------
    queue.SimpleQueue : :mod:`threading` implementation.
    multiprocessing.SimpleQueue : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import SimpleQueue, Worker
    >>>
    >>> queue = SimpleQueue()
    >>> def fill_queue():
    ...     queue.put("hello")
    ...     queue.put("world")
    ...
    >>> worker = Worker(target=fill_queue)
    >>> worker.start()
    >>> queue.get()
    'hello'
    >>> queue.get()
    'world'
    >>> worker.join()
    >>> queue.empty()
    True
    """

    def __init__(self):
        self._queue = _SimpleQueue()

    def put(self, item):
        """
        Put an item into the queue.

        Parameters
        ----------
        item
            Item to add to the queue.

        Notes
        -----
        This method always blocks until the item can be added, ensuring
        consistent behavior across threading and multiprocessing backends.
        """
        self._queue.put(item)

    def get(self):
        """
        Remove and return an item from the queue.

        Returns
        -------
        item
            The next item from the queue.

        Notes
        -----
        This method always blocks until an item is available, ensuring
        consistent behavior across threading and multiprocessing backends.
        """
        return self._queue.get()

    def empty(self):
        """
        Return True if the queue is empty.

        Returns
        -------
        bool
            True if empty, False otherwise.
        """
        return self._queue.empty()


class Worker:
    """
    Thread or process for parallel execution.

    Represents an activity that runs in a separate thread or process. Uses
    :class:`threading.Thread` or :class:`multiprocessing.Process` depending on backend.

    Parameters
    ----------
    group : None
        Reserved for future extension (always None).
    target : callable, optional
        Function to be invoked by the :meth:`run` method.
    name : str, optional
        Worker name for identification.
    args : tuple, default=()
        Positional arguments for the target function.
    kwargs : dict, optional
        Keyword arguments for the target function.
    daemon : bool, optional
        Whether the worker is a daemon. Daemon workers are terminated when
        the program exits.

    Raises
    ------
    ValueError
        If target, args, or kwargs are not picklable. All arguments must be
        picklable to ensure portability across threading and multiprocessing
        backends. Use module-level functions instead of lambdas or nested
        functions.

    See Also
    --------
    threading.Thread : :mod:`threading` implementation.
    multiprocessing.Process : :mod:`multiprocessing` implementation.

    Examples
    --------
    >>> from freethreading import Worker, current_worker
    >>>
    >>> def greet():
    ...     print(f"Hello from '{current_worker().name}'")
    ...
    >>> worker = Worker(name="Worker", target=greet)
    >>> worker.start()
    >>> worker.join()
    Hello from 'Worker'
    """

    def __init__(
        self,
        group=None,
        target=None,
        name=None,
        args=(),
        kwargs=None,
        *,
        daemon=None,
    ):
        if kwargs is None:
            kwargs = {}

        _validate_picklability(target=target, args=args, kwargs=kwargs)

        self._worker = _Worker(
            group=group,
            target=target,
            name=name,
            args=args,
            kwargs=kwargs,
            daemon=daemon,
        )

    def start(self):
        """
        Start the worker's activity.

        Raises
        ------
        RuntimeError
            If called more than once (threading backend).
        AssertionError
            If called more than once (multiprocessing backend).
        """
        self._worker.start()

    def join(self, timeout=None):
        """
        Wait for the worker to terminate.

        Parameters
        ----------
        timeout : float, optional
            Maximum time to wait in seconds. None means wait forever.

        Raises
        ------
        RuntimeError
            If called before start or on the current worker (threading backend).
        AssertionError
            If called before start (multiprocessing backend).
        """
        self._worker.join(timeout)

    def is_alive(self):
        """
        Return whether the worker is alive.

        Returns
        -------
        bool
            True if the worker is still running.
        """
        return self._worker.is_alive()

    @property
    def name(self):
        """The worker's name."""
        return self._worker.name

    @name.setter
    def name(self, value):
        self._worker.name = value

    @property
    def daemon(self):
        """Whether the worker is a daemon."""
        return self._worker.daemon

    @daemon.setter
    def daemon(self, value):
        self._worker.daemon = value


class WorkerPool:
    """
    Pool of workers for parallel execution.

    Provides a pool of workers that can execute tasks in parallel. Uses
    :class:`multiprocessing.pool.Pool` or :class:`multiprocessing.pool.ThreadPool`
    depending on backend.

    Parameters
    ----------
    workers : int, optional
        Number of workers in the pool. Defaults to the number of CPUs.
    initializer : callable, optional
        Callable invoked on each worker at start.
    initargs : tuple, default=()
        Arguments for initializer.

    Raises
    ------
    ValueError
        If initializer or initargs are not picklable. All arguments must be picklable
        to ensure portability across threading and multiprocessing backends. Use
        module-level functions instead of lambdas or nested functions.

    See Also
    --------
    multiprocessing.pool.Pool : Process pool implementation.
    multiprocessing.pool.ThreadPool : Thread pool implementation.

    Examples
    --------
    >>> from freethreading import WorkerPool
    >>>
    >>> def square(x):
    ...     return x * x
    >>> with WorkerPool(workers=4) as pool:
    ...     results = pool.map(square, range(10))
    >>> results
    [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
    """

    def __init__(self, workers=None, initializer=None, initargs=()):
        _validate_picklability(initializer=initializer, initargs=initargs)

        self._pool = _WorkerPool(
            processes=workers,
            initializer=initializer,
            initargs=initargs,
        )

    def apply(self, func, args=(), kwds=None):
        """
        Call func with arguments args and keyword arguments kwds.

        Blocks until the result is ready.

        Parameters
        ----------
        func : callable
            Function to call.
        args : tuple, default=()
            Positional arguments for func.
        kwds : dict, optional
            Keyword arguments for func.

        Returns
        -------
        object
            Result of the function call.

        Raises
        ------
        ValueError
            If func, args, or kwds are not picklable.
        """
        if kwds is None:
            kwds = {}
        _validate_picklability(func=func, args=args, kwds=kwds)
        return self._pool.apply(func, args, kwds)

    def apply_async(self, func, args=(), kwds=None, callback=None, error_callback=None):
        """
        Asynchronous version of :meth:`apply`.

        Parameters
        ----------
        func : callable
            Function to call.
        args : tuple, default=()
            Positional arguments for func.
        kwds : dict, optional
            Keyword arguments for func.
        callback : callable, optional
            Called with the result when ready.
        error_callback : callable, optional
            Called with exception if call fails.

        Returns
        -------
        AsyncResult
            Result object for retrieving the result.

        Raises
        ------
        ValueError
            If func, args, or kwds are not picklable.
        """
        if kwds is None:
            kwds = {}
        _validate_picklability(func=func, args=args, kwds=kwds)
        return self._pool.apply_async(
            func, args, kwds, callback=callback, error_callback=error_callback
        )

    def map(self, func, iterable, chunksize=None):
        """
        Apply func to each element in iterable.

        Blocks until all results are ready.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of arguments.
        chunksize : int, optional
            Size of chunks for workers. Larger values reduce overhead.

        Returns
        -------
        list
            List of results in order.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.map(func, iterable, chunksize)

    def map_async(
        self, func, iterable, chunksize=None, callback=None, error_callback=None
    ):
        """
        Asynchronous version of :meth:`map`.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of arguments.
        chunksize : int, optional
            Size of chunks for workers.
        callback : callable, optional
            Called with the result list when ready.
        error_callback : callable, optional
            Called with exception if call fails.

        Returns
        -------
        AsyncResult
            Result object for retrieving the results.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.map_async(
            func, iterable, chunksize, callback=callback, error_callback=error_callback
        )

    def imap(self, func, iterable, chunksize=1):
        """
        Lazier version of :meth:`map`.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of arguments.
        chunksize : int, default=1
            Size of chunks for workers.

        Returns
        -------
        iterator
            Iterator yielding results in order.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.imap(func, iterable, chunksize)

    def imap_unordered(self, func, iterable, chunksize=1):
        """
        Like :meth:`imap` but results are yielded as soon as ready.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of arguments.
        chunksize : int, default=1
            Size of chunks for workers.

        Returns
        -------
        iterator
            Iterator yielding results as they complete.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.imap_unordered(func, iterable, chunksize)

    def starmap(self, func, iterable, chunksize=None):
        """
        Like :meth:`map` but arguments are unpacked from iterables.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of argument tuples.
        chunksize : int, optional
            Size of chunks for workers.

        Returns
        -------
        list
            List of results in order.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.starmap(func, iterable, chunksize)

    def starmap_async(
        self, func, iterable, chunksize=None, callback=None, error_callback=None
    ):
        """
        Asynchronous version of :meth:`starmap`.

        Parameters
        ----------
        func : callable
            Function to apply.
        iterable : iterable
            Iterable of argument tuples.
        chunksize : int, optional
            Size of chunks for workers.
        callback : callable, optional
            Called with the result list when ready.
        error_callback : callable, optional
            Called with exception if call fails.

        Returns
        -------
        AsyncResult
            Result object for retrieving the results.

        Raises
        ------
        ValueError
            If func is not picklable.
        """
        _validate_picklability(func=func)
        return self._pool.starmap_async(
            func, iterable, chunksize, callback=callback, error_callback=error_callback
        )

    def close(self):
        """
        Prevent any more tasks from being submitted to the pool.

        Once all tasks are complete, workers will exit.
        """
        self._pool.close()

    def terminate(self):
        """
        Stop workers immediately without completing outstanding work.
        """
        self._pool.terminate()

    def join(self):
        """
        Wait for workers to exit.

        Must call :meth:`close` or :meth:`terminate` before using :meth:`join`.
        """
        self._pool.join()

    def __enter__(self):
        """Enter the runtime context."""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (terminate the pool)."""
        self.terminate()
        return False


class WorkerPoolExecutor:
    """
    Executor that manages a pool of :class:`Worker` objects.

    Provides a high-level interface for asynchronously executing callables using
    a pool of workers. Uses :class:`concurrent.futures.ThreadPoolExecutor` or
    :class:`concurrent.futures.ProcessPoolExecutor` depending on backend.

    Parameters
    ----------
    max_workers : int, optional
        Maximum number of workers in the pool.
    **kwargs
        Additional arguments passed to the underlying executor.

    See Also
    --------
    concurrent.futures.ThreadPoolExecutor : Thread pool executor.
    concurrent.futures.ProcessPoolExecutor : Process pool executor.

    Examples
    --------
    >>> from freethreading import WorkerPoolExecutor
    >>> def square(x):
    ...     return x * x
    >>> with WorkerPoolExecutor(max_workers=4) as executor:
    ...     results = list(executor.map(square, range(10)))
    >>> results
    [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
    """

    def __init__(self, max_workers=None, **kwargs):
        self._executor = _WorkerPoolExecutor(max_workers=max_workers, **kwargs)

    def submit(self, fn, *args, **kwargs):
        """
        Submit a callable to be executed.

        Parameters
        ----------
        fn : callable
            The callable to execute.
        *args
            Positional arguments for fn.
        **kwargs
            Keyword arguments for fn.

        Returns
        -------
        Future
            A Future representing the execution.

        Raises
        ------
        ValueError
            If fn, args, or kwargs are not picklable.
        """
        _validate_picklability(fn=fn, args=args, kwargs=kwargs)
        return self._executor.submit(fn, *args, **kwargs)

    def map(self, fn, *iterables, timeout=None, chunksize=1):
        """
        Map a function over iterables.

        Parameters
        ----------
        fn : callable
            Function to apply.
        *iterables
            Iterables to map over.
        timeout : float, optional
            Maximum time to wait for results. None means no limit.
        chunksize : int, default=1
            Size of chunks for workers.

        Returns
        -------
        iterator
            Iterator over results.

        Raises
        ------
        ValueError
            If fn is not picklable.
        TimeoutError
            If the entire result iterator could not be generated before the timeout.
        """
        _validate_picklability(fn=fn)
        return self._executor.map(fn, *iterables, timeout=timeout, chunksize=chunksize)

    def shutdown(self, wait=True, cancel_futures=False):
        """
        Shutdown the executor.

        Parameters
        ----------
        wait : bool, default=True
            If True, wait for pending futures to complete.
        cancel_futures : bool, default=False
            If True, cancel pending futures.
        """
        return self._executor.shutdown(wait=wait, cancel_futures=cancel_futures)

    def __enter__(self):
        """Enter the runtime context."""
        return self._executor.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit the runtime context (shutdown the executor)."""
        return self._executor.__exit__(exc_type, exc_val, exc_tb)


def active_children() -> list[Thread] | list[BaseProcess]:
    """
    Return a list of all active workers, excluding the current one.

    Returns
    -------
    list of Thread | BaseProcess
        List of child thread or process objects currently alive, excluding the
        current worker.

    See Also
    --------
    active_count : Get the count of all active workers
    current_worker : Get the current worker
    enumerate : Get a list of all workers

    Examples
    --------
    >>> from freethreading import active_children, Worker
    >>> def task():
    ...     pass
    >>> w = Worker(target=task)
    >>> w.start()
    >>> children = active_children()
    >>> len(children) >= 1  # At least our worker
    True
    """
    return _active_children()


def active_count() -> int:
    """
    Return the number of currently active workers.

    Returns
    -------
    int
        Number of currently running workers.

    See Also
    --------
    current_worker : Get the current worker
    enumerate : Get a list of all workers

    Notes
    -----
    This counts all workers (threads or processes) that have been started but not yet
    finished.

    Examples
    --------
    >>> from freethreading import Worker, active_count
    >>>
    >>> def busy_wait():
    ...     while True:
    ...         pass
    ...
    >>> daemon = Worker(target=busy_wait, name="Daemon", daemon=True) # Daemon worker
    >>> daemon.start()
    >>> active_count()  # Main worker + our worker
    2
    """
    return _active_count()


def current_worker() -> Thread | BaseProcess:
    """
    Return the current worker object.

    Returns
    -------
    Thread | BaseProcess
        The underlying thread or process object corresponding to the caller.

    See Also
    --------
    active_count : Get the count of all active workers
    get_ident : Get the identifier of the current worker

    Examples
    --------
    >>> from freethreading import current_worker
    >>> current_worker().name # 'MainThread' or 'MainProcess'
    'MainThread'
    """
    return _current_worker()


def get_backend() -> Literal["threading", "multiprocessing"]:
    """
    Get the name of the active concurrency backend.

    Returns
    -------
    Literal['threading', 'multiprocessing']
        'threading' when GIL is disabled, and 'multiprocessing' otherwise.

    Examples
    --------
    >>> from freethreading import get_backend
    >>> get_backend()  # 'threading' or 'multiprocessing' depending on your Python build
    'threading'
    """
    return _backend


def get_ident() -> int:
    """
    Return the identifier of the current worker.

    Returns
    -------
    int
        Thread identifier or process ID of the current worker.

    See Also
    --------
    current_worker : Get the current worker

    Notes
    -----
    - When using threading backend: Returns thread identifier
    - When using multiprocessing backend: Returns process ID (PID)

    Examples
    --------
    >>> from freethreading import get_ident
    >>> ident = get_ident()
    >>> isinstance(ident, int)
    True
    """
    return _get_ident()


def enumerate() -> list[Thread] | list[BaseProcess]:
    """
    Return a list of all active worker objects, including the current one.

    Returns
    -------
    list of Thread | BaseProcess
        List of all underlying thread or process objects currently alive,
        including the current worker.

    See Also
    --------
    current_worker : Get the current worker
    active_children : Get a list of all workers, excluding the current one
    active_count : Get the count of all active workers

    Notes
    -----
    Backend-specific attributes like ``pid`` (processes) or ``native_id`` (threads)
    are also available but not portable across backends.

    Examples
    --------
    >>> from freethreading import Worker, enumerate
    >>>
    >>> def busy_wait():
    ...     while True:
    ...         pass
    ...
    >>> daemon = Worker(target=busy_wait, name="Daemon", daemon=True) # Daemon worker
    >>> daemon.start()
    >>> len(enumerate())  # Main worker + our worker
    2
    """
    return _enumerate()


__all__ = [
    "Barrier",
    "BoundedSemaphore",
    "Condition",
    "Event",
    "Lock",
    "Queue",
    "RLock",
    "Semaphore",
    "SimpleQueue",
    "Worker",
    "WorkerPool",
    "WorkerPoolExecutor",
    "active_children",
    "active_count",
    "current_worker",
    "get_backend",
    "get_ident",
    "enumerate",
]
