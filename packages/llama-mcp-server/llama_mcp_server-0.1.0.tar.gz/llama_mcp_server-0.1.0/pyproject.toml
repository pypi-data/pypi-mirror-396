[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llama-mcp-server"
version = "0.1.0"
description = "MCP server for document parsing with LlamaCloud multimodal understanding"
readme = "README.md"
requires-python = ">=3.10"
license = "MIT"
authors = [
    { name = "Oloruntoba Madamori", email = "oloruntoba.madamori@totogi.com" }
]
keywords = ["mcp", "llama", "llamacloud", "document-parsing", "ai"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]
dependencies = [
    "llama-index-indices-managed-llama-cloud>=0.6.9",
    "mcp[cli]>=1.6.0",
    "python-dotenv>=1.1.0",
    "llama-cloud-services",
    "click",
]

[project.urls]
Homepage = "https://github.com/oloruntoba-madamori/llamacloud-mcp"
Repository = "https://github.com/oloruntoba-madamori/llamacloud-mcp"

[project.scripts]
llama-mcp-server = "llamacloud_mcp.main:main"

[tool.hatch.build.targets.wheel]
packages = ["llamacloud_mcp"]