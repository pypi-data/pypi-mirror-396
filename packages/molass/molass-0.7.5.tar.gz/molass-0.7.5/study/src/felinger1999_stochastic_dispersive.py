"""
Stochastic-Dispersive Theory of Chromatography (Felinger et al. 1999)
INTERPRETED THROUGH THE LÃ‰VY PROCESS FRAMEWORK (Pasti et al. 2005)

Implementation of the unified stochastic-dispersive model from:
"Stochastic-Dispersive Theory of Chromatography"
Felinger, A.; Cavazzini, A.; Remelli, M.; Dondi, F.
Anal. Chem. 1999, 71, 20, 4472-4479

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LÃ‰VY PROCESS INTERPRETATION (Canonical Form)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Felinger's characteristic function (eq 13):

    Î¦(Ï‰) = exp[iÏ‰tâ‚€ - Dtâ‚€Ï‰Â²/(2u) + nÂ·(Î¦_s(Ï‰) - 1)]

is EXACTLY a LÃ©vy process with three independent components:

1. DRIFT TERM (convection in mobile phase):
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Î³Â·iÏ‰  where Î³ = tâ‚€ = L/u
   
   Physical meaning: Deterministic flow carries molecules down column
   LÃ©vy component: Linear drift with velocity u

2. BROWNIAN TERM (axial dispersion):
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   -ÏƒÂ²Ï‰Â²/2  where ÏƒÂ² = 2Dtâ‚€/u = 2DL/uÂ²
   
   Physical meaning: Diffusion spreads molecules symmetrically
   LÃ©vy component: Gaussian with variance ÏƒÂ²

3. COMPOUND POISSON TERM (adsorption-desorption):
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Î»Â·âˆ«[e^(iÏ‰Ï„) - 1]Î½(dÏ„)  where Î» = n, Î½(dÏ„) = f_s(Ï„)dÏ„
   
   Physical meaning: Random jumps in time due to surface binding
   LÃ©vy component: Jump process with rate Î» and jump distribution f_s(Ï„)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CANONICAL LÃ‰VY-KHINTCHINE REPRESENTATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

The LÃ©vy-Khintchine formula states that ANY infinitely divisible distribution 
has a characteristic function of the form:

    log Î¦(Ï‰) = iÎ³Ï‰ - ÏƒÂ²Ï‰Â²/2 + âˆ«[e^(iÏ‰x) - 1 - iÏ‰xÂ·ğŸ™_{|x|<1}]Î½(dx)

Felinger 1999 simplification (all jumps are POSITIVE delays, so no cutoff needed):

    log Î¦(Ï‰) = iÎ³Ï‰ - ÏƒÂ²Ï‰Â²/2 + nÂ·âˆ«[e^(iÏ‰Ï„) - 1]f_s(Ï„)dÏ„
                â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                drift  Brownian    Poisson jumps (Ï„ â‰¥ 0)

Parameters:
- Î³ = tâ‚€ (hold-up time)
- ÏƒÂ² = 2DL/uÂ² (dispersion variance)
- Î» = n (rate parameter)
- Î½(dÏ„) = f_s(Ï„)dÏ„ (LÃ©vy measure = sorption time PDF)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KEY INSIGHTS FROM LÃ‰VY FRAMEWORK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. INDEPENDENCE: The three components (drift, Brownian, Poisson) evolve
   independently. This is why Felinger can calculate variance by ADDITION:
   
   Var[total] = Var[Brownian] + Var[Poisson]
              = 2Dtâ‚€(1+k')Â²/u  +  nÂ·(mâ‚‚ - mâ‚Â²)

2. INFINITE DIVISIBILITY: Retention time distribution is infinitely divisible
   (can be written as sum of arbitrary number of i.i.d. random variables).
   This property is FUNDAMENTAL to LÃ©vy processes.

3. LÃ‰VY MEASURE: The sorption time distribution f_s(Ï„) is actually the LÃ©vy
   measure Î½ restricted to positive jumps. Different f_s give different LÃ©vy
   processes:
   - Exponential f_s â†’ Gamma process (homogeneous surface)
   - Mixture of exponentials â†’ Mixed Gamma process (heterogeneous)
   - Log-normal f_s â†’ Log-normal subordinator

4. SUBORDINATION: In LÃ©vy theory, the adsorption process is a "subordinator"
   (monotone increasing LÃ©vy process). Time spent on surface only INCREASES,
   never decreases (Î½ supported on [0,âˆ) only).

5. MOMENTS WITHOUT SIMULATION: LÃ©vy processes have cumulant generating function
   K(Ï‰) = log Î¦(iÏ‰). Derivatives at Ï‰=0 give cumulants directly:
   
   Îºâ‚ = K'(0) = mean
   Îºâ‚‚ = K''(0) = variance
   Îºâ‚ƒ = K'''(0) = skewness numerator
   
   This is why Felinger can compute MOMENTS analytically (eqs 32-42)!
   
   âš ï¸ CRITICAL DISTINCTION (see Dondi 2002):
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ANALYTICAL: Moments (mean, variance, skewness, kurtosis, plate height)
               â†’ Always possible via derivatives of log Î¦(Ï‰) at Ï‰=0
   
   NUMERICAL:  Full peak shape f(t)
               â†’ Requires FFT inversion for most cases!
               â†’ Analytical f(t) exists ONLY for special cases:
                 * Giddings-Eyring-Carmichael (1952): no dispersion â†’ Gamma PDF
                 * Pure Gaussian: no adsorption â†’ Normal PDF
               â†’ Heterogeneous surfaces have NO closed-form f(t)!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHAT FELINGER DIDN'T KNOW IN 1999
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Felinger derived eq 13 from physical reasoning (convolution of independent
processes). But they didn't recognize this was a LÃ©vy process! The LÃ©vy
framework provides:

1. Rigorous mathematical foundation (LÃ©vy-Khintchine theorem)
2. Connection to single-molecule experiments (Pasti 2005)
3. General theory for arbitrary jump distributions
4. Path properties (cadlag trajectories, no negative jumps)
5. Extension to infinite activity (âˆ«Î½(dÏ„) = âˆ for broad distributions)

This implementation makes the LÃ©vy structure EXPLICIT through:
- Separation of Î³ (drift), ÏƒÂ² (Brownian), Î½ (LÃ©vy measure)
- Direct calculation from LÃ©vy-Khintchine formula
- Extensible sorption models = different LÃ©vy measures

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.special import i1  # Modified Bessel function of the first kind
from dataclasses import dataclass
from typing import Optional, Callable, Union
from math import factorial

@dataclass
class ColumnParameters:
    """Chromatographic column parameters."""
    L: float  # Column length (cm or Î¼m)
    u: float  # Mobile phase velocity (cm/s or Î¼m/Î¼s)
    D: float  # Axial dispersion coefficient (cmÂ²/s or Î¼mÂ²/Î¼s)
    
    @property
    def t0(self) -> float:
        """Hold-up time (column dead time)."""
        return self.L / self.u
    
    @property
    def N_disp(self) -> float:
        """Number of theoretical plates from dispersion only."""
        return self.L * self.u / (2 * self.D)


@dataclass
class SorptionModel:
    """Base class for sorption time distribution models.
    
    LÃ‰VY INTERPRETATION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    The sorption time distribution f_s(Ï„) is the LÃ‰VY MEASURE Î½(dÏ„) of the
    compound Poisson process representing adsorption-desorption events.
    
    In LÃ©vy theory, Î½(dÏ„) characterizes the jump distribution:
    - Support on [0,âˆ): Only positive delays (time spent on surface)
    - âˆ« Î½(dÏ„) < âˆ: Finite activity (finite expected number of jumps)
    - âˆ« Ï„ Î½(dÏ„): Mean jump size (average sorption time)
    - âˆ« Ï„Â² Î½(dÏ„): Second moment (controls variance)
    
    Different sorption models = Different LÃ©vy measures:
    - Exponential: Î³(dÏ„) = (1/Ï„Ì„)e^(-Ï„/Ï„Ì„)dÏ„  (Gamma process)
    - Two-site mixture: Î½ = pÂ·Î½â‚ + (1-p)Â·Î½â‚‚  (Mixed Gamma)
    - Discrete: Î½ = Î£ páµ¢Î´(Ï„-Ï„áµ¢)  (Compound Poisson with finite support)
    """
    
    def moment(self, order: int) -> float:
        """Calculate moment of sorption time distribution.
        
        For order r: m_r = âˆ« Ï„^r f(Ï„) dÏ„ = E[Ï„^r]
        
        LÃ‰VY INTERPRETATION: These are moments of the LÃ©vy measure Î½(dÏ„).
        """
        raise NotImplementedError
    
    def mean(self) -> float:
        """Mean sorption time: m_1 = E[Ï„]."""
        return self.moment(1)
    
    def variance(self) -> float:
        """Variance: m_2 - m_1Â²."""
        return self.moment(2) - self.moment(1)**2
    
    def pdf(self, tau: np.ndarray) -> np.ndarray:
        """Probability density function f(Ï„)."""
        raise NotImplementedError
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """Characteristic function Î¦_s(Ï‰) = E[exp(iÏ‰Ï„)].
        
        LÃ‰VY INTERPRETATION:
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        This is the characteristic function of the LÃ‰VY MEASURE, which appears
        in the compound Poisson term:
        
            exp[nÂ·(Î¦_s(Ï‰) - 1)] = exp[Î»Â·âˆ«(e^(iÏ‰Ï„) - 1)Î½(dÏ„)]
        
        where Î¦_s(Ï‰) = âˆ« e^(iÏ‰Ï„) f_s(Ï„)dÏ„
        
        The "-1" in the exponent is crucial: it's the LÃ©vy-Khintchine
        compensator that ensures the process starts at 0.
        """
        raise NotImplementedError


class HomogeneousSorption(SorptionModel):
    """Homogeneous surface: exponential distribution (Giddings-Eyring).
    
    f(Ï„) = (1/Ï„Ì„) exp(-Ï„/Ï„Ì„)
    
    LÃ‰VY INTERPRETATION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    This is a GAMMA PROCESS (also called Gamma subordinator).
    
    The compound Poisson process with exponential jumps is equivalent to
    a continuous-time random walk that, in the limit nâ†’âˆ, converges to
    a Gamma process with:
    - Shape parameter: Î± = n
    - Scale parameter: Î² = Ï„Ì„
    
    The Gamma process is the prototypical LÃ©vy subordinator used in
    time change (subordination) applications.
    """
    
    def __init__(self, tau_mean: float):
        """
        Parameters
        ----------
        tau_mean : float
            Mean sorption time Ï„Ì„ (same units as time)
        """
        self.tau_mean = tau_mean
    
    def moment(self, order: int) -> float:
        """For exponential: m_r = r! Ï„Ì„^r."""
        return factorial(order) * (self.tau_mean ** order)
    
    def pdf(self, tau: np.ndarray) -> np.ndarray:
        """Exponential PDF."""
        return (1/self.tau_mean) * np.exp(-tau/self.tau_mean)
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """CF for exponential: Î¦(Ï‰) = 1/(1 - iÏ‰Ï„Ì„)."""
        return 1.0 / (1.0 - 1j * omega * self.tau_mean)


class TwoSiteSorption(SorptionModel):
    """Two-site heterogeneous surface (Felinger 1999, Figure 4-7).
    
    Mixture of two exponential distributions:
    f(Ï„) = pÂ·f_1(Ï„) + (1-p)Â·f_2(Ï„)
    
    LÃ‰VY INTERPRETATION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    This is a MIXTURE OF GAMMA PROCESSES.
    
    The LÃ©vy measure is:
        Î½(dÏ„) = pÂ·Î½â‚(dÏ„) + (1-p)Â·Î½â‚‚(dÏ„)
    
    where Î½â‚ and Î½â‚‚ are exponential measures with rates 1/Ï„â‚ and 1/Ï„â‚‚.
    
    Physically: Each adsorption event randomly selects either a fast site
    (probability p) or slow site (probability 1-p), then draws a sorption
    time from the corresponding exponential distribution.
    
    This creates a DISCRETE LÃ‰VY MEASURE with two atoms (Dirac masses)
    in the limit of rare events, or a continuous mixture for frequent events.
    
    KEY INSIGHT: Heterogeneity = Multiple components in LÃ©vy measure!
    """
    
    def __init__(self, tau1: float, tau2: float, p: float):
        """
        Parameters
        ----------
        tau1 : float
            Mean sorption time on fast sites
        tau2 : float
            Mean sorption time on slow sites
        p : float
            Proportion of fast sites (0 < p < 1)
        """
        self.tau1 = tau1
        self.tau2 = tau2
        self.p = p
        
    def moment(self, order: int) -> float:
        """Weighted sum of exponential moments."""
        m1 = factorial(order) * (self.tau1 ** order)
        m2 = factorial(order) * (self.tau2 ** order)
        return self.p * m1 + (1 - self.p) * m2
    
    def pdf(self, tau: np.ndarray) -> np.ndarray:
        """Mixture of two exponentials."""
        f1 = (1/self.tau1) * np.exp(-tau/self.tau1)
        f2 = (1/self.tau2) * np.exp(-tau/self.tau2)
        return self.p * f1 + (1 - self.p) * f2
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """Weighted sum of exponential CFs."""
        cf1 = 1.0 / (1.0 - 1j * omega * self.tau1)
        cf2 = 1.0 / (1.0 - 1j * omega * self.tau2)
        return self.p * cf1 + (1 - self.p) * cf2
    
    def worst_composition(self) -> dict:
        """Calculate worst stationary phase composition (eq 43).
        
        Returns proportion of slow sites that gives maximum plate height.
        """
        k1 = self.tau1  # Proportional to k'
        k2 = self.tau2
        
        p_worst = (k1 * np.sqrt(k2)) / (np.sqrt(k1) * (k1 + k2))
        
        return {
            'p_slow_worst': 1 - p_worst,
            'p_fast_worst': p_worst,
            'tau_ratio': k2 / k1
        }


class LogNormalSorption(SorptionModel):
    """Log-normal distribution from Gaussian energy distribution.
    
    From Frenkel equation: Ï„ = Ï„â‚€ exp(E/RT)
    If E ~ N(E*, Ïƒ_EÂ²) then Ï„ has log-normal distribution.
    
    LÃ‰VY INTERPRETATION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    This is a LOG-NORMAL SUBORDINATOR.
    
    The LÃ©vy measure has the form:
        Î½(dÏ„) = (1/(Ï„Ïƒâˆš(2Ï€))) exp(-(log Ï„ - Î¼)Â²/(2ÏƒÂ²)) dÏ„
    
    Key property: INFINITE ACTIVITY near Ï„=0
        âˆ«â‚€Â¹ Î½(dÏ„) = âˆ
    
    This means the process has INFINITELY MANY small jumps near zero.
    However, the integral âˆ«â‚€^âˆ Ï„ Î½(dÏ„) < âˆ, so mean jump size is finite.
    
    Physical interpretation: Continuous distribution of adsorption energies
    creates continuous distribution of sorption times, with many brief
    visits to shallow sites and rare long visits to deep sites.
    
    Unlike exponential (Gamma process), this does NOT simplify to a
    standard named LÃ©vy process, but it's still a valid LÃ©vy subordinator.
    """
    
    def __init__(self, tau_star: float, sigma_E: float, RT: float = 1.0):
        """
        Parameters
        ----------
        tau_star : float
            Median sorption time (Ï„* = Ï„â‚€ exp(E*/RT))
        sigma_E : float
            Standard deviation of energy distribution
        RT : float
            Gas constant Ã— Temperature (default: 1.0 for normalized)
        """
        self.tau_star = tau_star
        self.sigma_E = sigma_E
        self.RT = RT
        self.q = np.exp((sigma_E / RT)**2)  # Convenience parameter
    
    def moment(self, order: int) -> float:
        """For log-normal: m_r = Ï„*^r Â· q^(rÂ²/2) (eq 46 in Felinger 1999)."""
        return (self.tau_star ** order) * (self.q ** (order**2 / 2))
    
    def pdf(self, tau: np.ndarray) -> np.ndarray:
        """Log-normal PDF."""
        sigma = self.sigma_E / self.RT
        numerator = np.exp(-0.5 * ((np.log(tau / self.tau_star) / sigma)**2))
        denominator = tau * sigma * np.sqrt(2 * np.pi)
        return numerator / denominator
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """No closed form - must integrate numerically."""
        raise NotImplementedError("Log-normal CF requires numerical integration")


class DiscreteSorption(SorptionModel):
    """Discrete sorption time distribution (arbitrary histogram).
    
    Used for Monte Carlo comparison or experimental distributions.
    
    LÃ‰VY INTERPRETATION:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    This is a COMPOUND POISSON PROCESS with FINITE SUPPORT.
    
    The LÃ©vy measure is a sum of Dirac masses:
        Î½(dÏ„) = Î£áµ¢ páµ¢ Î´(Ï„ - Ï„áµ¢)
    
    This is the most general finite-activity LÃ©vy subordinator.
    
    Properties:
    - Finite activity: âˆ« Î½(dÏ„) = Î£ páµ¢ = 1 < âˆ
    - Jump process: Sample paths are piecewise constant (step functions)
    - Poisson arrivals: Jumps occur at Poisson times with rate Î» = n
    - Random jump sizes: Each jump is Ï„áµ¢ with probability páµ¢
    
    This is EXACTLY what Pasti 2005 analyzed for single-molecule experiments!
    Each binding event is a random draw from {Ï„â‚, Ï„â‚‚, ..., Ï„â‚–} with
    probabilities {pâ‚, pâ‚‚, ..., pâ‚–}.
    """
    
    def __init__(self, tau_values: np.ndarray, probabilities: np.ndarray):
        """
        Parameters
        ----------
        tau_values : ndarray
            Discrete sorption time values
        probabilities : ndarray
            Probability of each value (must sum to 1)
        """
        self.tau_values = np.array(tau_values)
        self.probabilities = np.array(probabilities)
        
        # Normalize probabilities
        self.probabilities = self.probabilities / np.sum(self.probabilities)
    
    def moment(self, order: int) -> float:
        """Discrete moment: Î£ p_i Â· Ï„_i^r."""
        return np.sum(self.probabilities * (self.tau_values ** order))
    
    def pdf(self, tau: np.ndarray) -> np.ndarray:
        """Discrete distribution (sum of Dirac deltas - return histogram)."""
        # For visualization, create histogram
        hist, _ = np.histogram(self.tau_values, bins=len(tau), 
                               weights=self.probabilities, density=True)
        return hist
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """Discrete CF: Î£ p_i Â· exp(iÏ‰Â·Ï„_i)."""
        cf = np.zeros_like(omega, dtype=complex)
        for tau, prob in zip(self.tau_values, self.probabilities):
            cf += prob * np.exp(1j * omega * tau)
        return cf


class StochasticDispersiveChromatography:
    """
    Unified stochastic-dispersive chromatography model (Felinger 1999).
    
    Combines:
    - Random adsorption-desorption (stochastic)
    - Axial dispersion (Gaussian spreading)
    
    ANALYTICAL vs NUMERICAL:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ANALYTICAL (always possible):
    - Moments: mean, variance, skewness, kurtosis (via cumulants)
    - Plate number N, plate height H, optimum velocity
    - Peak characterization without computing f(t)
    
    NUMERICAL (required for most cases):
    - Full peak shape f(t) via FFT inversion of Î¦(Ï‰)
    - Only special cases have analytical f(t):
      * Giddings-Eyring (no dispersion) â†’ Gamma distribution
      * Pure dispersion (no adsorption) â†’ Normal distribution
      * Homogeneous + dispersion â†’ Generalized Gamma (still complex)
    
    For heterogeneous surfaces, moments are exact but f(t) needs FFT!
    """
    
    def __init__(self, column: ColumnParameters, sorption: SorptionModel, n_ads: float):
        """
        Parameters
        ----------
        column : ColumnParameters
            Column properties (L, u, D)
        sorption : SorptionModel
            Sorption time distribution model
        n_ads : float
            Mean number of adsorption-desorption events
        """
        self.column = column
        self.sorption = sorption
        self.n_ads = n_ads
    
    def retention_time(self) -> float:
        """Mean retention time (eq 32): t_R = tâ‚€(1 + k')."""
        m1 = self.sorption.mean()
        k_prime = self.n_ads * m1 / self.column.t0
        return self.column.t0 * (1 + k_prime)
    
    def variance(self) -> dict:
        """Variance components (eq 33).
        
        Returns
        -------
        dict with keys:
            'total': Total variance
            'kinetics': Variance from slow kinetics
            'dispersion': Variance from axial dispersion
        
        LÃ‰VY INTERPRETATION:
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        The total variance is the SUM of variances from independent LÃ©vy
        components (by independence):
        
        Var[X] = Var[Xâ‚] + Var[Xâ‚‚] + Var[Xâ‚ƒ]
        
        Xâ‚ (drift): Var = 0 (deterministic)
        Xâ‚‚ (Brownian): Var = ÏƒÂ² = 2Dtâ‚€/u Ã— (1+k')Â²
        Xâ‚ƒ (compound Poisson): Var = Î»âˆ«Ï„Â²Î½(dÏ„) - (Î»âˆ«Ï„Î½(dÏ„))Â²
                                   = nÂ·mâ‚‚ - nÂ²mâ‚Â² â‰ˆ n(mâ‚‚-mâ‚Â²) for large n
        
        The (1+k')Â² factor in dispersion comes from time change: molecules
        spend total time tâ‚€(1+k') in column, so dispersion accumulates over
        longer effective time.
        """
        m1 = self.sorption.mean()
        m2 = self.sorption.moment(2)
        
        # LÃ‰VY COMPONENT 3: Compound Poisson variance
        # Var[Î£áµ¢ Ï„áµ¢] where N~Poisson(n), Ï„áµ¢~f_s
        var_kinetics = self.n_ads * (m2 - m1**2)
        
        # LÃ‰VY COMPONENT 2: Brownian variance (time-changed)
        k_prime = self.n_ads * m1 / self.column.t0
        var_dispersion = 2 * self.column.D * self.column.t0 * (1 + k_prime)**2 / self.column.u
        
        return {
            'total': var_kinetics + var_dispersion,
            'kinetics': var_kinetics,  # Jump variance
            'dispersion': var_dispersion  # Brownian variance
        }
    
    def plate_number(self) -> dict:
        """Number of theoretical plates (eq 34).
        
        1/N = 1/N_kinetics + 1/N_dispersion
        
        Returns
        -------
        dict with plate numbers and contributions
        """
        m1 = self.sorption.mean()
        m2 = self.sorption.moment(2)
        k_prime = self.n_ads * m1 / self.column.t0
        
        # Dispersion contribution (B-term in van Deemter)
        inv_N_disp = 2 * self.column.D / (self.column.u * self.column.L)
        
        # Kinetic contribution (C-term in van Deemter)
        inv_N_kinetics = (m2 - m1**2) / (self.n_ads * m1**2)
        
        inv_N_total = inv_N_disp + inv_N_kinetics
        
        return {
            'N_total': 1.0 / inv_N_total,
            'N_dispersion': 1.0 / inv_N_disp,
            'N_kinetics': 1.0 / inv_N_kinetics,
            'inv_N_total': inv_N_total,
            'inv_N_dispersion': inv_N_disp,
            'inv_N_kinetics': inv_N_kinetics
        }
    
    def plate_height(self) -> dict:
        """Plate height (eq 35): H = L/N.
        
        H = B/u + CÂ·u  (van Deemter equation)
        """
        N = self.plate_number()
        m1 = self.sorption.mean()
        m2 = self.sorption.moment(2)
        k_prime = self.n_ads * m1 / self.column.t0
        
        # B and C terms
        B = 2 * self.column.D
        C = (m2 - m1**2) * self.column.L / (self.n_ads * m1**2)
        
        H_total = self.column.L / N['N_total']
        H_disp = B / self.column.u
        H_kinetics = C * self.column.u
        
        return {
            'H_total': H_total,
            'H_dispersion': H_disp,
            'H_kinetics': H_kinetics,
            'B_term': B,
            'C_term': C
        }
    
    def optimum_velocity(self) -> dict:
        """Optimum mobile phase velocity (eq 37): u_opt = âˆš(B/C)."""
        H = self.plate_height()
        u_opt = np.sqrt(H['B_term'] / H['C_term'])
        H_min = 2 * np.sqrt(H['B_term'] * H['C_term'])
        
        return {
            'u_opt': u_opt,
            'H_min': H_min,
            'N_max': self.column.L / H_min
        }
    
    def skewness(self) -> float:
        """Peak skewness (eq 41): S = Î¼â‚ƒ/ÏƒÂ³."""
        m1 = self.sorption.mean()
        m2 = self.sorption.moment(2)
        m3 = self.sorption.moment(3)
        
        var = self.variance()
        
        # Third central moment (kinetics only, dispersion contributes 0)
        mu3 = self.n_ads * (m3 - 3*m1*m2 + 2*m1**3)
        
        S = mu3 / (var['total'] ** 1.5)
        return S
    
    def excess(self) -> float:
        """Peak excess kurtosis (eq 42): Ex = Î¼â‚„/Ïƒâ´ - 3."""
        m1 = self.sorption.mean()
        m2 = self.sorption.moment(2)
        m3 = self.sorption.moment(3)
        m4 = self.sorption.moment(4)
        
        var = self.variance()
        
        # Fourth central moment (kinetics contribution)
        mu4_kin = self.n_ads * (m4 - 4*m1*m3 + 6*m1**2*m2 - 3*m1**4)
        
        # Dispersion contribution (Gaussian has excess = 0, so adds 3Ïƒâ´)
        mu4 = mu4_kin + 3 * var['dispersion']**2
        
        Ex = mu4 / (var['total'] ** 2) - 3
        return Ex
    
    def characteristic_function(self, omega: np.ndarray) -> np.ndarray:
        """Full CF including dispersion (eq 13).
        
        Î¦(Ï‰) = exp[iÏ‰tâ‚€ - Dtâ‚€Ï‰Â²/(2u) + nÂ·(Î¦_s(Ï‰) - 1)]
        
        LÃ‰VY INTERPRETATION - CANONICAL DECOMPOSITION:
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        log Î¦(Ï‰) = iÎ³Ï‰ - ÏƒÂ²Ï‰Â²/2 + Î»âˆ«[e^(iÏ‰Ï„) - 1]Î½(dÏ„)
                   â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                   DRIFT  BROWNIAN   COMPOUND POISSON
        
        Components (independent LÃ©vy processes):
        
        1. Î³ = tâ‚€: Drift at constant velocity u
           Process: Xâ‚(t) = uÂ·t (deterministic)
           
        2. ÏƒÂ² = 2Dtâ‚€/u: Brownian motion
           Process: Xâ‚‚(t) ~ N(0, 2Dt)
           
        3. Î» = n, Î½(dÏ„) = f_s(Ï„)dÏ„: Compound Poisson jumps
           Process: Xâ‚ƒ(t) = Î£áµ¢â‚Œâ‚^N(t) Ï„áµ¢ where N(t)~Poisson(Î»t), Ï„áµ¢~f_s
        
        Total: X(t) = Xâ‚(t) + Xâ‚‚(t) + Xâ‚ƒ(t)
        
        This is the LÃ‰VY-ITÃ” DECOMPOSITION in action!
        """
        # LÃ‰VY COMPONENT 1: Drift (deterministic translation)
        gamma = self.column.t0
        shift = np.exp(1j * omega * gamma)
        
        # LÃ‰VY COMPONENT 2: Brownian motion (Gaussian spreading)
        sigma_squared = 2 * self.column.D * self.column.t0 / self.column.u
        dispersion = np.exp(-sigma_squared * omega**2 / 2)
        
        # LÃ‰VY COMPONENT 3: Compound Poisson (random time delays)
        lambda_rate = self.n_ads
        cf_s = self.sorption.characteristic_function(omega)
        # LÃ©vy-Khintchine form: Î»âˆ«[e^(iÏ‰Ï„) - 1]Î½(dÏ„) = Î»[Î¦_s(Ï‰) - 1]
        poisson = np.exp(lambda_rate * (cf_s - 1))
        
        # Independence: Multiply the three components
        return shift * dispersion * poisson
    
    def calculate_peak(self, n_points: int = 4096) -> tuple:
        """Calculate chromatographic peak by FFT inversion.
        
        âš ï¸ NUMERICAL METHOD - NOT ANALYTICAL! âš ï¸
        
        This uses FFT to numerically invert the characteristic function.
        The peak shape f(t) has NO closed-form analytical expression for
        most sorption models (except Giddings-Eyring-Carmichael 1952).
        
        Even though we can compute moments analytically (via derivatives),
        the full distribution requires numerical inversion.
        
        This is exactly what Pasti 2005 did - use the CF framework to get
        f(t) numerically while getting moments analytically.
        
        Parameters
        ----------
        n_points : int
            Number of FFT points
        
        Returns
        -------
        time : ndarray
            Time values
        peak : ndarray
            Peak intensity (probability density) - NUMERICAL APPROXIMATION
        """
        # Estimate time range
        t_R = self.retention_time()
        var = self.variance()['total']
        sigma = np.sqrt(var)
        
        # Time grid
        dt = 6 * sigma / n_points  # Cover Â±3Ïƒ well
        t_max = t_R + 6 * sigma
        
        # Frequency grid
        omega_max = np.pi / dt
        omega = np.linspace(0, omega_max, n_points)
        
        # Calculate CF
        cf = self.characteristic_function(omega)
        
        # FFT inversion (same as pasti2005_levy_inversion.py)
        cf_extended = np.concatenate([cf, [0], np.conj(cf[-1:0:-1])])
        peak_complex = np.fft.ifft(cf_extended) * len(cf_extended) / np.sqrt(len(cf_extended))
        peak = np.real(peak_complex[:n_points])
        
        # Normalize
        peak = peak / (np.sum(peak) * dt)
        
        # Time axis
        time = np.arange(n_points) * dt
        
        return time, peak
    
    def summary(self) -> dict:
        """Generate comprehensive summary of chromatographic properties."""
        return {
            'retention_time': self.retention_time(),
            'variance': self.variance(),
            'plate_number': self.plate_number(),
            'plate_height': self.plate_height(),
            'optimum': self.optimum_velocity(),
            'skewness': self.skewness(),
            'excess': self.excess(),
            'retention_factor': self.n_ads * self.sorption.mean() / self.column.t0
        }


def demo_homogeneous_surface(save_fig=False):
    """Reproduce Figures 1-3 from Felinger 1999."""
    print("=" * 70)
    print("Demo: Homogeneous Surface (Figures 1-3)")
    print("=" * 70)
    
    # Parameters from Figure 1
    L = 25  # cm
    u = 0.5  # cm/s
    k_prime = 2
    n = 1000  # Fast kinetics
    
    # Calculate tau_mean from k' and n
    t0 = L / u  # 50 s
    tau_mean = k_prime * t0 / n  # 0.1 s
    
    sorption = HomogeneousSorption(tau_mean=tau_mean)
    
    # Vary diffusion coefficient
    D_values = np.logspace(-4, -1, 5)  # 10^-4 to 10^-1 cmÂ²/s
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    for D in D_values:
        column = ColumnParameters(L=L, u=u, D=D)
        model = StochasticDispersiveChromatography(column, sorption, n)
        
        time, peak = model.calculate_peak(n_points=2048)
        
        summary = model.summary()
        label = f"D = {D:.0e} cmÂ²/s, S = {summary['skewness']:.3f}"
        ax.plot(time, peak, label=label, linewidth=2)
    
    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Probability Density')
    ax.set_title(f'Homogeneous Surface: n = {n}, k\' = {k_prime}')
    ax.legend()
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    if save_fig:
        plt.savefig('felinger1999_fig1_homogeneous.png', dpi=300)
        print("\nSaved: felinger1999_fig1_homogeneous.png")
    plt.show()


def demo_two_site_heterogeneity(save_fig=False):
    """Reproduce Figures 4-7 from Felinger 1999."""
    print("\n" + "=" * 70)
    print("Demo: Two-Site Heterogeneous Surface (Figures 4-7)")
    print("=" * 70)
    
    # Parameters
    L = 25  # cm
    u = 0.5  # cm/s
    D = 0.001  # cmÂ²/s
    tau_m = 0.005  # s (mobile phase)
    tau1 = 0.01  # s (fast sites)
    
    column = ColumnParameters(L=L, u=u, D=D)
    
    # Vary tau2/tau1 ratio
    ratios = [10, 100, 1000]
    p_values = np.linspace(0.001, 0.999, 200)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Left: Minimum plate height vs composition
    ax = axes[0]
    for ratio in ratios:
        tau2 = ratio * tau1
        H_min_values = []
        
        for p in p_values:
            sorption = TwoSiteSorption(tau1, tau2, p)
            # Use high n to approach minimum
            n = 1000
            model = StochasticDispersiveChromatography(column, sorption, n)
            opt = model.optimum_velocity()
            H_min_values.append(opt['H_min'])
        
        ax.plot(1 - p_values, H_min_values, linewidth=2, 
                label=f'Ï„â‚‚/Ï„â‚ = {ratio}')
    
    ax.set_xlabel('Proportion of slow sites (1-p)')
    ax.set_ylabel('Minimum plate height H_min (cm)')
    ax.set_title('Worst Stationary Phase Composition (Fig 4)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_xlim([0, 0.3])
    
    # Right: Skewness vs proportion of slow sites
    ax = axes[1]
    for ratio in ratios:
        tau2 = ratio * tau1
        skew_values = []
        
        for p in p_values:
            sorption = TwoSiteSorption(tau1, tau2, p)
            n = 10000  # High n for clear effect
            model = StochasticDispersiveChromatography(column, sorption, n)
            skew_values.append(model.skewness())
        
        ax.semilogy(1 - p_values, np.abs(skew_values), linewidth=2,
                    label=f'Ï„â‚‚/Ï„â‚ = {ratio}')
    
    ax.set_xlabel('Proportion of slow sites (1-p)')
    ax.set_ylabel('|Skewness|')
    ax.set_title('Peak Asymmetry (Fig 6 style)')
    ax.legend()
    ax.grid(True, alpha=0.3, which='both')
    ax.set_xlim([0, 0.01])
    
    plt.tight_layout()
    if save_fig:
        plt.savefig('felinger1999_two_site_analysis.png', dpi=300)
        print("\nSaved: felinger1999_two_site_analysis.png")
    plt.show()


def demo_comparison_with_monte_carlo(save_fig=False):
    """Compare Felinger 1999 analytical model with Monte Carlo from repository."""
    print("\n" + "=" * 70)
    print("Demo: Felinger 1999 vs Monte Carlo (Repository Parameters)")
    print("=" * 70)
    
    # Parameters matching script_column_run.py
    L = 2000  # Î¼m
    u = 0.2  # Î¼m/Î¼s
    D = 0.05  # Î¼mÂ²/Î¼s (estimate)
    
    tau1 = 10  # Î¼s (fast sites)
    tau2 = 500  # Î¼s (slow sites, 50x slower)
    p = 0.98  # 98% fast, 2% slow
    
    n_ads = 100  # Approximate number of adsorptions
    
    # Create model
    column = ColumnParameters(L=L, u=u, D=D)
    sorption = TwoSiteSorption(tau1, tau2, p)
    model = StochasticDispersiveChromatography(column, sorption, n_ads)
    
    # Calculate peak
    time, peak = model.calculate_peak(n_points=2048)
    
    # Get summary
    summary = model.summary()
    
    print("\nChromatographic Properties:")
    print(f"  Retention time: {summary['retention_time']:.1f} Î¼s")
    print(f"  Retention factor k': {summary['retention_factor']:.2f}")
    print(f"  Total variance: {summary['variance']['total']:.1f} Î¼sÂ²")
    print(f"  Plate number N: {summary['plate_number']['N_total']:.1f}")
    print(f"  Plate height H: {summary['plate_height']['H_total']:.3f} Î¼m")
    print(f"  Skewness: {summary['skewness']:.3f}")
    print(f"  Excess kurtosis: {summary['excess']:.3f}")
    
    # Plot
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(time, peak, 'b-', linewidth=2.5, label='Felinger 1999 (Analytical)')
    ax.axvline(summary['retention_time'], color='r', linestyle='--', alpha=0.7,
               label=f'Mean: {summary['retention_time']:.0f} Î¼s')
    
    ax.set_xlabel('Time (Î¼s)')
    ax.set_ylabel('Probability Density')
    ax.set_title('Felinger 1999: Two-Site Model (Repository Parameters)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Add text box
    textstr = '\n'.join([
        f"N = {summary['plate_number']['N_total']:.0f}",
        f"k' = {summary['retention_factor']:.2f}",
        f"S = {summary['skewness']:.3f}",
    ])
    ax.text(0.95, 0.95, textstr, transform=ax.transAxes,
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    if save_fig:
        plt.savefig('felinger1999_repository_comparison.png', dpi=300)
        print("\nSaved: felinger1999_repository_comparison.png")
    print("\nNote: Compare this with Monte Carlo results from your repository!")
    plt.show()


if __name__ == '__main__':
    print("Felinger 1999: Stochastic-Dispersive Theory of Chromatography")
    print("=" * 70)
    
    demo_homogeneous_surface()
    demo_two_site_heterogeneity()
    demo_comparison_with_monte_carlo()
    
    print("\n" + "=" * 70)
    print("All demonstrations complete!")
    print("=" * 70)
