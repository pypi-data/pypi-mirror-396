from __future__ import annotations

"""æœ¬åœ°æ•æ„Ÿæ£€æŸ¥æœåŠ¡APIæ¨¡å—ã€‚

æœ¬æ¨¡å—æä¾›æ•æ„Ÿæ£€æŸ¥çš„æœ¬åœ°æœåŠ¡APIå…¥å£ï¼Œå®ç°HTTPæ¥å£ã€äº‹ä»¶æµã€ä»£ç†ç®¡ç†å’Œæ•°æ®è½¬å‘åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æä¾›å¥åº·æ£€æŸ¥ã€çŠ¶æ€æŸ¥è¯¢å’Œé…ç½®æŸ¥çœ‹æ¥å£
- å®ç°åŸºäºSSEçš„äº‹ä»¶æµæ¨é€æœºåˆ¶
- ç®¡ç†ç³»ç»Ÿä»£ç†è®¾ç½®ï¼ˆç‰¹åˆ«æ˜¯macOSå¹³å°ï¼‰
- æ”¯æŒæ•°æ®è½¬å‘åˆ°åç«¯æœåŠ¡
- é›†æˆè¶Šæƒæµ‹è¯•ç›¸å…³æ¥å£

æ¥å£çº¦æŸï¼š
- å…¨å±€CORSé…ç½®å…è®¸ä»»æ„æºè®¿é—®ï¼Œä¾¿äºè¿œç¨‹å‰ç«¯è°ƒç”¨
- ä¸¥æ ¼çš„è¯·æ±‚å‚æ•°æ ¡éªŒï¼Œç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
- å¥å£®çš„é”™è¯¯å¤„ç†ï¼Œæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
"""

from typing import Any, Dict, Optional
import importlib
from typing import TYPE_CHECKING
try:
    _fastapi = importlib.import_module("fastapi")
    FastAPI = getattr(_fastapi, "FastAPI")
    Request = getattr(_fastapi, "Request")
    HTTPException = getattr(_fastapi, "HTTPException")
except Exception:
    FastAPI = None
    class Request: ...
    class HTTPException(Exception): ...
try:
    _cors_mod = importlib.import_module("fastapi.middleware.cors")
    CORSMiddleware = getattr(_cors_mod, "CORSMiddleware")
except Exception:
    class CORSMiddleware: ...
try:
    _starlette_responses = importlib.import_module("starlette.responses")
    StreamingResponse = getattr(_starlette_responses, "StreamingResponse")
except Exception:
    class StreamingResponse: ...
import asyncio
import shutil
import platform

from . import __version__
from . import process
from . import events
from . import proxy_macos
from .config import load_config
from .backend_client import BackendAPIError, build_backend_api_from_context
from .packaging_utils import find_mitmdump_executable
from .realtime_manager import fix_headers_field, map_notify_to_item
from .param_test_execute import _apply_param_to_request

# added: logging & forwarding deps
import os
import json
import logging
import time
from urllib import request as _urlreq, error as _urlerr

app = FastAPI(title="sensitive-check-local", version=__version__)

# Import and register realtime routes from server.py
try:
    from . import server
    # Register realtime routes from server.py to the main app
    for route in server.app.routes:
        if hasattr(route, 'path') and route.path.startswith('/local/realtime'):
            app.router.routes.append(route)
    print("Successfully registered realtime routes from server.py")
except Exception as e:
    print(f"Failed to register realtime routes: {e}")

# In-memory snapshot for macOS system proxy to allow rollback on /stop or failure during /start
_proxy_snapshot: Dict[str, Any] | None = None
_proxy_services: list[str] | None = None
_proxy_enabled: bool = False

# CORS: allow any origin for Stage A to enable remote frontend access
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# param-test throttler lifecycle hooks
try:
    from .param_test_throttler import start_throttler as _pt_start, stop_throttler as _pt_stop
    @app.on_event("startup")
    async def _on_startup():
        try:
            await _pt_start()
            _logger.info("[param-test-throttler] started on app startup")
        except Exception:
            pass

    @app.on_event("shutdown")
    async def _on_shutdown():
        try:
            await _pt_stop()
            _logger.info("[param-test-throttler] stopped on app shutdown")
        except Exception:
            pass
except Exception:
    pass

# added: logger & forwarding config
_logger = logging.getLogger("sensitive_check_local")
if not _logger.handlers:
    _logger.setLevel(logging.ERROR)
    _h = logging.StreamHandler()
    _h.setLevel(logging.ERROR)
    _h.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s - %(message)s"))
    _logger.addHandler(_h)
logging.getLogger("uvicorn.access").setLevel(logging.ERROR)
logging.getLogger("uvicorn").setLevel(logging.ERROR)

_BACKEND_INGEST_URL = os.getenv("BACKEND_INGEST_URL", "http://aqapi.jdtest.local:8008/api/traffic/ingest")
# é»˜è®¤å…³é—­è½¬å‘ï¼›ä»… FORWARD_TO_BACKEND=true æ—¶å¼€å¯
_FORWARD_TO_BACKEND = os.getenv("FORWARD_TO_BACKEND", "false").lower() in ("1", "true", "yes", "on")
_FORWARD_LOG_BODY_MAX = int(os.getenv("FORWARD_LOG_BODY_MAX", "1024"))
_INGEST_TIMEOUT = float(os.getenv("INGEST_TIMEOUT", "5.0"))

_logger.info("[local-config] forwarding=%s target=%s timeout=%ss", _FORWARD_TO_BACKEND, _BACKEND_INGEST_URL, _INGEST_TIMEOUT)


@app.get("/health")
async def health() -> Dict[str, Any]:
    """å¥åº·æ£€æŸ¥æ¥å£ï¼Œæä¾›æœåŠ¡å¯ç”¨æ€§å’Œç‰ˆæœ¬ä¿¡æ¯ã€‚
    
    è¯¥æ¥å£ç”¨äºæ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œå¹¶è¿”å›å½“å‰æœåŠ¡ç‰ˆæœ¬ä¿¡æ¯ã€‚
    å¯ä½œä¸ºç›‘æ§æ¢é’ˆä½¿ç”¨ï¼Œæˆ–åœ¨å‰ç«¯åˆå§‹åŒ–æ—¶ç¡®è®¤æœåŠ¡å¯ç”¨æ€§ã€‚
    
    è¿”å›ï¼š
        Dict[str, Any]ï¼šåŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
            - ok (bool): æœåŠ¡çŠ¶æ€æ ‡å¿—ï¼Œå§‹ç»ˆä¸º True è¡¨ç¤ºæœåŠ¡æ­£å¸¸
            - version (str): å½“å‰æœåŠ¡ç‰ˆæœ¬å·
    """
    return {"ok": True, "version": __version__}

# æŸ¥çœ‹å½“å‰è½¬å‘é…ç½®ï¼Œä¾¿äºæ’éšœ
@app.get("/forwarding")
async def forwarding() -> Dict[str, Any]:
    """è·å–å½“å‰æ•°æ®è½¬å‘é…ç½®ä¿¡æ¯æ¥å£ã€‚
    
    è¯¥æ¥å£ç”¨äºæŸ¥çœ‹å½“å‰ç³»ç»Ÿçš„æ•°æ®è½¬å‘é…ç½®ï¼Œä¾¿äºæ’æŸ¥è½¬å‘ç›¸å…³é—®é¢˜ã€‚
    è¿”å›çš„é…ç½®åŒ…æ‹¬æ˜¯å¦å¯ç”¨è½¬å‘ã€ç›®æ ‡åç«¯URLã€è¶…æ—¶è®¾ç½®å’Œæ—¥å¿—è®°å½•é™åˆ¶ç­‰ã€‚
    
    è¿”å›ï¼š
        Dict[str, Any]ï¼šåŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
            - forwardToBackend (bool): æ˜¯å¦å¯ç”¨å‘åç«¯è½¬å‘æ•°æ®
            - backendIngestUrl (str): åç«¯æ•°æ®æ¥æ”¶URL
            - timeoutSec (float): è½¬å‘è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            - logBodyMax (int): æ—¥å¿—è®°å½•çš„è¯·æ±‚/å“åº”ä½“æœ€å¤§é•¿åº¦
    """
    return {
        "forwardToBackend": _FORWARD_TO_BACKEND,
        "backendIngestUrl": _BACKEND_INGEST_URL,
        "timeoutSec": _INGEST_TIMEOUT,
        "logBodyMax": _FORWARD_LOG_BODY_MAX,
    }


def _status_payload(state: Dict[str, Any]) -> Dict[str, Any]:
    """æ„å»ºçŠ¶æ€å“åº”æ•°æ®ç»“æ„ã€‚
    
    å°†å†…éƒ¨çŠ¶æ€æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„çŠ¶æ€å“åº”æ ¼å¼ï¼ŒåŒ…å«è¿è¡ŒçŠ¶æ€ã€ç«¯å£ã€ä¼šè¯IDç­‰ä¿¡æ¯ã€‚
    è¯¥å‡½æ•°æ•´åˆäº†è¿›ç¨‹çŠ¶æ€å’Œäº‹ä»¶ç³»ç»ŸçŠ¶æ€ï¼Œæä¾›å®Œæ•´çš„ç³»ç»Ÿè¿è¡ŒçŠ¶å†µè§†å›¾ã€‚
    
    å‚æ•°ï¼š
        state: Dict[str, Any] - è¿›ç¨‹çŠ¶æ€æ•°æ®å­—å…¸ï¼Œé€šå¸¸æ¥è‡ª process.status()
        
    è¿”å›ï¼š
        Dict[str, Any]ï¼šåŒ…å«ä»¥ä¸‹å­—æ®µçš„çŠ¶æ€ä¿¡æ¯å­—å…¸ï¼š
            - running (bool): æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ
            - port (int): æœåŠ¡ç›‘å¬ç«¯å£
            - sessionId (str): å½“å‰ä¼šè¯ID
            - lastError (str): æœ€è¿‘ä¸€æ¬¡é”™è¯¯ä¿¡æ¯
            - proxyEnabled (bool): ç³»ç»Ÿä»£ç†æ˜¯å¦å·²å¯ç”¨
            - queueSize (int): äº‹ä»¶é˜Ÿåˆ—å½“å‰å¤§å°
            - lastEventTs (int): æœ€åä¸€ä¸ªäº‹ä»¶çš„æ—¶é—´æˆ³
            - dedupEnabled (bool): æ˜¯å¦å¯ç”¨äº†äº‹ä»¶å»é‡åŠŸèƒ½
    """
    extra = events.get_status_fields()
    return {
        "running": bool(state.get("running")),
        "port": state.get("port"),
        "sessionId": state.get("sessionId"),
        "lastError": state.get("lastError"),
        "proxyEnabled": bool(state.get("proxyEnabled", False)),
        "queueSize": int(extra.get("queueSize", 0)),
        "lastEventTs": extra.get("lastEventTs"),
        # optional but useful for debugging
        "dedupEnabled": bool(state.get("dedupEnabled", False)),
    }


@app.get("/status")
async def status() -> Dict[str, Any]:
    """è·å–å½“å‰æœåŠ¡çŠ¶æ€ä¿¡æ¯æ¥å£ã€‚
    
    è¯¥æ¥å£ç”¨äºæŸ¥è¯¢æœåŠ¡çš„å½“å‰è¿è¡ŒçŠ¶æ€ï¼ŒåŒ…æ‹¬è¿è¡ŒçŠ¶æ€ã€ç«¯å£ã€ä¼šè¯IDã€
    ä»£ç†çŠ¶æ€å’Œäº‹ä»¶é˜Ÿåˆ—ä¿¡æ¯ç­‰ã€‚å‰ç«¯å¯é€šè¿‡æ­¤æ¥å£å®šæœŸæ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼Œ
    å¹¶åœ¨UIä¸Šå±•ç¤ºç›¸å…³ä¿¡æ¯ã€‚
    
    è¿”å›ï¼š
        Dict[str, Any]ï¼šåŒ…å«æœåŠ¡çŠ¶æ€ä¿¡æ¯çš„å­—å…¸ï¼Œå…·ä½“å­—æ®µè¯¦è§ _status_payload å‡½æ•°æ–‡æ¡£ã€‚
            ä¸»è¦åŒ…æ‹¬ï¼š
            - running (bool): æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ
            - port (int): æœåŠ¡ç›‘å¬ç«¯å£
            - sessionId (str): å½“å‰ä¼šè¯ID
            - proxyEnabled (bool): ç³»ç»Ÿä»£ç†æ˜¯å¦å·²å¯ç”¨
            - ä»¥åŠå…¶ä»–çŠ¶æ€ä¿¡æ¯
    """
    state = process.status()
    return _status_payload(state)


@app.get("/events")
async def events_stream():
    """äº‹ä»¶æµæ¥å£ï¼Œæä¾›åŸºäºSSEçš„å®æ—¶äº‹ä»¶æ¨é€ã€‚
    
    è¯¥æ¥å£å»ºç«‹ä¸€ä¸ªé•¿è¿æ¥ï¼Œä½¿ç”¨Server-Sent Events (SSE) åè®®å‘å®¢æˆ·ç«¯
    æ¨é€å®æ—¶äº‹ä»¶æ•°æ®ã€‚å‰ç«¯å¯é€šè¿‡EventSource APIè®¢é˜…æ­¤ç«¯ç‚¹ï¼Œå®æ—¶æ¥æ”¶
    ç³»ç»Ÿä¸­çš„äº‹ä»¶é€šçŸ¥ï¼Œå¦‚æµé‡æ•è·ã€ä»£ç†çŠ¶æ€å˜æ›´ç­‰ã€‚
    
    å®ç°ç»†èŠ‚ï¼š
    - ä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—å®ç°äº‹ä»¶è®¢é˜…å’Œå¹¿æ’­
    - è‡ªåŠ¨å¤„ç†è¿æ¥ä¸­æ–­å’Œèµ„æºæ¸…ç†
    - è®¾ç½®é€‚å½“çš„HTTPå¤´ä»¥æ”¯æŒSSEåè®®
    
    è¿”å›ï¼š
        StreamingResponse: è¿”å›ä¸€ä¸ªæµå¼å“åº”å¯¹è±¡ï¼ŒæŒç»­æ¨é€äº‹ä»¶æ•°æ®
            - åª’ä½“ç±»å‹: text/event-stream
            - æ ¼å¼: ç¬¦åˆSSEåè®®çš„æ•°æ®æµï¼Œæ¯æ¡æ¶ˆæ¯æ ¼å¼ä¸º "data: {jsonæ•°æ®}\n\n"
    """
    q = await events.subscribe()

    async def gen():
        try:
            while True:
                data = await q.get()
                yield f"data: {data}\n\n"
        except asyncio.CancelledError:
            pass
        finally:
            events.unsubscribe(q)

    headers = {"Cache-Control": "no-cache", "Connection": "keep-alive"}
    return StreamingResponse(gen(), media_type="text/event-stream", headers=headers)

# added: helpers for forwarding to backend ingest
def _truncate(s: str, n: int) -> str:
    try:
        return s if len(s) <= n else s[:n] + "..."
    except Exception:
        return s

def _post_json_blocking(url: str, payload_str: str, timeout: float, headers: dict | None = None) -> tuple[int, str]:
    """æ‰§è¡Œé˜»å¡å¼JSON POSTè¯·æ±‚ï¼Œç”¨äºæ•°æ®è½¬å‘ã€‚
    
    è¯¥å‡½æ•°å°è£…äº†æ ‡å‡†åº“çš„HTTPè¯·æ±‚åŠŸèƒ½ï¼Œæä¾›äº†å¥å£®çš„é”™è¯¯å¤„ç†å’Œå“åº”è§£æã€‚
    ä¸»è¦ç”¨äºå°†æ•è·çš„æµé‡æ•°æ®è½¬å‘åˆ°åç«¯æœåŠ¡ï¼Œæ”¯æŒè‡ªå®šä¹‰è¯·æ±‚å¤´å’Œè¶…æ—¶è®¾ç½®ã€‚
    
    å‚æ•°ï¼š
        url: str - ç›®æ ‡URLåœ°å€
        payload_str: str - è¦å‘é€çš„JSONå­—ç¬¦ä¸²
        timeout: float - è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        headers: dict | None - å¯é€‰çš„è‡ªå®šä¹‰HTTPå¤´ï¼Œä¼šä¸é»˜è®¤çš„Content-Typeåˆå¹¶
        
    è¿”å›ï¼š
        tuple[int, str]: åŒ…å«ä»¥ä¸‹å…ƒç´ çš„å…ƒç»„ï¼š
            - int: HTTPçŠ¶æ€ç ï¼ˆæˆåŠŸæ—¶ä¸º200-299ï¼Œå¤±è´¥æ—¶ä¸ºå¯¹åº”é”™è¯¯ç ï¼Œç½‘ç»œé”™è¯¯æ—¶ä¸º599ï¼‰
            - str: å“åº”ä½“æ–‡æœ¬å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯
            
    å¼‚å¸¸å¤„ç†ï¼š
        - æ•è·å¹¶å¤„ç†HTTPErrorï¼Œæå–é”™è¯¯å“åº”å†…å®¹
        - æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸ï¼Œè¿”å›599çŠ¶æ€ç å’Œå¼‚å¸¸ä¿¡æ¯
        - ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œç¡®ä¿è°ƒç”¨æ–¹å¯ä»¥å®‰å…¨å¤„ç†ç»“æœ
    """
    # merge default json header with custom headers
    _headers = {"Content-Type": "application/json"}
    try:
        if headers:
            _headers.update({str(k): str(v) for k, v in headers.items() if str(k).strip() and str(v).strip()})
    except Exception:
        pass
    req = _urlreq.Request(url=url, data=payload_str.encode("utf-8"), headers=_headers, method="POST")
    try:
        with _urlreq.urlopen(req, timeout=timeout) as resp:
            status = getattr(resp, "status", 200)
            body = resp.read()
            body_txt = body.decode("utf-8", errors="ignore") if isinstance(body, (bytes, bytearray)) else str(body)
            return status, body_txt
    except _urlerr.HTTPError as e:
        try:
            b = e.read()
            body_txt = b.decode("utf-8", errors="ignore") if isinstance(b, (bytes, bytearray)) else str(b)
        except Exception:
            body_txt = str(e)
        return int(getattr(e, "code", 500) or 500), body_txt
    except Exception as e:
        return 599, str(e)

async def _forward_ingest(body: dict):
    """å¼‚æ­¥è½¬å‘æ•è·çš„æµé‡æ•°æ®åˆ°åç«¯æœåŠ¡ã€‚
    
    è¯¥å‡½æ•°è´Ÿè´£å°†æ•è·çš„æµé‡äº‹ä»¶æ•°æ®å¼‚æ­¥è½¬å‘åˆ°åç«¯æœåŠ¡ï¼ŒåŒ…æ‹¬æ•°æ®æ ¼å¼è½¬æ¢ã€
    è¯·æ±‚å¤´å¤„ç†å’Œé”™è¯¯å¤„ç†ã€‚å®ç°äº†å¤šç§è¿‡æ»¤æœºåˆ¶ï¼Œé¿å…æ— æ•ˆè½¬å‘å’Œå¾ªç¯è¯·æ±‚ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - æ£€æŸ¥è½¬å‘å¼€å…³ï¼Œæœªå¯ç”¨æ—¶ç›´æ¥è¿”å›
    - ä»…åœ¨æ•è·è¿è¡Œæ—¶è½¬å‘ï¼Œé¿å…å¯åŠ¨å™ªéŸ³
    - é˜²æ­¢å¾ªç¯è½¬å‘ï¼ˆä¸è½¬å‘æŒ‡å‘åç«¯æ¥æ”¶URLçš„è¯·æ±‚ï¼‰
    - æ ‡å‡†åŒ–æ•°æ®æ ¼å¼ï¼Œç»Ÿä¸€å­—æ®µå‘½å
    - æ³¨å…¥èº«ä»½è®¤è¯å’Œéš”ç¦»æ ‡è¯†å¤´ä¿¡æ¯
    - å¼‚æ­¥æ‰§è¡ŒHTTPè¯·æ±‚ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
    
    å‚æ•°ï¼š
        body: dict - åŸå§‹æ•è·çš„æµé‡äº‹ä»¶æ•°æ®
        
    è¿”å›ï¼š
        None - è¯¥å‡½æ•°æ— è¿”å›å€¼ï¼Œè½¬å‘ç»“æœé€šè¿‡æ—¥å¿—è®°å½•
        
    å¼‚å¸¸å¤„ç†ï¼š
        æ•è·æ‰€æœ‰å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—ï¼Œä¸ä¼šä¸­æ–­è°ƒç”¨æ–¹çš„æ‰§è¡Œæµç¨‹
    """
    if not _FORWARD_TO_BACKEND:
        return
    try:
        # Only forward when capture is running; otherwise skip to avoid startup noise
        state = process.status()
        if not bool(state.get("running")):
            _logger.info("[local-forward] skipped: capture not running")
            return

        # avoid echo/loop: do not forward backend ingest flows themselves
        try:
            url_raw = str(body.get("url") or body.get("requestUrl") or "")
            if url_raw and url_raw.startswith(_BACKEND_INGEST_URL):
                _logger.info("[local-forward] skipped: backend ingest url")
                return
        except Exception:
            pass

        # best-effort mapping
        dto = {
            "flowId": body.get("flowId") or body.get("id") or f"local-{int(time.time()*1000)}",
            "startedAt": body.get("startedAt") or body.get("ts") or time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime()),
            "method": body.get("method") or "GET",
            "url": body.get("url") or body.get("requestUrl") or "http://aqapi.jdtest.local/",
            "responseStatus": body.get("responseStatus") or body.get("status") or 200,
            "durationMs": body.get("durationMs") or 0,
            "requestHeaders": fix_headers_field(body.get("request", {}).get("headers") or body.get("requestHeaders")),
            "responseHeaders": fix_headers_field(body.get("response", {}).get("headers") or body.get("responseHeaders")),
            "requestBodyBase64": body.get("requestBodyBase64") or "",
            "responseBodyBase64": body.get("responseBodyBase64") or "",
            "meta": body.get("meta") or {},
        }
        # ensure session_id present if provided as sessionId at top-level
        if "session_id" not in dto["meta"]:
            sid = body.get("session_id") or body.get("sessionId")
            if sid:
                dto["meta"]["session_id"] = sid

        payload_str = json.dumps(dto, ensure_ascii=False)

        # Inject headers for backend auth & isolation (align with addon)
        headers: dict[str, str] = {}
        try:
            ingest_key = os.getenv("INGEST_KEY", "").strip()
            user_id = os.getenv("USER_ID", "").strip()
            project_id = os.getenv("PROJECT_ID", "").strip()
            task_id = os.getenv("TASK_ID", "").strip()
            if ingest_key:
                headers["X-INGEST-KEY"] = ingest_key
            if user_id:
                headers["X-USER-ID"] = user_id
            if project_id:
                headers["X-PROJECT-ID"] = project_id
            if task_id:
                headers["X-TASK-ID"] = task_id
        except Exception:
            pass

        loop = asyncio.get_running_loop()
        status, resp_txt = await loop.run_in_executor(
            None, _post_json_blocking, _BACKEND_INGEST_URL, payload_str, _INGEST_TIMEOUT, headers
        )
        _logger.info("[local-forward] url=%s status=%s resp=%s", _BACKEND_INGEST_URL, status, _truncate(resp_txt, _FORWARD_LOG_BODY_MAX))
    except Exception as e:
        _logger.error("[local-forward] failed: %s", e, exc_info=False)


@app.post("/notify")
async def notify(req: Request) -> Dict[str, Any]:
    try:
        body = await req.json()
        if not isinstance(body, dict):
            body = {}
    except Exception:
        body = {}

    # è¿‡æ»¤ç›®æ ‡é€šçŸ¥ï¼šä»…å¤„ç† type == 'flow'ï¼ˆä¸å†æ”¯æŒ flow_extï¼‰
    try:
        type_str = str(body.get("type") or "").strip().lower()
    except Exception:
        type_str = ""
    if type_str != "flow":
        try:
            if _logger.isEnabledFor(logging.DEBUG):
                _logger.debug("[local-notify] skipped type=%s", type_str or "unknown")
        except Exception:
            pass
        return {"ok": True, "message": "skipped"}
    
    # ä¸€æ¬¡æ€§å†…åˆ¤ï¼ˆone-shotï¼‰ï¼šåœ¨å…¥å£æ¶ˆè´¹å¹¶è·³è¿‡ï¼Œé¿å…ä¸¢å¤´æ—¶é‡å¤å…¥é˜Ÿ
    try:
        from .realtime_queue import get_realtime_queue
        queue = get_realtime_queue()
    except Exception:
        queue = None
    try:
        # ä» body æˆ– body.payload æå– URLï¼Œè§£æä¸º domain|path
        payload_obj = (body.get("payload") or {}) if isinstance(body.get("payload"), dict) else {}
        url_raw = body.get("url") or body.get("requestUrl") or payload_obj.get("url") or payload_obj.get("requestUrl") or ""
        from urllib.parse import urlparse
        p = urlparse(str(url_raw) or "")
        dom = (p.netloc.split(":")[0] if ":" in (p.netloc or "") else (p.netloc or "")).lower().strip()
        pth = p.path or "/"
        key = f"{dom}|{pth}"
        pending_key = getattr(queue, "_pending_internal_key", None) if queue else None
        if queue and queue.is_running() and pending_key and key == pending_key:
            # å‘½ä¸­ä¸€æ¬¡æ€§æ ‡è®°ï¼šç«‹å³æ¶ˆè´¹å¹¶è·³è¿‡å…¥é˜Ÿ
            try:
                queue._pending_internal_key = None
            except Exception:
                pass
            try:
                _logger.info("[local-notify] one_shot_filtered domain=%s path=%s", dom, pth)
            except Exception:
                pass
            return {"ok": True, "message": "skipped"}
    except Exception:
        # ä»»ä½•å¼‚å¸¸å‡ä¸å½±å“åŸæœ‰é€»è¾‘ï¼Œç»§ç»­æ‰§è¡Œ
        pass

    # å¯è§æ€§æ—¥å¿—ï¼ˆé™æ•ï¼‰
    try:
        if _logger.isEnabledFor(logging.DEBUG):
            keys = list(body.keys())
            preview = _truncate(json.dumps(body) if isinstance(body, dict) else str(body), _FORWARD_LOG_BODY_MAX)
            _logger.debug("[local-notify] keys=%s size=%s preview=%s", keys, len(preview), preview)
    except Exception:
        pass

    # å¹¿æ’­äº‹ä»¶ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰ï¼Œå¹¶æ›´æ–°è®¡æ•°
    await events.broadcast(body)
    events.apply_event(body)

    # ä½¿ç”¨æ ‡å‡†æ˜ å°„å¹¶å…¥é˜Ÿï¼ˆç¯å½¢ç¼“å†²ï¼‰
    try:
        from .realtime_queue import get_realtime_queue

        queue = get_realtime_queue()
        if queue and queue.is_running():
            item = map_notify_to_item(body)

            # å…¥é˜Ÿå‰åŸŸåè¿‡æ»¤ï¼šä»…æ¥å—ç›®æ ‡åŸŸå
            accept = True
            try:
                if hasattr(queue, "should_accept_item"):
                    accept = bool(queue.should_accept_item(item))
            except Exception:
                accept = False

            if not accept:
                try:
                    if _logger.isEnabledFor(logging.DEBUG):
                        _logger.debug(
                            "[local-notify] skipped non-target domain: %s (url=%s, accepted_domains=%s)",
                            item.get("domain"),
                            item.get("url"),
                            queue.get_accepted_domains() if hasattr(queue, "get_accepted_domains") else "unknown",
                        )
                except Exception:
                    pass
                try:
                    if hasattr(queue, "cache_last_item"):
                        queue.cache_last_item(item)
                except Exception:
                    pass
            else:
                await queue.enqueue(item)
                try:
                    preview_obj = {
                        "flowId": item.get("flowId"),
                        "method": item.get("method"),
                        "domain": item.get("domain"),
                        "path": item.get("path"),
                        "occurMs": item.get("occurMs"),
                    }
                    if _logger.isEnabledFor(logging.DEBUG):
                        _logger.debug("[local-notify] enqueued preview=%s", json.dumps(preview_obj, ensure_ascii=False))
                except Exception:
                    pass
                # ç”Ÿæˆé˜Ÿåˆ—ï¼šæ¯æ¬¡å…¥é˜Ÿï¼ˆå–æ¶ˆå¤ç”¨ä¸æœ‰æ•ˆæœŸæ‹¦æˆªï¼‰
                pass
    except Exception as e:
        try:
            _logger.warning("[local-notify] realtime enqueue failed: %s", e)
        except Exception:
            pass

    # å¼‚æ­¥è½¬å‘ç»™åç«¯ï¼ˆæœ€ä½³åŠªåŠ›ï¼‰
    try:
        asyncio.create_task(_forward_ingest(body))
    except Exception:
        pass

    return {"ok": True}

@app.post("/local/notify/trigger")
async def notify_trigger() -> Dict[str, Any]:
    try:
        from .notify_scheduler import run_once
        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä»ç¯å¢ƒä¸é…ç½®æ‹‰å–ï¼‰
        cfg = load_config()
        user_id = os.getenv("USER_ID") or str(cfg.get("user_id") or "")
        project_id = os.getenv("PROJECT_ID") or str(cfg.get("project_id") or "")
        try:
            # å¤ç”¨æƒé™ä¸Šä¸‹æ–‡çš„ client_id å­˜å‚¨
            client_id = _permission_load_or_create_client_id()
        except Exception:
            import uuid
            client_id = uuid.uuid4().hex
        ctx = {
            "user_id": user_id,
            "project_id": project_id,
            "client_id": client_id,
        }
        res = await run_once(ctx)
        return {"ok": True, "result": res}
    except Exception as e:
        return {"ok": False, "error": str(e)}

@app.post("/start")
async def start(req: Request) -> Dict[str, Any]:
    global _proxy_snapshot, _proxy_services, _proxy_enabled
    try:
        body = await req.json()
        if not isinstance(body, dict):
            body = {}
    except Exception:
        body = {}
    # Normalize dedup toggle from compatible fields; persist as 'deduplicate'
    try:
        dedup_bool = bool(body.get("deduplicate") or body.get("enableDedup") or body.get("dedup"))
        body["deduplicate"] = dedup_bool
    except Exception:
        dedup_bool = False

    # Fail-fast validation: identity and ingest configuration
    try:
        merged_cfg = load_config()
    except Exception:
        merged_cfg = {}

    user_id = body.get("userId")
    if user_id is None:
        user_id = merged_cfg.get("user_id")
    project_id = body.get("projectId")
    if project_id is None:
        project_id = merged_cfg.get("project_id")
    task_id = body.get("taskId")
    if task_id is None:
        task_id = merged_cfg.get("task_id")

    # Required: userId, projectId(å…è®¸0=ä¸ªäººç©ºé—´), taskIdï¼ˆä¸¥æ ¼è¦æ±‚ï¼›ç¼ºå¤±å³ä¸­æ–­å¹¶æç¤ºï¼‰
    missing_fields: list[str] = []
    if not user_id:
        missing_fields.append("userId")
    # projectId å¿…é¡»æä¾›ï¼›å…è®¸ä¸º0è¡¨ç¤ºâ€œä¸ªäººç©ºé—´â€ï¼Œä»…ç¦æ­¢è´Ÿæ•°æˆ–ç¼ºå¤±/ç©ºå­—ç¬¦ä¸²
    try:
        pid_int = int(project_id) if project_id is not None and str(project_id).strip() != "" else None
    except Exception:
        pid_int = None
    if pid_int is None or pid_int < 0:
        missing_fields.append("projectId")
    # taskId å¿…é¡»å­˜åœ¨ï¼ˆç”±å‰ç«¯/åç«¯é¢„åˆ›å»ºä»»åŠ¡åä¼ å…¥ï¼‰
    if not task_id or str(task_id).strip() == "":
        missing_fields.append("taskId")
    if missing_fields:
        return {
            "ok": False,
            "error": f"missing required fields: {', '.join(missing_fields)}. Provide in /start body or config.yaml",
            "running": False,
            "proxyEnabled": False,
        }

    # export identity and ingest key to API process env for forwarding header injection
    try:
        os.environ["USER_ID"] = str(user_id)
        os.environ["PROJECT_ID"] = str(project_id)
        os.environ["TASK_ID"] = str(task_id)
        # åŒæ­¥å°† INGEST_KEY æ³¨å…¥å½“å‰è¿›ç¨‹ç¯å¢ƒï¼Œä¾› _forward_ingest ä½¿ç”¨
        ingest_key = body.get("ingestKey") or merged_cfg.get("ingest_key")
        if ingest_key is not None and str(ingest_key).strip() != "":
            os.environ["INGEST_KEY"] = str(ingest_key)
    except Exception:
        pass
    ingest_url_present = bool(body.get("ingestUrl") or merged_cfg.get("ingest_url"))
    if (not _FORWARD_TO_BACKEND) and (not ingest_url_present):
        return {
            "ok": False,
            "error": "ingest not configured: provide ingestUrl in body/config or set FORWARD_TO_BACKEND=true with BACKEND_INGEST_URL",
            "running": False,
            "proxyEnabled": False,
        }

    # Step 1: preflight check for mitmdump using enhanced finder
    mitmdump_path = find_mitmdump_executable()
    if not mitmdump_path:
        return {"ok": False, "error": "mitmdump not found. Please install mitmproxy (pip install mitmproxy or brew install mitmproxy)."}

    # Prepare vars
    bypass_domains = body.get("bypassDomains") or []
    if not isinstance(bypass_domains, list):
        bypass_domains = []
    _proxy_snapshot = None
    _proxy_services = None
    _proxy_enabled = False

    # å•è½® /start é˜²æŠ–ä¸çŠ¶æ€é‡ç½®ï¼šç¡®ä¿æœ€å¤šå¼¹ä¸€æ¬¡ç®¡ç†å‘˜æˆæƒï¼Œä¸”ä»…åœ¨å¯ç”¨æˆåŠŸåæ‰å…è®¸æ¢å¤
    try:
        proxy_macos._helper_install_attempted_once = False
        proxy_macos._proxy_applied_this_round = False
    except Exception:
        pass
    proxy_applied = False

    # Step 2: take proxy snapshot on macOS (Darwin) before starting
    is_darwin = platform.system() == "Darwin"
    if is_darwin:
        try:
            services = proxy_macos.detect_services()
            snap = proxy_macos.snapshot_proxy_state(services)
            _proxy_services = services
            _proxy_snapshot = snap
        except getattr(proxy_macos, "NoActiveNetworkServices", Exception):
            # No active network services -> fail fast with clear message
            msg = "æœªæ£€æµ‹åˆ°å¯ç”¨ç½‘ç»œæœåŠ¡ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®å¯ç”¨ Wiâ€‘Fi æˆ–æœ‰çº¿ç½‘ç»œåé‡è¯•"
            process.set_proxy_enabled(False)
            if hasattr(process, "set_last_error"):
                process.set_last_error(msg)
            return {
                "ok": False,
                "error": msg,
                "running": False,
                "proxyEnabled": False,
            }
        except Exception:
            # Snapshot failed for other reasons: continue in no-proxy mode
            _proxy_services = None
            _proxy_snapshot = None

    # Step 3: start mitmdump process
    res = process.start(body)
    # Log dedup-enabled with sessionId for debugging
    try:
        sid = res.get("sessionId") or process.status().get("sessionId") or body.get("sessionId")
        _logger.info("dedup-enabled:%s, sessionId=%s", "true" if dedup_bool else "false", sid)
    except Exception:
        pass
    if not bool(res.get("ok", True)):
        # Failure: rollback proxy if we changed (we haven't yet), nothing to stop here besides state
        # Just ensure proxyEnabled false
        err_msg = res.get("error") or "failed to start mitmdump"
        process.set_proxy_enabled(False)
        if hasattr(process, "set_last_error"):
            process.set_last_error(err_msg)
        return {
            "ok": False,
            "error": err_msg,
            "running": False,
            "proxyEnabled": False,
        }

    # Step 4: enable system proxy on macOS; other platforms degrade gracefully
    port = res.get("port")
    if is_darwin and isinstance(port, int) and port:
        try:
            services = _proxy_services or proxy_macos.detect_services()
            proxy_macos.enable_system_proxy(services, port, bypass_domains)
            proxy_applied = True
            _proxy_enabled = True
            process.set_proxy_enabled(True)
            if hasattr(process, "set_last_error"):
                process.set_last_error(None)
        except Exception as e:
            # Enable proxy failed: stop mitmdump and restore snapshot
            _logger.error("[start] ä»£ç†å¯ç”¨å¤±è´¥ï¼Œå¼€å§‹æ¸…ç†: %s", str(e))
            
            try:
                _logger.info("[start] åœæ­¢ mitmdump è¿›ç¨‹...")
                process.stop()
                _logger.info("[start] mitmdump è¿›ç¨‹å·²åœæ­¢")
            except Exception as stop_err:
                _logger.error("[start] åœæ­¢ mitmdump å¤±è´¥: %s", stop_err)
                
            # ä»…å½“æœ¬è½®ç¡®å®å·²å¯ç”¨è¿‡ç³»ç»Ÿä»£ç†æ—¶æ‰æ¢å¤å¿«ç…§ï¼›å¦åˆ™è·³è¿‡ï¼Œé¿å…é¢å¤–å¼¹çª—
            try:
                if proxy_applied and _proxy_snapshot:
                    _logger.info("[start] æ¢å¤ä»£ç†è®¾ç½®å¿«ç…§ï¼ˆå·²å¯ç”¨è¿‡ä»£ç†ï¼‰...")
                    proxy_macos.restore_proxy_state(_proxy_snapshot)
                    _logger.info("[start] ä»£ç†è®¾ç½®å·²æ¢å¤")
                else:
                    _logger.info("[start] è·³è¿‡æ¢å¤ï¼šæœªå¯ç”¨è¿‡ä»£ç†æˆ–æ— å¿«ç…§")
            except Exception as restore_err:
                _logger.error("[start] æ¢å¤ä»£ç†è®¾ç½®å¤±è´¥: %s", restore_err)
                
            _proxy_enabled = False
            process.set_proxy_enabled(False)
            err_text = str(e)
            if hasattr(process, "set_last_error"):
                process.set_last_error(err_text)
            
            _logger.error("[start] æœ€ç»ˆçŠ¶æ€: running=False, proxyEnabled=False, error=%s", err_text)
            
            # ç‰¹æ®Šå¤„ç†ç”¨æˆ·å–æ¶ˆçš„æƒ…å†µï¼Œæä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            user_friendly_error = err_text
            if "ç”¨æˆ·å·²å–æ¶ˆ" in err_text or "User canceled" in err_text:
                user_friendly_error = "ç”¨æˆ·å–æ¶ˆäº†ç®¡ç†å‘˜æƒé™éªŒè¯ï¼Œä»£ç†æœªå¯ç”¨ã€‚è¯·é‡æ–°å°è¯•å¹¶åœ¨å¼¹çª—ä¸­ç‚¹å‡»'å…è®¸'ã€‚"
            
            # Return the aggregated error from enable_system_proxy when available
            return {
                "ok": False,
                "error": user_friendly_error,
                "running": False,
                "proxyEnabled": False,
                "userCanceled": "ç”¨æˆ·å·²å–æ¶ˆ" in err_text or "User canceled" in err_text,
            }
    else:
        # Non-Darwin or invalid port: run without touching system proxy
        _proxy_enabled = False
        process.set_proxy_enabled(False)
        # æˆåŠŸå¯åŠ¨åæ¸…ç©º lastErrorï¼ˆå³ä¾¿æœªæ”¹ç³»ç»Ÿä»£ç†ï¼‰
        if hasattr(process, "set_last_error"):
            process.set_last_error(None)

    # è®¾ç½®å…¨å±€æ´»åŠ¨æ¨¡å¼ï¼šä»…åœ¨æœªè®¾ç½®æ—¶è®¾ä¸ºæ•°æ®ä¼ è¾“æ£€æµ‹ï¼Œé¿å…è¦†ç›–å®æ—¶æ£€æµ‹æ¨¡å¼
    try:
        from . import server
        # å¦‚æœå½“å‰æ¨¡å¼ä¸æ˜¯ realtimeï¼Œåˆ™è®¾ç½®ä¸º ingest
        if server._activity_mode != "realtime":
            server._activity_mode = "ingest"
    except Exception:
        pass

    # å¯åŠ¨å­åè‡ªåŠ¨å¼€å¯é€šçŸ¥è°ƒåº¦å™¨
    try:
        from .api import local_notify_start as _notify_start
        await _notify_start()
        _logger.info("[é€šçŸ¥] å·²è‡ªåŠ¨å¯åŠ¨é€šçŸ¥è°ƒåº¦å™¨")
    except Exception as _e_auto_notify:
        try:
            _logger.warning("[é€šçŸ¥] è‡ªåŠ¨å¯åŠ¨é€šçŸ¥è°ƒåº¦å™¨å¤±è´¥: %s", _e_auto_notify)
        except Exception:
            pass
    # ensure param-test throttler running
    try:
        from .param_test_throttler import start_throttler as _pt_start
        await _pt_start()
        _logger.info("[param-test-throttler] started after /start")
    except Exception:
        pass
    
    return {
        "ok": True,
        "sessionId": res.get("sessionId"),
        "running": True,
        "port": res.get("port"),
        "proxyEnabled": _proxy_enabled,
        "lastError": None if _proxy_enabled or not is_darwin else process.status().get("lastError"),
    }


@app.post("/stop")
async def stop() -> Dict[str, Any]:
    global _proxy_snapshot, _proxy_services, _proxy_enabled
    # Always try to stop mitmdump
    res = process.stop()
    # ä»…å½“æœ¬è½®ç¡®å®å¯ç”¨è¿‡ç³»ç»Ÿä»£ç†æ—¶æ‰æ‰§è¡Œæ¢å¤ï¼Œé¿å…æ— æ„ä¹‰æ¢å¤ä¸äºŒæ¬¡å¼¹çª—
    if platform.system() == "Darwin":
        try:
            if _proxy_enabled and _proxy_snapshot:
                proxy_macos.restore_proxy_state(_proxy_snapshot)
        except Exception:
            # best-effort restore
            pass
    # Reset in-memory flags
    _proxy_snapshot = None
    _proxy_services = None
    _proxy_enabled = False
    process.set_proxy_enabled(False)
    
    # æ¸…ç†å…¨å±€æ´»åŠ¨æ¨¡å¼
    try:
        from . import server
        server._activity_mode = None
    except Exception:
        pass
    
    return {"ok": True, "running": False, "proxyEnabled": False}
# ============================================================================
# è¶Šæƒæµ‹è¯•ç›¸å…³æ¥å£ï¼ˆæ–°å¢ï¼‰
# ============================================================================

# å†…å­˜æ€ä¸Šä¸‹æ–‡ä¸ä»»åŠ¡çŠ¶æ€ï¼ˆè¶Šæƒæµ‹è¯•ä¸“ç”¨ï¼‰
_permission_context_mem: Dict[str, Any] = {}  # ç»“æ„ï¼š{project_id, user_id, task_id, client_id, started_at, state}
_permission_running_task_id: Optional[str] = None
_permission_completed_tasks: Dict[str, str] = {}  # task_id -> "success"|"failed"
_permission_lock = asyncio.Lock()  # æ§åˆ¶å¹¶å‘ï¼šå…¨å±€ä»…å…è®¸ä¸€ä¸ªæ‰§è¡Œä¸­çš„ task

# è·¯å¾„è®¾å®šï¼ˆå…è®¸ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
def _permission_client_id_path() -> str:
    default_path = os.path.expanduser("~/.sensitive-check/client_id")
    return os.environ.get("SENSITIVE_LOCAL_CLIENT_ID_PATH", default_path)

def _permission_context_path() -> str:
    default_path = os.path.expanduser("~/.sensitive-check/context.json")
    return os.environ.get("SENSITIVE_LOCAL_CONTEXT_PATH", default_path)

def _permission_load_or_create_client_id() -> str:
    path = _permission_client_id_path()
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                client_id = f.read().strip()
                if client_id:
                    return client_id
    except Exception:
        pass
    
    # ç”Ÿæˆæ–°çš„ client_id
    import uuid
    client_id = str(uuid.uuid4())
    try:
        with open(path, "w", encoding="utf-8") as f:
            f.write(client_id)
    except Exception:
        pass
    return client_id

def _permission_load_context() -> Dict[str, Any]:
    path = _permission_context_path()
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.loads(f.read())
    except Exception:
        pass
    return {}

def _permission_save_context(ctx: Dict[str, Any]) -> None:
    path = _permission_context_path()
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(ctx, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def _permission_extract_headers(request: Request) -> tuple[str, str]:
    """
    ä»è¯·æ±‚å¤´æå– Project-Idã€User-Idï¼ˆä¸¥æ ¼ä¸åš Body å…œåº•ï¼‰
    è¿”å›ï¼š(project_id, user_id)
    """
    project_id = ""
    user_id = ""
    
    # æ”¯æŒå¤šç§ Header é”®å
    for key in ["Project-Id", "Project-ID", "X-Project-Id", "projectId"]:
        if key in request.headers:
            project_id = request.headers[key].strip()
            break
    
    for key in ["User-Id", "User-ID", "X-User-Id", "userId"]:
        if key in request.headers:
            user_id = request.headers[key].strip()
            break
    
    return project_id, user_id

@app.post("/local/context/bind")
async def permission_context_bind(request: Request) -> Dict[str, Any]:
    """
    ç»‘å®šä¸Šä¸‹æ–‡ï¼šPOST /local/context/bind
    Headers: Project-Idã€User-Id
    Body: { "task_id": "..." }
    """
    global _permission_context_mem
    
    _logger.info("[permission-bind] å¼€å§‹ç»‘å®šè¶Šæƒæµ‹è¯•ä¸Šä¸‹æ–‡")
    
    # ä¸¥æ ¼ä» Headers è¯»å–ï¼Œä¸åš Body å…œåº•
    project_id, user_id = _permission_extract_headers(request)
    _logger.info(f"[permission-bind] æå–Headers: project_id={project_id}, user_id={user_id[:6] if user_id else 'None'}***")
    
    if not project_id or not user_id:
        _logger.error("[permission-bind] ç¼ºå°‘å¿…è¦çš„Headers: Project-Id å’Œ User-Id")
        raise HTTPException(
            status_code=400,
            detail="Missing required headers: Project-Id and User-Id"
        )
    
    try:
        body = await request.json()
        task_id = str(body.get("task_id", "")).strip()
        _logger.info(f"[permission-bind] è§£æè¯·æ±‚ä½“: task_id={task_id}")
        if not task_id:
            _logger.error("[permission-bind] è¯·æ±‚ä½“ä¸­ç¼ºå°‘task_id")
            raise HTTPException(status_code=400, detail="Missing task_id in request body")
    except Exception as e:
        _logger.error(f"[permission-bind] è§£æè¯·æ±‚ä½“å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid JSON body: {e}")
    
    # ç”Ÿæˆ/è·å– client_id
    client_id = _permission_load_or_create_client_id()
    _logger.info(f"[permission-bind] è·å–å®¢æˆ·ç«¯ID: client_id={client_id[:8]}***")
    
    # æ›´æ–°å†…å­˜ä¸Šä¸‹æ–‡
    _permission_context_mem = {
        "project_id": project_id,
        "user_id": user_id,
        "task_id": task_id,
        "client_id": client_id,
        "started_at": int(time.time()),
        "state": "bound"
    }
    
    # æŒä¹…åŒ–ä¸Šä¸‹æ–‡
    _permission_save_context(_permission_context_mem)
    _logger.info("[permission-bind] ä¸Šä¸‹æ–‡å·²æŒä¹…åŒ–åˆ°æ–‡ä»¶")
    
    _logger.info(f"[permission-bind] âœ… ä¸Šä¸‹æ–‡ç»‘å®šæˆåŠŸ: task_id={task_id} project_id={project_id} user_id={user_id[:6]}*** client_id={client_id[:8]}***")
    
    return {"success": True}

@app.post("/local/tasks/start")
async def permission_task_start(request: Request) -> Dict[str, Any]:
    """
    å¯åŠ¨æ‰§è¡Œï¼šPOST /local/tasks/start
    Headers: Project-Idã€User-Id
    Body: { "task_id": "..." }
    """
    global _permission_running_task_id, _permission_completed_tasks
    
    _logger.info("[permission-start] ğŸš€ å¼€å§‹å¯åŠ¨è¶Šæƒæµ‹è¯•ä»»åŠ¡")
    
    async with _permission_lock:
        # éªŒè¯ Headers
        project_id, user_id = _permission_extract_headers(request)
        _logger.info(f"[permission-start] éªŒè¯Headers: project_id={project_id}, user_id={user_id[:6] if user_id else 'None'}***")
        
        if not project_id or not user_id:
            _logger.error("[permission-start] âŒ ç¼ºå°‘å¿…è¦çš„Headers")
            raise HTTPException(
                status_code=400,
                detail="Missing required headers: Project-Id and User-Id"
            )
        
        try:
            body = await request.json()
            task_id = str(body.get("task_id", "")).strip()
            _logger.info(f"[permission-start] è§£æä»»åŠ¡ID: task_id={task_id}")
            if not task_id:
                _logger.error("[permission-start] âŒ ç¼ºå°‘task_id")
                raise HTTPException(status_code=400, detail="Missing task_id in request body")
        except Exception as e:
            _logger.error(f"[permission-start] âŒ è§£æè¯·æ±‚ä½“å¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail=f"Invalid JSON body: {e}")
        
        # éªŒè¯ä¸Šä¸‹æ–‡ä¸€è‡´æ€§
        _logger.info(f"[permission-start] éªŒè¯ä¸Šä¸‹æ–‡ä¸€è‡´æ€§...")
        _logger.info(f"[permission-start] å†…å­˜ä¸Šä¸‹æ–‡: project_id={_permission_context_mem.get('project_id')}, user_id={_permission_context_mem.get('user_id')}, task_id={_permission_context_mem.get('task_id')}")
        
        if (_permission_context_mem.get("project_id") != project_id or
            _permission_context_mem.get("user_id") != user_id or
            _permission_context_mem.get("task_id") != task_id):
            _logger.error("[permission-start] âŒ ä¸Šä¸‹æ–‡ä¸åŒ¹é…ï¼Œéœ€è¦å…ˆè°ƒç”¨/local/context/bind")
            raise HTTPException(
                status_code=400,
                detail="Context mismatch. Please call /local/context/bind first"
            )
        
        _logger.info("[permission-start] âœ… ä¸Šä¸‹æ–‡éªŒè¯é€šè¿‡")
        
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if task_id in _permission_completed_tasks:
            status = _permission_completed_tasks[task_id]
            _logger.info(f"[permission-start] âš ï¸ ä»»åŠ¡å·²å®Œæˆ: task_id={task_id}, status={status}")
            return {
                "success": True,
                "started": False,
                "message": f"already completed: status={status}"
            }
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
        if _permission_running_task_id == task_id:
            _logger.info(f"[permission-start] âš ï¸ ä»»åŠ¡å·²åœ¨è¿è¡Œ: task_id={task_id}")
            return {
                "success": True,
                "started": False,
                "message": "already running"
            }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ä»»åŠ¡åœ¨è¿è¡Œ
        if _permission_running_task_id is not None:
            _logger.warning(f"[permission-start] âš ï¸ å…¶ä»–ä»»åŠ¡æ­£åœ¨è¿è¡Œ: current={_permission_running_task_id}, requested={task_id}")
            return {
                "success": True,
                "started": False,
                "message": f"another task running: {_permission_running_task_id}"
            }
        
        # æ ‡è®°ä¸ºè¿è¡Œä¸­
        _permission_running_task_id = task_id
        _logger.info(f"[permission-start] ğŸ“ æ ‡è®°ä»»åŠ¡ä¸ºè¿è¡Œä¸­: task_id={task_id}")
        
        # å¯åŠ¨åå°æ‰§è¡Œå™¨
        _logger.info(f"[permission-start] ğŸ”„ å¯åŠ¨åå°æ‰§è¡Œå™¨...")
        asyncio.create_task(_permission_execute_task(task_id))
        
        _logger.info(f"[permission-start] âœ… ä»»åŠ¡å¯åŠ¨æˆåŠŸ: task_id={task_id}")
        
        return {
            "success": True,
            "started": True,
            "message": "started"
        }

async def _permission_execute_task(task_id: str) -> None:
    """
    åå°æ‰§è¡Œè¶Šæƒæµ‹è¯•ä»»åŠ¡
    """
    global _permission_running_task_id, _permission_completed_tasks, _permission_context_mem
    
    try:
        _logger.info(f"[permission-execute] ğŸ”¥ å¼€å§‹æ‰§è¡Œè¶Šæƒæµ‹è¯•ä»»åŠ¡: task_id={task_id}")
        _logger.info(f"[permission-execute] å½“å‰ä¸Šä¸‹æ–‡: {_permission_context_mem}")
        
        # ä» process æ¨¡å—è°ƒç”¨æ‰§è¡Œå™¨
        _logger.info(f"[permission-execute] è°ƒç”¨process.run_permission_task...")
        success = await process.run_permission_task(_permission_context_mem.copy())
        
        # æ ‡è®°å®ŒæˆçŠ¶æ€
        status = "success" if success else "failed"
        _permission_completed_tasks[task_id] = status
        _logger.info(f"[permission-execute] âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ: task_id={task_id}, success={success}, status={status}")
        
    except Exception as e:
        _logger.error(f"[permission-execute] âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: task_id={task_id}, error={e}", exc_info=True)
        _permission_completed_tasks[task_id] = "failed"
        
    finally:
        _logger.info(f"[permission-execute] ğŸ§¹ å¼€å§‹æ¸…ç†ä»»åŠ¡çŠ¶æ€: task_id={task_id}")
        
        # æ¸…ç†è¿è¡ŒçŠ¶æ€
        if _permission_running_task_id == task_id:
            _permission_running_task_id = None
            _logger.info(f"[permission-execute] æ¸…é™¤è¿è¡Œä¸­ä»»åŠ¡ID: {task_id}")
        
        # åŸºç¡€ä¸Šä¸‹æ–‡æ¸…ç†ï¼ˆä¿ç•™ client_idï¼Œæ¸…ç† task_idï¼‰
        if _permission_context_mem.get("task_id") == task_id:
            _permission_context_mem.pop("task_id", None)
            _permission_context_mem["state"] = "completed"
            _permission_save_context(_permission_context_mem)
            _logger.info(f"[permission-execute] ä¸Šä¸‹æ–‡å·²æ›´æ–°ä¸ºcompletedçŠ¶æ€")
        
        _logger.info(f"[permission-execute] ğŸ ä»»åŠ¡æ‰§è¡Œæµç¨‹ç»“æŸ: task_id={task_id}")
_notify_task: asyncio.Task | None = None

@app.post("/local/notify/start")
async def local_notify_start() -> Dict[str, Any]:
    global _notify_task
    if _notify_task and not _notify_task.done():
        return {"ok": True, "started": False, "message": "already running"}
    cfg = load_config()
    user_id = os.getenv("USER_ID") or str(cfg.get("user_id") or "")
    project_id = os.getenv("PROJECT_ID") or str(cfg.get("project_id") or "")
    try:
        client_id = _permission_load_or_create_client_id()
    except Exception:
        import uuid
        client_id = uuid.uuid4().hex
    ctx = {"user_id": user_id, "project_id": project_id, "client_id": client_id}
    interval = 30
    try:
        interval = int(((cfg or {}).get("notify") or {}).get("intervalSec") or 30)
    except Exception:
        interval = 30
    from .notify_scheduler import run_scheduler
    _notify_task = asyncio.create_task(run_scheduler(ctx, interval_sec=interval))
    return {"ok": True, "started": True, "intervalSec": interval}

@app.post("/local/notify/stop")
async def local_notify_stop() -> Dict[str, Any]:
    global _notify_task
    if _notify_task and not _notify_task.done():
        try:
            _notify_task.cancel()
        except Exception:
            pass
    _notify_task = None
    return {"ok": True, "stopped": True}

@app.post("/local/param-test/replay")
async def local_param_test_replay(req: Request):
    try:
        body = await req.json()
    except Exception:
        raise HTTPException(status_code=400, detail={"message": "invalid json"})
    method = str(body.get("method") or "GET")
    url = str(body.get("url") or "")
    headers = fix_headers_field(body.get("headers")) or {}
    request_body = body.get("requestBody")
    parameter_path = str(body.get("parameterPath") or "")
    parameter_value_json = body.get("parameterValueJson")
    is_loss = bool(body.get("isLose", False))
    try:
        if _logger.isEnabledFor(logging.DEBUG):
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ å‚æ•° path=%s isLose=%s valueJson.preview=%s", parameter_path, str(is_loss), str(parameter_value_json)[:200])
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ åŸå§‹è¯·æ±‚ method=%s url=%s", method, url)
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ åŸå§‹è¯·æ±‚ headers.keys=%s", list(headers.keys())[:20])
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ åŸå§‹è¯·æ±‚ body.preview=%s", (str(request_body) if not isinstance(request_body, (dict, list)) else json.dumps(request_body, ensure_ascii=False))[:200])
    except Exception:
        pass
    original = {
        "method": method,
        "url": url,
        "headers": headers,
        "request_body": request_body,
    }
    mod_req = _apply_param_to_request(original, parameter_path, parameter_value_json, is_loss)
    try:
        if _logger.isEnabledFor(logging.DEBUG):
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ æ›¿æ¢åè¯·æ±‚ method=%s url=%s", str(mod_req.get("method")), str(mod_req.get("url")))
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ æ›¿æ¢å body.preview=%s", (str(mod_req.get("request_body")) if not isinstance(mod_req.get("request_body"), (dict, list)) else json.dumps(mod_req.get("request_body"), ensure_ascii=False))[:200])
    except Exception:
        pass
    try:
        from .realtime_queue import RealtimeQueue
        q = RealtimeQueue({})
        rsp = await q._send_modified_request(mod_req)
    except Exception:
        rsp = {"status": 0, "text": "", "headers": {}}
    try:
        if _logger.isEnabledFor(logging.DEBUG):
            _logger.debug("ã€å…¥å‚æµ‹è¯•ã€‘æœ¬åœ°é‡æ”¾å…¥å£ è¿”å› status=%s body.preview=%s", str(rsp.get("status")), str(rsp.get("text", ""))[:300])
    except Exception:
        pass
    return {"ok": True, "modifiedRequest": mod_req, "response": rsp}
