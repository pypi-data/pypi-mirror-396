{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EdisonScientific platform client usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldp.agent import AgentConfig\n",
    "\n",
    "from edison_client import EdisonClient, JobNames\n",
    "from edison_client.models import (\n",
    "    AuthType,\n",
    "    RuntimeConfig,\n",
    "    Stage,\n",
    "    TaskRequest,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client instantiation\n",
    "\n",
    "Here we use `auth_type=AuthType.API_KEY` to authenticate with the platform.\n",
    "Please log in to the platform and go to your user settings to get your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = EdisonClient(\n",
    "    stage=Stage.PROD,\n",
    "    auth_type=AuthType.API_KEY,\n",
    "    api_key=\"your-api-key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting jobs is done by calling the `run_tasks_until_done` method, which receives a `TaskRequest` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = TaskRequest(\n",
    "    name=JobNames.from_string(\"crow\"),\n",
    "    query=\"What is the molecule known to have the greatest solubility in water?\",\n",
    ")\n",
    "task_response = client.run_tasks_until_done(task_data)\n",
    "\n",
    "print(f\"Job status: {task_response.status}\")\n",
    "print(f\"Job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a `runtime_config` to the task, which will be used to configure the agent on runtime.\n",
    "Here, we will define a agent configuration and pass it to the task. This agent is used to decide the next action to take.\n",
    "We will also use the `max_steps` parameter to limit the number of steps the agent will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentConfig(\n",
    "    agent_type=\"SimpleAgent\",\n",
    "    agent_kwargs={\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    ")\n",
    "task_data = TaskRequest(\n",
    "    name=JobNames.LITERATURE,\n",
    "    query=\"How many moons does earth have?\",\n",
    "    runtime_config=RuntimeConfig(agent=agent, max_steps=10),\n",
    ")\n",
    "task_response = client.run_tasks_until_done(task_data)\n",
    "\n",
    "print(f\"Job status: {task_response.status}\")\n",
    "print(f\"Job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue a job\n",
    "\n",
    "The platform allows to keep asking follow-up questions to the previous job.\n",
    "To accomplish that, we can use the `runtime_config` to pass the `job_id` of the previous job.\n",
    "\n",
    "Notice that `create_job` accepts both a `JobRequest` object and a dictionary with keywords arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = TaskRequest(\n",
    "    name=JobNames.LITERATURE, query=\"How many species of birds are there?\"\n",
    ")\n",
    "\n",
    "task_response = client.run_tasks_until_done(task_data)\n",
    "\n",
    "print(f\"First job status: {task_response.status}\")\n",
    "print(f\"First job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continued_job_data = {\n",
    "    \"name\": JobNames.LITERATURE,\n",
    "    \"query\": \"From the previous answer, specifically,how many species of crows are there?\",\n",
    "    \"runtime_config\": {\"continued_job_id\": task_response.task_id},\n",
    "}\n",
    "\n",
    "continued_task_response = client.run_tasks_until_done(continued_job_data)\n",
    "\n",
    "\n",
    "print(f\"Continued job status: {continued_task_response.status}\")\n",
    "print(f\"Continued job answer: \\n{continued_task_response.formatted_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
