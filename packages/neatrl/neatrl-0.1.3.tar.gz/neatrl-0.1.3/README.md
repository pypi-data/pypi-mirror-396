# ğŸ¯ NeatRL

[![CI](https://github.com/YuvrajSingh-mist/NeatRL/actions/workflows/ci.yml/badge.svg)](https://github.com/YuvrajSingh-mist/NeatRL/actions/workflows/ci.yml)
[![PyPI version](https://badge.fury.io/py/neatrl.svg)](https://pypi.org/project/neatrl/)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**A clean, modern Python library for reinforcement learning algorithms**

NeatRL provides high-quality implementations of popular RL algorithms with a focus on simplicity, performance, and ease of use. Built with PyTorch and designed for both research and production use.

## âœ¨ Features

- ğŸš€ **Fast & Efficient**: Optimized implementations using PyTorch
- ğŸ¯ **Production Ready**: Clean APIs and comprehensive error handling
- ğŸ“Š **Experiment Tracking**: Built-in support for Weights & Biases logging
- ğŸ® **Gymnasium Compatible**: Works with all Gymnasium environments
- ğŸ”§ **Easy to Extend**: Modular design for adding new algorithms
- ğŸ“ˆ **State-of-the-Art**: Implements modern RL techniques and best practices

## ğŸ—ï¸ Supported Algorithms

### Current Implementations
- **DQN** (Deep Q-Network) - Classic value-based RL algorithm
- *More algorithms coming soon...*

## ğŸ“¦ Installation

```bash
pip install neatrl
```

## ğŸš€ Quick Start

Train a DQN agent on CartPole in 3 lines:

```python
from neatrl import train_dqn

model = train_dqn(
    env_id="CartPole-v1",
    total_timesteps=10000,
    seed=42
)
```

## ğŸ“š Documentation

ğŸ“– **[Complete Documentation](./docs/README.md)**

The docs include:
- Detailed usage examples
- Hyperparameter tuning guides
- Environment compatibility
- Experiment tracking setup
- Troubleshooting tips

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Development Setup
```bash
git clone https://github.com/YuvrajSingh-mist/NeatRL.git
cd NeatRL
pip install -e .[dev]
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Made with â¤ï¸ for the RL community**