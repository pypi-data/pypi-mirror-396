# Event Schemas

> Avro-based event schemas for TypeScript and Python services

This repository contains Apache Avro schemas for event-driven communication between services, with auto-generated TypeScript and Python types.

## ğŸ“¦ Installation

### TypeScript / JavaScript

```bash
npm install @godjigame/event-schemas
```

### Python

```bash
pip install godjigame-event-schemas
```

## ğŸš€ Usage

### TypeScript

```typescript
import { UserCreatedEvent, UserUpdatedEvent, EventMetadata } from '@godjigame/event-schemas';

// Create event metadata
const metadata: EventMetadata = {
  correlationId: '123e4567-e89b-12d3-a456-426614174000',
  causationId: '456e7890-e89b-12d3-a456-426614174001',
  traceId: '789e1234-e89b-12d3-a456-426614174002'
};

// Create user created event
const userCreatedEvent: UserCreatedEvent = {
  eventId: '550e8400-e29b-41d4-a716-446655440000',
  eventType: 'user.created',
  version: '1.0.0',
  timestamp: new Date().toISOString(),
  source: 'gamer-id',
  metadata,
  data: {
    userId: 'user123',
    email: 'user@example.com',
    username: 'johndoe',
    displayName: 'John Doe',
    createdAt: new Date().toISOString(),
    updatedAt: null
  }
};

// Use in Kafka consumer
async function handleUserCreated(event: UserCreatedEvent) {
  console.log(`User created: ${event.data.userId}`);
  // Process event...
}
```

### Python

```python
from event_types import UserCreatedEvent, UserUpdatedEvent, EventMetadata
from datetime import datetime
import uuid

# Create event metadata
metadata = EventMetadata(
    correlationId=str(uuid.uuid4()),
    causationId=str(uuid.uuid4()),
    traceId=str(uuid.uuid4())
)

# Create user created event
user_created_event = UserCreatedEvent(
    eventId=str(uuid.uuid4()),
    eventType="user.created",
    version="1.0.0",
    timestamp=datetime.utcnow().isoformat(),
    source="gamer-id",
    metadata=metadata,
    data=UserPayload(
        userId="user123",
        email="user@example.com",
        username="johndoe",
        displayName="John Doe",
        createdAt=datetime.utcnow().isoformat(),
        updatedAt=None
    )
)

# Use in Kafka producer
def publish_user_created(user_data):
    event = UserCreatedEvent(
        eventId=str(uuid.uuid4()),
        eventType="user.created",
        version="1.0.0",
        timestamp=datetime.utcnow().isoformat(),
        source="gamer-id",
        metadata=create_metadata(),
        data=user_data
    )
    # Send to Kafka...
```

## ğŸ“‹ Available Types

### Event Types

- `UserCreatedEvent` - Emitted when a new user is created
- `UserUpdatedEvent` - Emitted when a user is updated
- `UserDeletedEvent` - Emitted when a user is deleted

### Common Types

- `EventMetadata` - Common metadata for all events
- `BaseEvent` - Base event structure
- `UserPayload` - User data payload
- `DeletedUserPayload` - Payload for deleted user events

## ğŸ”§ Development

### Prerequisites

- Node.js 20+
- Python 3.8+

### Setup

```bash
# Clone the repository
git clone https://github.com/goodgameteamit/event-schemas.git
cd event-schemas

# Install dependencies
npm install

# Generate types
npm run generate
```

### Commands

```bash
# Generate TypeScript and Python types
npm run generate

# Validate schemas
npm run test:schemas

# Validate generated types
npm run test:types

# Run all tests
npm test

# Bump version
npm run version:bump
```

### Schema Development

1. **Add new schemas** in the `schemas/` directory
2. **Follow naming conventions**: Use kebab-case for file names
3. **Update dependencies**: Add new schema files to the generation script
4. **Test thoroughly**: Run validation and generation after changes

### Schema Evolution

When evolving schemas:

- âœ… **Add new optional fields** with default values
- âœ… **Add new event types**
- âœ… **Update documentation**
- âŒ **Don't remove existing fields**
- âŒ **Don't rename existing fields**
- âŒ **Don't change field types**

## ğŸ“ Repository Structure

```
event-schemas/
â”œâ”€â”€ schemas/                    # Avro schema definitions
â”‚   â”œâ”€â”€ metadata.avsc
â”‚   â”œâ”€â”€ base-event.avsc
â”‚   â””â”€â”€ user-events.avsc
â”œâ”€â”€ generated/                  # Generated types
â”‚   â”œâ”€â”€ typescript/
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ python/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ scripts/                    # Build scripts
â”‚   â”œâ”€â”€ generate-types.sh
â”‚   â””â”€â”€ validate-schemas.js
â”œâ”€â”€ .github/workflows/          # CI/CD pipeline
â”‚   â””â”€â”€ release.yml
â”œâ”€â”€ package.json               # NPM package config
â”œâ”€â”€ setup.py                   # Python package config
â””â”€â”€ pyproject.toml             # Modern Python config
```

## ğŸ”„ CI/CD Pipeline

The repository includes automated CI/CD with GitHub Actions:

- **Pull Requests**: Schema validation and type generation checks
- **Main Branch**: Automatic NPM publishing and continuous validation

### Publishing

To publish a new version:

```bash
# Bump version in package.json and pyproject.toml
npm run version:bump

# Commit and push changes
git add package.json pyproject.toml
git commit -m "Bump version to x.x.x"
git push
```

## ğŸ“– Schema Documentation

### Event Metadata

All events include common metadata for tracing and correlation:

```json
{
  "correlationId": "Unique identifier for tracking related events",
  "causationId": "Identifier of the event that caused this event",
  "traceId": "Distributed tracing identifier"
}
```

### Base Event Structure

All events extend the base event structure:

```json
{
  "eventId": "Unique identifier for this event",
  "eventType": "Type of event (e.g., user.created)",
  "version": "Schema version",
  "timestamp": "ISO 8601 timestamp",
  "source": "Service that generated the event",
  "metadata": "Event metadata object",
  "data": "Event-specific data"
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new schemas
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ”— Related Projects

- [Apache Avro](https://avro.apache.org/) - Data serialization system
- [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/) - Schema management
- [Kafka](https://kafka.apache.org/) - Event streaming platform