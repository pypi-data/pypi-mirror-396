{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-section",
   "metadata": {},
   "source": [
    "# Measure Planetary Radius from Your Own Image\n",
    "\n",
    "This notebook guides you through measuring a planet's radius from your own horizon photograph. No configuration files needed!\n",
    "\n",
    "**What you'll need:**\n",
    "- A photo showing a planetary horizon (Earth, Mars, etc.)\n",
    "- The altitude when the photo was taken (from GPS, flight data, or mission specs)\n",
    "- About 5-10 minutes\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to extract camera parameters automatically from EXIF data\n",
    "- How to validate your measurement setup\n",
    "- Three different methods for horizon detection:\n",
    "  - **Manual annotation** (interactive, most reliable)\n",
    "  - **ML segmentation** (automatic with Segment Anything Model)\n",
    "  - **Gradient-field** (automatic, physics-based)\n",
    "- How to interpret optimization results and uncertainties\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import planet_ruler.observation as pro\n",
    "from planet_ruler.camera import create_config_from_image, extract_camera_parameters\n",
    "from planet_ruler.validation import validate_limb_config\n",
    "from planet_ruler.plot import (\n",
    "    plot_3d_solution,\n",
    "    plot_gradient_field_at_limb,\n",
    "    plot_residuals,\n",
    "    plot_gradient_field_quiver,\n",
    ")\n",
    "from planet_ruler.dashboard import OutputCapture\n",
    "from planet_ruler.uncertainty import calculate_parameter_uncertainty\n",
    "from planet_ruler.fit import format_parameter_result\n",
    "\n",
    "# these are here for developers\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-1",
   "metadata": {},
   "source": [
    "## Step 1: Specify Your Image and Context\n",
    "\n",
    "Point to your image file and provide the key information we need:\n",
    "- **altitude_km**: How high was the camera when the photo was taken? (in kilometers)\n",
    "- **planet**: Which planet are you measuring? (\"earth\", \"mars\", \"jupiter\", etc.)\n",
    "\n",
    "The altitude is **critical** for accurate measurements. If you're not sure:\n",
    "- For airplane photos: typical cruising altitude is 10-12 km\n",
    "- For ISS photos: approximately 400-420 km  \n",
    "- For high-altitude balloons: 30-40 km\n",
    "- Check GPS data in your photo's EXIF metadata (we'll show this below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "user-inputs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== EDIT THESE VALUES ======\n",
    "image_path = \"path/to/your/horizon_photo.jpg\"  # Your image file\n",
    "image_path = \"../../demo/images/2013-08-05_22-42-14_Wikimania.jpg\"  # Challenging example -- use 10k altitude\n",
    "image_path = \"../../demo/images/50644513538_56228a2027_o.jpg\"  # Easy example -- use 418kk altitude\n",
    "altitude_m = 10_000  # Altitude in meters when photo was taken\n",
    "altitude_m = 418_000\n",
    "planet = \"earth\"  # Which planet: \"earth\", \"mars\", \"jupiter\", \"saturn\", etc.\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-2",
   "metadata": {},
   "source": [
    "## Step 2: Extract Camera Parameters\n",
    "\n",
    "Planet Ruler can automatically extract camera information from your image's EXIF data. This includes:\n",
    "- Focal length\n",
    "- Sensor dimensions (from camera database or calculation)\n",
    "- Image dimensions\n",
    "- GPS altitude (if available)\n",
    "\n",
    "Let's see what we can learn from your image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract camera parameters from EXIF\n",
    "camera_info = extract_camera_parameters(image_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CAMERA PARAMETER EXTRACTION\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDetected Camera: {camera_info.get('camera_model', 'Unknown')}\")\n",
    "print(f\"Camera Type: {camera_info.get('camera_type', 'unknown')}\")\n",
    "print(f\"Confidence Level: {camera_info.get('confidence', 'unknown')}\")\n",
    "print(\n",
    "    f\"\\nImage Dimensions: {camera_info['image_width_px']} x {camera_info['image_height_px']} pixels\"\n",
    ")\n",
    "\n",
    "if camera_info[\"focal_length_mm\"]:\n",
    "    print(f\"\\nFocal Length: {camera_info['focal_length_mm']:.2f} mm\")\n",
    "else:\n",
    "    print(\"\\nFocal Length: Not found in EXIF\")\n",
    "\n",
    "if camera_info[\"sensor_width_mm\"]:\n",
    "    print(f\"Sensor Width: {camera_info['sensor_width_mm']:.2f} mm\")\n",
    "    if camera_info.get(\"sensor_width_min\") and camera_info.get(\"sensor_width_max\"):\n",
    "        print(\n",
    "            f\"  Range: [{camera_info['sensor_width_min']:.2f}, {camera_info['sensor_width_max']:.2f}] mm\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Sensor Width: Using defaults\")\n",
    "\n",
    "# Check for GPS altitude\n",
    "from planet_ruler.camera import get_gps_altitude\n",
    "\n",
    "gps_altitude = get_gps_altitude(image_path)\n",
    "if gps_altitude:\n",
    "    print(f\"\\n✓ GPS Altitude Found: {gps_altitude:.1f} meters\")\n",
    "    print(\n",
    "        f\"   Consider using this instead of your specified altitude: {altitude_m} meters\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"\\nGPS Altitude: Not found - using your specified altitude of {altitude_m} meters\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-3",
   "metadata": {},
   "source": [
    "## Step 3: Generate Configuration\n",
    "\n",
    "Now we'll automatically generate a complete configuration for your measurement using the extracted camera parameters and your inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration automatically from image and your inputs\n",
    "config = create_config_from_image(\n",
    "    image_path=image_path,\n",
    "    altitude_m=altitude_m,\n",
    "    planet=planet,\n",
    "    perturbation_factor=0.5,  # Perturb initial radius guess to avoid local minima\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AUTO-GENERATED CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTarget Planet: {planet.title()}\")\n",
    "print(f\"Altitude: {altitude_m} meters\")\n",
    "print(f\"\\nCamera Configuration:\")\n",
    "print(f\"  Focal Length: {config['init_parameter_values']['f']*1000:.2f} mm\")\n",
    "if \"w\" in config[\"init_parameter_values\"]:\n",
    "    print(f\"  Sensor Width: {config['init_parameter_values']['w']*1000:.2f} mm\")\n",
    "else:\n",
    "    print(f\"  Field of View: {config['init_parameter_values']['fov']:.1f}°\")\n",
    "print(f\"\\nInitial Parameter Guess:\")\n",
    "print(\n",
    "    f\"  Radius: {config['init_parameter_values']['r']/1000:.0f} km (perturbed from truth)\"\n",
    ")\n",
    "print(f\"  Altitude: {config['init_parameter_values']['h']/1000:.1f} km\")\n",
    "print(f\"\\n✓ Configuration ready for optimization\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-4",
   "metadata": {},
   "source": [
    "## Step 4: Validate Configuration\n",
    "\n",
    "Before we start the measurement, let's validate that our configuration is internally consistent and well-formed. This checks:\n",
    "- Initial parameter values are within their specified limits\n",
    "- Orientation angle (theta) ranges are wide enough to avoid coupling issues\n",
    "- Radius limits span a reasonable range for robust optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Validate (strict=False will show warnings but not fail)\n",
    "try:\n",
    "    validate_limb_config(config, strict=True)\n",
    "    print(\"✓ Configuration validation passed!\")\n",
    "    print(\"\\nAll parameter bounds are reasonable and internally consistent.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"Configuration issue detected:\")\n",
    "    print(f\"   {e}\")\n",
    "    print(\"\\nYou may want to adjust parameters before continuing.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-5",
   "metadata": {},
   "source": [
    "## Step 5: Load Image and View It\n",
    "\n",
    "Now let's load your image into a `LimbObservation` object and take a look at what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create observation using auto-generated config\n",
    "Obs = pro.LimbObservation(\n",
    "    image_filepath=image_path, fit_config=config  # Using dict instead of file path\n",
    ")\n",
    "\n",
    "print(f\"Image loaded: {Obs.image.shape[1]} x {Obs.image.shape[0]} pixels\")\n",
    "print(f\"Free parameters: {Obs.free_parameters}\")\n",
    "print()\n",
    "\n",
    "# Display the image\n",
    "Obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "method-choice",
   "metadata": {},
   "source": [
    "## Step 6: Choose Your Detection Method\n",
    "\n",
    "Planet Ruler offers three approaches to horizon detection. Each has different trade-offs:\n",
    "\n",
    "### Method 1: Manual Annotation (Recommended for beginners)\n",
    "- **Interactive GUI**: Click points along the horizon\n",
    "- **High accuracy**: You know better than any algorithm where the true horizon is\n",
    "- **Works everywhere**: Effective even with clouds, atmospheric haze, or unusual features\n",
    "- **Quick**: Usually takes less than a minute to click 10-20 points\n",
    "- **Lightweight**: Minimal compute requirements\n",
    "\n",
    "### Method 2: Gradient-Field Optimization (Automatic, lightweight)\n",
    "- **Fully automatic**: No human input or detection needed\n",
    "- **Physics-based**: Uses brightness gradients perpendicular to the limb\n",
    "- **Multi-resolution**: Optimizes on progressively higher resolution images\n",
    "- **Lightweight**: No ML models, modest memory footprint\n",
    "- **Best for batch processing**: Efficient for processing many images\n",
    "- **Best for clean horizons**: Works well with sharp Earth/planet boundaries\n",
    "- **May struggle with**: Atmospheric layers, clouds, or complex lighting\n",
    "\n",
    "### Method 3: ML Segmentation (Automatic but heavyweight)\n",
    "- **Fully automatic**: Uses Segment Anything Model (SAM) to detect the horizon\n",
    "- **Good for clear boundaries**: Works well when planet/space boundary is distinct\n",
    "- **Heavy compute**: Requires ~2GB model download and significant GPU/CPU resources\n",
    "- **May struggle with**: Subtle horizons, atmospheric gradients, or ambiguous features\n",
    "- **Resource intensive**: Not ideal for batch processing due to model size\n",
    "\n",
    "**Recommendation:**\n",
    "- **First time?** → Try Method 1 (Manual)\n",
    "- **Processing many images?** → Try Method 2 (Gradient-Field)\n",
    "- **Have GPU and want automatic detection?** → Try Method 3 (ML Segmentation)\n",
    "\n",
    "Choose one approach below and run the corresponding cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "method-1-header",
   "metadata": {},
   "source": [
    "### Option 1: Manual Annotation\n",
    "\n",
    "**Instructions:**\n",
    "1. A window will open showing your image\n",
    "2. Click along the horizon to place points (10-20 points is usually good)\n",
    "3. Try to space them somewhat evenly across the visible horizon\n",
    "4. When done, close the window\n",
    "5. The notebook will automatically fit a smooth curve through your points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "method-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for MANUAL annotation\n",
    "detection_method = \"manual\"\n",
    "\n",
    "print(\"Opening manual annotation tool...\")\n",
    "print(\"Click points along the horizon, then close the window when done.\\n\")\n",
    "\n",
    "Obs.limb_detection = detection_method\n",
    "Obs.detect_limb()\n",
    "\n",
    "print(\"\\n✓ Horizon annotation complete!\")\n",
    "print(\n",
    "    f\"   Detected {np.count_nonzero(~np.isnan(Obs.features['limb']))} points along the horizon\"\n",
    ")\n",
    "\n",
    "# Show the detected limb\n",
    "Obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "method-2-header",
   "metadata": {},
   "source": [
    "### Option 2: Gradient-Field Optimization\n",
    "\n",
    "This method skips explicit horizon detection and instead optimizes parameters directly on the image using brightness gradients. It automatically uses multi-resolution optimization to avoid local minima.\n",
    "\n",
    "**Advantages:**\n",
    "- No model downloads needed\n",
    "- Lightweight and efficient\n",
    "- Ideal for batch processing many images\n",
    "- Works well with clean planetary horizons\n",
    "\n",
    "**Note:** If your image has complex atmospheric features or clouds near the horizon, manual annotation may work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "method-gradient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for GRADIENT-FIELD method (skip detection)\n",
    "detection_method = \"gradient-field\"\n",
    "\n",
    "Obs.limb_detection = detection_method\n",
    "print(\"Using gradient-field method - no explicit limb detection needed.\")\n",
    "print(\"The optimizer will work directly with image gradients.\")\n",
    "print()\n",
    "\n",
    "plot_gradient_field_quiver(Obs.image, step=2, image_smoothing=2.0, kernel_smoothing=8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "method-3-header",
   "metadata": {},
   "source": [
    "### Option 3: ML Segmentation (Segment Anything Model)\n",
    "\n",
    "This uses Meta's Segment Anything Model (SAM) to automatically detect the horizon. \n",
    "\n",
    "**First time setup:**\n",
    "- The model (~2GB) will be downloaded automatically on first use\n",
    "- This may take a few minutes depending on your connection\n",
    "- Subsequent uses will be faster as the model is cached\n",
    "\n",
    "**Performance notes:**\n",
    "- With GPU: Usually completes in 10-30 seconds\n",
    "- CPU only: May take 1-5 minutes per image\n",
    "- Not ideal for batch processing due to memory requirements\n",
    "\n",
    "**When it works well:**\n",
    "- Clear planet/space boundary\n",
    "- Distinct color or brightness difference at horizon\n",
    "- Uniform lighting\n",
    "\n",
    "**When it may struggle:**\n",
    "- Atmospheric haze that blurs the boundary\n",
    "- Similar colors above and below horizon\n",
    "- Complex cloud structures\n",
    "\n",
    "**Note:** For batch processing, gradient-field (Option 2) is more efficient due to lower resource requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "method-ml",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for ML SEGMENTATION\n",
    "detection_method = \"segmentation\"\n",
    "\n",
    "print(\"Starting ML segmentation...\")\n",
    "print(\"(First time: downloading ~2GB model - please be patient)\\n\")\n",
    "\n",
    "Obs.limb_detection = detection_method\n",
    "Obs.detect_limb(segmentation_method=\"sam\", interactive=True, downsample_factor=5)\n",
    "\n",
    "# Smooth the detected limb to remove jitter\n",
    "Obs.smooth_limb(method=\"rolling-median\", window_length=15)\n",
    "\n",
    "print(\"\\n✓ ML segmentation complete!\")\n",
    "print(\n",
    "    f\"   Detected {np.count_nonzero(~np.isnan(Obs.features['limb']))} points along the horizon\"\n",
    ")\n",
    "print(\n",
    "    \"   Review the detection below - if it looks wrong, try manual annotation instead.\"\n",
    ")\n",
    "\n",
    "# Show the detected limb\n",
    "Obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-7",
   "metadata": {},
   "source": [
    "## Step 7: Fit Planetary Radius\n",
    "\n",
    "Now comes the main event: optimizing all free parameters to find the best-fit planetary radius.\n",
    "\n",
    "**What's happening:**\n",
    "- The optimizer searches through parameter space (radius, altitude, camera properties, orientation)\n",
    "- It tries to match the predicted limb position to the observed horizon\n",
    "- The dashboard shows real-time progress with adaptive refresh rates\n",
    "- Multi-resolution stages help avoid getting stuck in local minima\n",
    "\n",
    "**This may take a few minutes.** Watch the dashboard to see:\n",
    "- Current parameter estimates and how they compare to the true values\n",
    "- Loss function reduction (you want this decreasing steadily)\n",
    "- Progress bars for each optimization stage\n",
    "- Helpful warnings and hints\n",
    "\n",
    "The cell below is configured differently depending on which method you chose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-limb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output capture for displaying print statements in dashboard\n",
    "capture = OutputCapture(max_lines=20, line_width=70)\n",
    "\n",
    "if detection_method in [\"manual\", \"segmentation\"]:\n",
    "    # Manual or ML segmentation: standard L1 loss on detected limb points\n",
    "    method_name = (\n",
    "        \"manual annotation\" if detection_method == \"manual\" else \"ML segmentation\"\n",
    "    )\n",
    "    print(f\"Starting optimization with {method_name}...\")\n",
    "    print()\n",
    "\n",
    "    with capture:\n",
    "        Obs.fit_limb(\n",
    "            minimizer=\"differential-evolution\",\n",
    "            max_iter=3000,\n",
    "            verbose=True,\n",
    "            dashboard=True,\n",
    "            n_jobs=6,\n",
    "            target_planet=planet,\n",
    "            dashboard_kwargs={\n",
    "                \"output_capture\": capture,\n",
    "                \"width\": 80,\n",
    "                \"max_warnings\": 5,\n",
    "                \"max_hints\": 4,\n",
    "                \"min_message_display_time\": 5.0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "elif detection_method == \"gradient-field\":\n",
    "    # Gradient-field method: direct optimization on image gradients\n",
    "    print(\"Starting gradient-field optimization...\")\n",
    "    print(\"Using multi-resolution strategy: coarse --> fine\")\n",
    "    print()\n",
    "\n",
    "    with capture:\n",
    "        Obs.fit_limb(\n",
    "            minimizer=\"differential-evolution\",\n",
    "            loss_function=\"gradient_field\",\n",
    "            resolution_stages=[8, 4],\n",
    "            image_smoothing=2.0,  # Remove high-frequency image artifacts\n",
    "            kernel_smoothing=8.0,  # Smooth gradient field for stability\n",
    "            minimizer_preset=\"scipy-default\",\n",
    "            prefer_direction=None,\n",
    "            max_iter=300,  # 3000,\n",
    "            verbose=True,\n",
    "            dashboard=True,\n",
    "            target_planet=planet,\n",
    "            dashboard_kwargs={\n",
    "                \"output_capture\": capture,\n",
    "                \"width\": 80,\n",
    "                \"max_warnings\": 5,\n",
    "                \"max_hints\": 4,\n",
    "                \"min_message_display_time\": 5.0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "print(\"\\n✓ Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-8",
   "metadata": {},
   "source": [
    "## Step 8: Visual Check of Results\n",
    "\n",
    "Let's take a look at the fitted solution. The predicted limb should closely match the actual horizon in your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visual-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image with fitted limb\n",
    "Obs.plot()\n",
    "\n",
    "print(f\"\\nBest-fit radius: {Obs.radius_km:.1f} km\")\n",
    "print(f\"Best-fit altitude: {Obs.altitude_km:.1f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24480901",
   "metadata": {},
   "source": [
    "If we fit to the limb (using any method except gradient-field), we can take a look at the fit residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35669c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if detection_method != \"gradient-field\":\n",
    "    plot_residuals(\n",
    "        Obs,\n",
    "        show_image=True,\n",
    "        show_sparse_markers=True,\n",
    "        image_alpha=0.6,\n",
    "        figsize=(13, 8),\n",
    "        band_size=30,\n",
    "    )\n",
    "else:\n",
    "    print(\"No target -- no residuals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient-field-check",
   "metadata": {},
   "source": [
    "### For Gradient-Field Method: Check Gradient Directions\n",
    "\n",
    "If you used the gradient-field method, we can visualize the brightness gradient vectors at the detected limb. \n",
    "A good fit shows:\n",
    "- Strong gradients (long arrows)\n",
    "- Perpendicular to the limb\n",
    "- All pointing the same direction (inward or outward)\n",
    "\n",
    "Run this cell only if you used gradient-field optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if using gradient-field method\n",
    "if detection_method == \"gradient-field\":\n",
    "    plot_gradient_field_quiver(\n",
    "        Obs.image, step=2, image_smoothing=2.0, kernel_smoothing=8.0\n",
    "    )\n",
    "\n",
    "    fig, ax = plot_gradient_field_at_limb(\n",
    "        y_pixels=Obs.features[\"fitted_limb\"],\n",
    "        image=Obs.image,\n",
    "        image_smoothing=2.0,\n",
    "        directional_smoothing=50,\n",
    "        directional_decay_rate=0.15,\n",
    "        sample_spacing=100,\n",
    "        kernel_smoothing=8.0,\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"\\nArrows show gradient direction and strength at sampled points.\")\n",
    "    print(\"They should be perpendicular to the limb and point the same direction.\")\n",
    "else:\n",
    "    print(\"Gradient field visualization only available for gradient-field method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-9",
   "metadata": {},
   "source": [
    "## Step 9: 3D Visualization\n",
    "\n",
    "Let's visualize the geometry in 3D to see how the camera, planet, and horizon relate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_solution(**Obs.best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-10",
   "metadata": {},
   "source": [
    "## Step 10: Calculate Uncertainties\n",
    "\n",
    "Now let's quantify our measurement uncertainty. Planet Ruler can estimate parameter uncertainties using several methods:\n",
    "\n",
    "- **Population spread** (for differential-evolution): Uses final population distribution\n",
    "- **Hessian approximation**: Fast analytical estimate from optimization curvature\n",
    "- **Auto selection**: Automatically chooses the best method for your minimizer\n",
    "\n",
    "The uncertainty reflects both measurement precision and systematic uncertainties in camera parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uncertainties",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MEASUREMENT RESULTS WITH UNCERTAINTIES\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Radius uncertainty\n",
    "radius_result = calculate_parameter_uncertainty(\n",
    "    Obs, parameter=\"r\", scale_factor=1000, method=\"auto\"  # Convert m to km\n",
    ")\n",
    "print(\"RADIUS:\")\n",
    "print(format_parameter_result(radius_result, units=\"km\"))\n",
    "print(f\"Method: {radius_result['method']}\")\n",
    "print()\n",
    "\n",
    "# Altitude uncertainty\n",
    "altitude_result = calculate_parameter_uncertainty(\n",
    "    Obs, parameter=\"h\", scale_factor=1000, method=\"auto\"  # Convert m to km\n",
    ")\n",
    "print(\"ALTITUDE:\")\n",
    "print(format_parameter_result(altitude_result, units=\"km\"))\n",
    "print(f\"Method: {altitude_result['method']}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-11",
   "metadata": {},
   "source": [
    "## Step 11: Compare to Known Values\n",
    "\n",
    "If you're measuring Earth or another planet with a well-known radius, let's see how close we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known planetary radii (km)\n",
    "TRUE_RADII = {\n",
    "    \"earth\": 6371,\n",
    "    \"mars\": 3390,\n",
    "    \"jupiter\": 69911,\n",
    "    \"saturn\": 58232,\n",
    "    \"uranus\": 25362,\n",
    "    \"neptune\": 24622,\n",
    "    \"venus\": 6052,\n",
    "    \"mercury\": 2440,\n",
    "    \"moon\": 1737,\n",
    "    \"pluto\": 1188,\n",
    "}\n",
    "\n",
    "if planet.lower() in TRUE_RADII:\n",
    "    true_radius = TRUE_RADII[planet.lower()]\n",
    "    measured_radius = radius_result[\"value\"]\n",
    "    uncertainty = radius_result[\"uncertainty\"]\n",
    "\n",
    "    error_km = measured_radius - true_radius\n",
    "    error_pct = (error_km / true_radius) * 100\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"COMPARISON TO KNOWN {planet.upper()} RADIUS\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"Your measurement:  {measured_radius:.1f} ± {uncertainty:.1f} km\")\n",
    "    print(f\"Known value:       {true_radius} km\")\n",
    "    print()\n",
    "    print(f\"Difference:        {error_km:+.1f} km ({error_pct:+.2f}%)\")\n",
    "\n",
    "    # Check if within uncertainty\n",
    "    sigma_away = abs(error_km) / uncertainty if uncertainty > 0 else float(\"inf\")\n",
    "    print(f\"Statistical:       {sigma_away:.1f}σ from true value\")\n",
    "    print()\n",
    "\n",
    "    if abs(error_pct) < 10:\n",
    "        print(\"✓ Excellent! Within 10% of the true value.\")\n",
    "    elif abs(error_pct) < 20:\n",
    "        print(\"✓ Good! Within 20% of the true value.\")\n",
    "    else:\n",
    "        print(f\"Larger than expected error. Consider:\")\n",
    "        print(\"   - Is the altitude accurate?\")\n",
    "        print(\"   - Is the horizon clearly visible?\")\n",
    "        print(\"   - Did the optimization converge? (check dashboard)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "else:\n",
    "    print(f\"No known radius for '{planet}' in database for comparison.\")\n",
    "    print(\n",
    "        f\"Your measured radius: {radius_result['value']:.1f} Â± {radius_result['uncertainty']:.1f} km\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-12",
   "metadata": {},
   "source": [
    "## Step 12: Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully measured a planetary radius from your own image.\n",
    "\n",
    "**What you accomplished:**\n",
    "- ✓ Extracted camera parameters from image metadata\n",
    "- ✓ Validated the measurement configuration\n",
    "- ✓ Detected the planetary horizon (manual, ML, or gradient-field)\n",
    "- ✓ Optimized geometric parameters to find the best-fit radius\n",
    "- ✓ Quantified measurement uncertainty\n",
    "\n",
    "**Ways to improve your measurement:**\n",
    "1. **Better altitude data**: GPS altitude from EXIF is most accurate\n",
    "2. **Try all three methods**: Compare manual, ML segmentation, and gradient-field results\n",
    "3. **Multiple images**: Average results from several photos\n",
    "4. **Longer optimization**: Increase `max_iter` for more thorough parameter search\n",
    "5. **Known camera**: If sensor dimensions are in the database, confidence is higher\n",
    "6. **Validate ML results**: If using segmentation, always inspect with `Obs.plot()` before fitting\n",
    "\n",
    "**Share your results!**\n",
    "Consider sharing your findings with the planet-ruler community or using them in educational projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-save",
   "metadata": {},
   "source": [
    "## Optional: Save Your Results\n",
    "\n",
    "You can save the detected limb and best-fit parameters for later analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and customize to save results\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# # Save detected limb\n",
    "# if detection_method == \"manual\":\n",
    "#     np.save(\"my_detected_limb.npy\", Obs.features[\"detected_limb\"])\n",
    "\n",
    "# # Save fitted limb\n",
    "# np.save(\"my_fitted_limb.npy\", Obs.features[\"fitted_limb\"])\n",
    "\n",
    "# # Save best parameters\n",
    "# with open(\"my_results.json\", \"w\") as f:\n",
    "#     json.dump({\n",
    "#         \"radius_km\": Obs.radius_km,\n",
    "#         \"radius_uncertainty_km\": radius_result['uncertainty'],\n",
    "#         \"altitude_km\": Obs.altitude_km,\n",
    "#         \"method\": detection_method,\n",
    "#         \"planet\": planet,\n",
    "#         \"best_parameters\": Obs.best_parameters\n",
    "#     }, f, indent=2)\n",
    "\n",
    "# print(\"✓ Results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-ruler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
