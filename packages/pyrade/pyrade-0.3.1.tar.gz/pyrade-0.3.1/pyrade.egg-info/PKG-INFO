Metadata-Version: 2.4
Name: pyrade
Version: 0.3.1
Summary: High-performance, modular Differential Evolution optimization
Home-page: https://github.com/arartawil/pyrade
Author: PyRADE Contributors
Author-email: PyRADE Contributors <arartawil@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/arartawil/pyrade
Project-URL: Documentation, https://github.com/arartawil/pyrade/blob/main/API_DOCUMENTATION.md
Project-URL: Repository, https://github.com/arartawil/pyrade
Project-URL: Bug Reports, https://github.com/arartawil/pyrade/issues
Keywords: optimization,differential evolution,evolutionary algorithms,metaheuristics
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.20.0
Requires-Dist: tqdm>=4.65.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.0; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.9; extra == "dev"
Requires-Dist: mypy>=0.910; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# PyRADE

**Python Rapid Algorithm for Differential Evolution**

A high-performance, modular Differential Evolution (DE) optimization package that demonstrates how clean OOP architecture can **outperform** monolithic implementations through aggressive vectorization.

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üìñ What is PyRADE?

PyRADE is a production-ready optimization library implementing **Differential Evolution (DE)**, a powerful evolutionary algorithm for global optimization. Unlike traditional implementations that sacrifice code quality for performance, PyRADE proves you can have **both** through intelligent design.

### Why Choose PyRADE?

‚úÖ **3-5x Faster** than typical DE implementations  
‚úÖ **Clean, Modular Code** that's easy to understand and extend  
‚úÖ **Battle-Tested Algorithms** with 10+ benchmark functions included  
‚úÖ **Flexible Architecture** - plug in your own strategies with ease  
‚úÖ **Production Ready** - comprehensive documentation and examples  

---

## üöÄ Key Features

- **‚ö° High Performance**: 3-5x faster than traditional implementations through aggressive NumPy vectorization
- **üèóÔ∏è Clean Architecture**: Strategy pattern for all operators - easy to understand and extend  
- **üîß Modular Design**: Plug-and-play mutation, crossover, and selection strategies
- **üì¶ Production Ready**: Well-documented, tested, professional-quality code
- **üéØ Easy to Use**: Simple, intuitive API similar to scikit-learn optimizers
- **üß™ Comprehensive**: Includes 10+ benchmark functions and multiple real-world examples
- **üî¨ Extensible**: Create custom strategies in minutes, not hours

## üìä Performance

PyRADE's vectorized implementation significantly outperforms traditional loop-based DE:

| Function | Dimension | Modular (PyRADE) | Monolithic | Speedup |
|----------|-----------|------------------|------------|---------|
| Sphere | 20 | 0.45s | 1.89s | **4.2x** |
| Rastrigin | 20 | 0.52s | 2.14s | **4.1x** |
| Rosenbrock | 20 | 0.48s | 1.95s | **4.1x** |
| Ackley | 20 | 0.51s | 2.08s | **4.1x** |

*Average speedup: **4.1x** without sacrificing code quality!*

## üì¶ Installation

### From PyPI (Recommended)
```bash
pip install pyrade
```

### From Source
```bash
# Clone the repository
git clone https://github.com/arartawil/pyrade.git
cd pyrade

# Install dependencies
pip install -r requirements.txt

# Install package
pip install -e .
```

## üéØ Quick Start

### Unified Experiment Runner

PyRADE includes `main.py` - a ready-to-use experiment runner:

```bash
python main.py
```

**Three experiment modes:**
1. **Single run** - Quick test of algorithm on function
2. **Multiple runs** - Statistical analysis with plots
3. **Algorithm comparison** - Compare multiple DE variants

Edit `main.py` to configure:
- Algorithm (10 classic variants available)
- Benchmark function (11 functions included)
- Dimensions, bounds, population size
- Visualization and saving options

### Example 1: Minimizing a Simple Function

Let's start by minimizing the classic **Sphere function**: f(x) = Œ£x¬≤

```python
import numpy as np
from pyrade import DErand1bin  # or DifferentialEvolution for legacy

# Define your objective function to minimize
def sphere(x):
    """Simple quadratic function - global minimum at origin"""
    return np.sum(x**2)

# Create the optimizer
optimizer = DErand1bin(
    objective_func=sphere,
    bounds=[(-100, 100)] * 10,  # 10-dimensional problem, each dimension in [-100, 100]
    pop_size=50,                 # Population size (recommended: 5-10x dimensions)
    max_iter=200,                # Maximum iterations
    verbose=True,                # Show progress
    seed=42                      # For reproducibility
)

# Run the optimization
result = optimizer.optimize()

# View results
print(f"Best solution found: {result['best_solution']}")
print(f"Best fitness value: {result['best_fitness']:.6e}")
print(f"Optimization time: {result['time']:.2f}s")
```

**Output:**
```
Final best fitness: 6.834298e+01
Total time: 0.050s
```

### Example 2: Using Built-in Benchmark Functions

PyRADE includes many standard test functions. Let's optimize the challenging **Rastrigin function**:

```python
from pyrade import DifferentialEvolution
from pyrade.benchmarks import Rastrigin

# Create a 20-dimensional Rastrigin function (highly multimodal!)
func = Rastrigin(dim=20)
print(f"Global optimum: {func.optimum}")
print(f"Search bounds: {func.bounds}")

# Optimize using default settings
optimizer = DifferentialEvolution(
    objective_func=func,
    bounds=func.get_bounds_array(),  # Get properly formatted bounds
    pop_size=100,
    max_iter=300,
    verbose=True
)

result = optimizer.optimize()

# Check how close we got to the global optimum
error = abs(result['best_fitness'] - func.optimum)
print(f"\nFinal fitness: {result['best_fitness']:.6e}")
print(f"Error from global optimum: {error:.6e}")
print(f"Success: {error < 1e-3}")
```

**Available Benchmark Functions:**
- `Sphere`, `Rastrigin`, `Rosenbrock`, `Ackley`, `Griewank`
- `Schwefel`, `Levy`, `Michalewicz`, `Zakharov`

### Example 3: Using Algorithm Variants

Choose from 10 pre-configured classic DE variants:

```python
from pyrade import DEbest1bin, DErand2bin, DEcurrentToBest1bin
from pyrade.benchmarks.functions import ackley

# Fast convergence with DE/best/1
optimizer1 = DEbest1bin(
    objective_func=ackley,
    bounds=[(-32.768, 32.768)] * 30,
    pop_size=100,
    max_iter=500,
    F=0.8,
    CR=0.9,
    verbose=True
)

result1 = optimizer1.optimize()
print(f"DEbest1bin fitness: {result1['best_fitness']:.6e}")

# More exploration with DE/rand/2
optimizer2 = DErand2bin(
    objective_func=ackley,
    bounds=[(-32.768, 32.768)] * 30,
    pop_size=100,
    max_iter=500,
    verbose=True
)

result2 = optimizer2.optimize()
print(f"DErand2bin fitness: {result2['best_fitness']:.6e}")
```

### Example 4: Using Custom Strategies (Advanced)

Build your own configuration with the base class:

```python
from pyrade import DifferentialEvolution
from pyrade.operators import DEbest1, ExponentialCrossover, GreedySelection
from pyrade.benchmarks.functions import ackley

# Custom configuration for specific problem
optimizer = DifferentialEvolution(
    objective_func=ackley,
    bounds=[(-32.768, 32.768)] * 30,
    mutation=DEbest1(F=0.8),                    # Exploitative mutation
    crossover=ExponentialCrossover(CR=0.9),     # Exponential crossover
    selection=GreedySelection(),                 # Greedy selection
    pop_size=100,
    max_iter=500,
    verbose=True
)

result = optimizer.optimize()
print(f"Custom config fitness: {result['best_fitness']:.6e}")
```

**Algorithm Selection Guide:**
- **DErand1bin**: General-purpose, good balance
- **DEbest1bin**: Fast convergence on unimodal functions
- **DEcurrentToBest1bin**: Aggressive exploitation
- **DErand2bin**: Better exploration for multimodal
- **DErand1exp**: Better for preserving building blocks
- **jDE**: Automatic parameter adaptation (no tuning needed!)

## üèóÔ∏è Architecture

PyRADE uses a clean, extensible architecture based on the Strategy pattern:

```
pyrade/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ algorithm.py          # Main DifferentialEvolution class
‚îÇ   ‚îî‚îÄ‚îÄ population.py          # Population management
‚îú‚îÄ‚îÄ algorithms/               # Pre-configured algorithm variants
‚îÇ   ‚îú‚îÄ‚îÄ classic/              # Classic DE variants (10 algorithms)
‚îÇ   ‚îú‚îÄ‚îÄ adaptive/             # Adaptive DE (jDE, SaDE, JADE, CoDE)
‚îÇ   ‚îú‚îÄ‚îÄ multi_population/     # Multi-population variants
‚îÇ   ‚îî‚îÄ‚îÄ hybrid/               # Hybrid algorithms
‚îú‚îÄ‚îÄ operators/
‚îÇ   ‚îú‚îÄ‚îÄ mutation.py           # Mutation strategies (10 strategies)
‚îÇ   ‚îú‚îÄ‚îÄ crossover.py          # Crossover strategies (Binomial, Exponential)
‚îÇ   ‚îî‚îÄ‚îÄ selection.py          # Selection strategies (Greedy, Tournament, etc.)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ boundary.py           # Boundary handling (Clip, Reflect, Random, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ termination.py        # Termination criteria
‚îî‚îÄ‚îÄ benchmarks/
    ‚îî‚îÄ‚îÄ functions.py          # Standard test functions
```

## üé® Available Algorithm Variants (v0.3.0)

### Classic DE Variants (10 algorithms)
- **DErand1bin**: DE/rand/1/bin - Standard random base with binomial crossover
- **DErand2bin**: DE/rand/2/bin - Two difference vectors for exploration
- **DEbest1bin**: DE/best/1/bin - Exploitative, fast convergence
- **DEbest2bin**: DE/best/2/bin - Best with two difference vectors
- **DEcurrentToBest1bin**: DE/current-to-best/1/bin - Greedy toward best
- **DEcurrentToRand1bin**: DE/current-to-rand/1/bin - Diversity maintenance
- **DERandToBest1bin**: DE/rand-to-best/1/bin - Balanced approach
- **DErand1exp**: DE/rand/1/exp - Exponential crossover variant
- **DErand1EitherOrBin**: DE/rand/1/either-or - Probabilistic F selection
- **ClassicDE**: Flexible base class for custom configurations

### Adaptive DE Variants
- **jDE**: Self-adaptive F and CR parameters (fully implemented)
- **SaDE**, **JADE**, **CoDE**: Coming in v0.4.0

### Available Mutation Strategies
- **DErand1**: Most common, good exploration
- **DErand2**: More exploratory with two difference vectors
- **DEbest1**: Exploitative, fast convergence
- **DEbest2**: Best with two difference vectors
- **DEcurrentToBest1**: Balanced exploration/exploitation
- **DEcurrentToRand1**: Diversity maintenance
- **DERandToBest1**: Combination of random and best
- **DErand1EitherOr**: Probabilistic F selection

### Crossover Strategies
- **Binomial**: Standard independent dimension crossover
- **Exponential**: Contiguous segment crossover
- **Uniform**: Equal probability crossover

### Selection Strategies
- **Greedy**: Keep better individual (standard)
- **Tournament**: Tournament-based selection
- **Elitist**: Preserve top individuals

### Boundary Handlers
- **Clip**: Clip to bounds (most common)
- **Reflect**: Reflect at boundaries
- **Random**: Replace with random value
- **Wrap**: Toroidal topology
- **Midpoint**: Use midpoint between bound and parent

## üìö Benchmark Functions

PyRADE includes 10+ standard test functions:

- **Sphere**: Simple unimodal
- **Rastrigin**: Highly multimodal
- **Rosenbrock**: Valley-shaped
- **Ackley**: Many local minima
- **Griewank**: Multimodal
- **Schwefel**: Deceptive
- **Levy**: Multimodal
- **Michalewicz**: Steep valleys
- **Zakharov**: Unimodal

### Example 4: Real-World Application - Engineering Design

Optimize a real engineering problem with constraints:

```python
import numpy as np
from pyrade import DifferentialEvolution

def pressure_vessel_cost(x):
    """
    Minimize cost of a pressure vessel design.
    x[0]: shell thickness, x[1]: head thickness
    x[2]: inner radius, x[3]: length
    """
    # Material and welding costs
    cost = (
        0.6224 * x[0] * x[2] * x[3] +
        1.7781 * x[1] * x[2]**2 +
        3.1661 * x[0]**2 * x[3] +
        19.84 * x[0]**2 * x[2]
    )
    
    # Add penalty for constraint violations
    penalty = 0
    
    # Constraint: minimum shell thickness
    if x[0] < 0.0625:
        penalty += 1000 * (0.0625 - x[0])**2
    
    # Constraint: minimum head thickness  
    if x[1] < 0.0625:
        penalty += 1000 * (0.0625 - x[1])**2
    
    # Constraint: minimum volume
    volume = (np.pi * x[2]**2 * x[3] + 
              4/3 * np.pi * x[2]**3)
    if volume < 1296000:
        penalty += 10 * (1296000 - volume)**2
    
    return cost + penalty

# Define bounds for each variable
bounds = [
    (0.0625, 99),   # shell thickness
    (0.0625, 99),   # head thickness  
    (10, 200),      # inner radius
    (10, 200)       # length
]

optimizer = DifferentialEvolution(
    objective_func=pressure_vessel_cost,
    bounds=bounds,
    pop_size=40,
    max_iter=500,
    seed=42
)

result = optimizer.optimize()
print(f"Optimal design cost: ${result['best_fitness']:.2f}")
print(f"Design parameters: {result['best_solution']}")
```

### Example 5: Using Callbacks for Progress Monitoring

Track optimization progress with custom callbacks:

```python
from pyrade import DifferentialEvolution
from pyrade.benchmarks import Rosenbrock

# Storage for tracking progress
history = {'iterations': [], 'fitness': []}

def progress_callback(iteration, best_fitness, best_solution):
    """Called after each iteration"""
    history['iterations'].append(iteration)
    history['fitness'].append(best_fitness)
    
    # Print every 50 iterations
    if iteration % 50 == 0:
        print(f"Iteration {iteration:4d}: Best fitness = {best_fitness:.6e}")

func = Rosenbrock(dim=10)

optimizer = DifferentialEvolution(
    objective_func=func,
    bounds=func.get_bounds_array(),
    pop_size=50,
    max_iter=300,
    callback=progress_callback,  # Add your callback
    verbose=False
)

result = optimizer.optimize()

# Plot convergence curve
import matplotlib.pyplot as plt
plt.plot(history['iterations'], history['fitness'])
plt.xlabel('Iteration')
plt.ylabel('Best Fitness')
plt.yscale('log')
plt.title('Convergence Curve')
plt.show()
```

---

## üî¨ Complete Examples

The `examples/` directory contains comprehensive, ready-to-run examples:

1. **`basic_usage.py`** - Simple optimization scenarios with detailed explanations
2. **`custom_strategy.py`** - Creating and using custom mutation/crossover strategies  
3. **`benchmark_comparison.py`** - Performance benchmarking against monolithic implementations

Run examples:
```bash
cd examples
python basic_usage.py
python custom_strategy.py  
python benchmark_comparison.py
```


**What you'll learn:**
- How to optimize different types of functions
- Using callbacks for monitoring
- Handling constraints with penalties
- Comparing different strategies
- Creating custom operators
- Performance optimization techniques

## üß™ Experiment Manager & Output Structure

PyRADE includes a powerful **ExperimentManager** for automated benchmarking, visualization, and data export.

### How It Works

- Selects and runs multiple benchmark functions with configurable parameters (runs, population, iterations, dimensions)
- Automatically generates and saves:
    - Convergence plots (per function and combined)
    - Fitness boxplots
    - Raw data (NumPy arrays, CSVs)
    - Summary statistics and rankings
    - Timestamped experiment folders for easy organization

### Output Folder Structure

```
experiment_YYYY-MM-DD_HH-MM-SS/
‚îú‚îÄ‚îÄ convergence_plots/
‚îÇ   ‚îú‚îÄ‚îÄ sphere_convergence.png
‚îÇ   ‚îú‚îÄ‚îÄ rastrigin_convergence.png
‚îÇ   ‚îî‚îÄ‚îÄ ... (one per function)
‚îú‚îÄ‚îÄ all_functions_convergence.png
‚îú‚îÄ‚îÄ fitness_boxplot.png
‚îú‚îÄ‚îÄ statistics.txt
‚îú‚îÄ‚îÄ csv_exports/
‚îÇ   ‚îú‚îÄ‚îÄ sphere_detailed.csv
‚îÇ   ‚îú‚îÄ‚îÄ summary_statistics.csv
‚îÇ   ‚îî‚îÄ‚îÄ ... (per function)
‚îú‚îÄ‚îÄ raw_data/
‚îÇ   ‚îú‚îÄ‚îÄ sphere_convergence.npy
‚îÇ   ‚îú‚îÄ‚îÄ sphere_final_fitness.npy
‚îÇ   ‚îî‚îÄ‚îÄ ... (per function)
‚îî‚îÄ‚îÄ config.json
```

### Example Usage

```python
from pyrade import ExperimentManager

manager = ExperimentManager(
        benchmarks=['Sphere', 'Rastrigin', 'Rosenbrock'],
        n_runs=30,
        population_size=50,
        max_iterations=100,
        dimensions=10
)
manager.run_complete_pipeline()
```

All results are saved in a new folder named with the date and time of the experiment.

## üéì Creating Custom Strategies

### Custom Mutation Strategy

```python
from pyrade.operators import MutationStrategy
import numpy as np

class MyMutation(MutationStrategy):
    def __init__(self, F=0.8):
        self.F = F
    
    def apply(self, population, fitness, best_idx, target_indices):
        pop_size = len(population)
        # Your vectorized mutation logic here
        # Must return mutants array of shape (pop_size, dim)
        mutants = ...  # Your implementation
        return mutants
```

### Custom Crossover Strategy

```python
from pyrade.operators import CrossoverStrategy
import numpy as np

class MyCrossover(CrossoverStrategy):
    def __init__(self, CR=0.9):
        self.CR = CR
    
    def apply(self, population, mutants):
        # Your vectorized crossover logic here
        # Must return trials array of shape (pop_size, dim)
        trials = ...  # Your implementation
        return trials
```

## üìà Performance Tips

1. **Use vectorized operations**: All strategies should process entire population at once
2. **Tune population size**: Typically 5-10x the problem dimension
3. **Choose appropriate F and CR**: F=0.8, CR=0.9 work well for most problems
4. **Select mutation strategy wisely**:
   - DE/rand/1: General-purpose
   - DE/best/1: Fast convergence on unimodal
   - DE/current-to-best/1: Balanced approach

## ü§ù Contributing

Contributions are welcome! Areas for contribution:
- Additional mutation/crossover strategies
- More benchmark functions
- Performance optimizations
- Documentation improvements
- Bug fixes

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- Storn & Price for the original Differential Evolution algorithm
- NumPy team for the amazing numerical computing library
- Scientific Python community

## üìû Contact

For questions, suggestions, or issues:
- Open an issue on GitHub
- Email: arartawil@gmail.com

## üåü Star History

If you find PyRADE useful, please consider starring the repository!

---

**PyRADE** - Proving that clean, modular design and high performance can coexist! üöÄ
