
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/data_management_and_configuration/plot_explore_paradigm.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_data_management_and_configuration_plot_explore_paradigm.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_data_management_and_configuration_plot_explore_paradigm.py:


=======================
Explore Paradigm Object
=======================

A paradigm defines how the raw data will be converted to trials ready
to be processed by a decoding algorithm. This is a function of the paradigm
used, i.e. in motor imagery one can have two-class, multi-class,
or continuous paradigms; similarly, different preprocessing is necessary
for ERP vs ERD paradigms.

A paradigm also defines the appropriate evaluation metric, for example AUC
for binary classification problems, accuracy for multiclass, or kappa
coefficients for continuous paradigms.

This tutorial explores the paradigm object, with 3 examples of paradigm :
     - MotorImagery
     - FilterBankMotorImagery
     - LeftRightImagery

.. GENERATED FROM PYTHON SOURCE LINES 22-36

.. code-block:: Python


    # Authors: Alexandre Barachant <alexandre.barachant@gmail.com>
    #          Sylvain Chevallier <sylvain.chevallier@uvsq.fr>
    #
    # License: BSD (3-clause)

    import numpy as np

    from moabb.datasets import BNCI2014_001
    from moabb.paradigms import FilterBankMotorImagery, LeftRightImagery, MotorImagery


    print(__doc__)


.. GENERATED FROM PYTHON SOURCE LINES 37-41

MotorImagery
-----------------

First, let's take an example of the MotorImagery paradigm.

.. GENERATED FROM PYTHON SOURCE LINES 41-46

.. code-block:: Python


    paradigm = MotorImagery(n_classes=4)

    print(paradigm.__doc__)


.. GENERATED FROM PYTHON SOURCE LINES 47-50

The function `get_data` allow you to access preprocessed data from a dataset.
this function will return 3 objects. A numpy array containing the
preprocessed EEG data, the labels, and a dataframe with metadata.

.. GENERATED FROM PYTHON SOURCE LINES 50-53

.. code-block:: Python


    print(paradigm.get_data.__doc__)


.. GENERATED FROM PYTHON SOURCE LINES 54-60

Lets take the example of the BNCI2014_001 dataset, known as the dataset IIa
from the BCI competition IV. We will load the data from the subject 1.
When calling `get_data`, the paradigm will retrieve the data from the
specified list of subjects, apply preprocessing (by default, a bandpass
between 7 and 35 Hz), epoch the data (with interval specified by the dataset,
unless superseded by the paradigm) and return the corresponding objects.

.. GENERATED FROM PYTHON SOURCE LINES 60-66

.. code-block:: Python


    dataset = BNCI2014_001()
    subjects = [1]

    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)


.. GENERATED FROM PYTHON SOURCE LINES 67-70

The epoched data is a 3D array, with epochs on the first dimension (here
576 trials), channels on the second (22 channels) and time sample on the last
one.

.. GENERATED FROM PYTHON SOURCE LINES 70-73

.. code-block:: Python


    print(X.shape)


.. GENERATED FROM PYTHON SOURCE LINES 74-76

Labels contains the labels corresponding to each trial. in the case of this
dataset, we have the 4 types of motor imagery that was performed.

.. GENERATED FROM PYTHON SOURCE LINES 76-79

.. code-block:: Python


    print(np.unique(y))


.. GENERATED FROM PYTHON SOURCE LINES 80-88

Metadata have at least 3 columns: subject, session and run.

- subject is the subject id of the corresponding trial
- session is the session id. A session denotes a recording made without
  removing the EEG cap.
- run is the individual continuous recording made during a session. A session
  may or may not contain multiple runs.


.. GENERATED FROM PYTHON SOURCE LINES 88-91

.. code-block:: Python


    print(metadata.head())


.. GENERATED FROM PYTHON SOURCE LINES 92-94

For this data, we have one subject, 2 sessions (2 different recording days)
and 6 runs per session.

.. GENERATED FROM PYTHON SOURCE LINES 94-97

.. code-block:: Python


    print(metadata.describe(include="all"))


.. GENERATED FROM PYTHON SOURCE LINES 98-100

Paradigm objects can also return the list of all dataset compatible. Here
it will return the list all the imagery datasets from the MOABB.

.. GENERATED FROM PYTHON SOURCE LINES 100-104

.. code-block:: Python


    compatible_datasets = paradigm.datasets
    print([dataset.code for dataset in compatible_datasets])


.. GENERATED FROM PYTHON SOURCE LINES 105-111

FilterBank MotorImagery
-----------------------

FilterBankMotorImagery is the same paradigm, but with a different
preprocessing. In this case, it applies a bank of 6 bandpass filter on the data
before concatenating the output.

.. GENERATED FROM PYTHON SOURCE LINES 111-116

.. code-block:: Python


    paradigm = FilterBankMotorImagery()

    print(paradigm.__doc__)


.. GENERATED FROM PYTHON SOURCE LINES 117-118

Therefore, the output X is a 4D array, with trial x channel x time x filter

.. GENERATED FROM PYTHON SOURCE LINES 118-123

.. code-block:: Python


    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)

    print(X.shape)


.. GENERATED FROM PYTHON SOURCE LINES 124-129

LeftRight MotorImagery
----------------------

LeftRightImagery is a variation over the BaseMotorImagery paradigm,
restricted to left- and right-hand events.

.. GENERATED FROM PYTHON SOURCE LINES 129-134

.. code-block:: Python


    paradigm = LeftRightImagery()

    print(paradigm.__doc__)


.. GENERATED FROM PYTHON SOURCE LINES 135-137

The compatible dataset list is a subset of motor imagery dataset that
contains at least left and right hand events.

.. GENERATED FROM PYTHON SOURCE LINES 137-141

.. code-block:: Python


    compatible_datasets = paradigm.datasets
    print([dataset.code for dataset in compatible_datasets])


.. GENERATED FROM PYTHON SOURCE LINES 142-144

So if we apply this to our original dataset, it will only return trials
corresponding to left- and right-hand motor imagination.

.. GENERATED FROM PYTHON SOURCE LINES 144-148

.. code-block:: Python


    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=subjects)

    print(np.unique(y))

**Estimated memory usage:**  0 MB


.. _sphx_glr_download_auto_examples_data_management_and_configuration_plot_explore_paradigm.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_explore_paradigm.ipynb <plot_explore_paradigm.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_explore_paradigm.py <plot_explore_paradigm.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_explore_paradigm.zip <plot_explore_paradigm.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
