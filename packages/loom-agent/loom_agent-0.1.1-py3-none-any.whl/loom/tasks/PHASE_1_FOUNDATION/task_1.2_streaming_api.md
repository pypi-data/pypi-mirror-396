# Task 1.2: é‡æ„ Agent.execute() ä¸ºæµå¼æ¥å£

**çŠ¶æ€**: â³ å¾…å¼€å§‹
**ä¼˜å…ˆçº§**: P0
**é¢„è®¡æ—¶é—´**: 1-2 å¤©
**ä¾èµ–**: Task 1.1 (AgentEvent æ¨¡å‹) âœ…

---

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

### ç›®æ ‡

å°† `Agent.execute()` æ–¹æ³•æ”¹ä¸ºè¿”å› `AsyncGenerator[AgentEvent, None]`ï¼Œå®ç°å…¨é“¾è·¯æµå¼æ¶æ„ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªä»»åŠ¡ï¼Ÿ

**å½“å‰é—®é¢˜**:
```python
# Loom 1.0 - éæµå¼
result = await agent.run(prompt)  # ç­‰å¾…å®Œæˆï¼Œæ— å®æ—¶è¿›åº¦
print(result)
```

**æœŸæœ›ç»“æœ**:
```python
# Loom 2.0 - æµå¼
async for event in agent.execute(prompt):
    if event.type == AgentEventType.LLM_DELTA:
        print(event.content, end="", flush=True)
    elif event.type == AgentEventType.TOOL_PROGRESS:
        print(f"\n[Tool] {event.metadata['status']}")
```

---

## ğŸ“ è¯¦ç»†æ­¥éª¤

### Step 1: ä¿®æ”¹ Agent æ¥å£

**æ–‡ä»¶**: `loom/components/agent.py`

**å½“å‰ä»£ç ** (ç®€åŒ–):
```python
class Agent:
    async def run(self, input: str) -> str:
        """Execute agent and return final response"""
        return await self.executor.execute(input)
```

**ä¿®æ”¹ä¸º**:
```python
class Agent:
    async def execute(self, input: str) -> AsyncGenerator[AgentEvent, None]:
        """
        Execute agent with streaming events.

        Yields:
            AgentEvent: Events representing execution progress

        Example:
            ```python
            async for event in agent.execute("Your prompt"):
                if event.type == AgentEventType.LLM_DELTA:
                    print(event.content, end="")
            ```
        """
        # åˆå§‹åŒ– turn state
        turn_state = TurnState(turn_counter=0, turn_id=str(uuid.uuid4()))

        # åˆ›å»ºåˆå§‹æ¶ˆæ¯
        messages = [Message(role="user", content=input)]

        # è°ƒç”¨ executor çš„æµå¼æ¥å£
        async for event in self.executor.execute_stream(messages, turn_state):
            yield event

    async def run(self, input: str) -> str:
        """
        Execute agent and return final response (backward compatible).

        This is a convenience method that wraps execute() and extracts
        the final response.

        Args:
            input: User input

        Returns:
            Final response text
        """
        final_content = ""

        async for event in self.execute(input):
            # Accumulate LLM deltas
            if event.type == AgentEventType.LLM_DELTA:
                final_content += event.content or ""

            # Return on finish
            elif event.type == AgentEventType.AGENT_FINISH:
                return event.content or final_content

            # Raise on error
            elif event.type == AgentEventType.ERROR:
                raise event.error

        return final_content
```

**æ–°å¢æ•°æ®ç±»**:
```python
from dataclasses import dataclass

@dataclass
class TurnState:
    """State for recursive agent execution"""
    turn_counter: int
    turn_id: str
    compacted: bool = False
    max_iterations: int = 10
```

---

### Step 2: ä¿®æ”¹ AgentExecutor æ¥å£

**æ–‡ä»¶**: `loom/core/agent_executor.py`

**å½“å‰ä»£ç ** (ç®€åŒ–):
```python
class AgentExecutor:
    async def execute(self, user_input: str) -> str:
        """Execute agent and return final response"""
        # ... å¤æ‚çš„é€»è¾‘
        return final_response
```

**ä¿®æ”¹ä¸º**:
```python
class AgentExecutor:
    async def execute_stream(
        self,
        messages: List[Message],
        turn_state: TurnState
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        Execute agent with streaming events.

        Args:
            messages: Conversation history
            turn_state: Current turn state

        Yields:
            AgentEvent: Events representing execution progress
        """

        # Phase 0: Iteration check
        yield AgentEvent(
            type=AgentEventType.ITERATION_START,
            iteration=turn_state.turn_counter,
            turn_id=turn_state.turn_id
        )

        if turn_state.turn_counter >= turn_state.max_iterations:
            yield AgentEvent(type=AgentEventType.MAX_ITERATIONS_REACHED)
            return

        # Phase 1: Context assembly
        yield AgentEvent.phase_start("context_assembly")

        system_prompt = self.system_prompt_builder.build()
        # TODO: åç»­ä»»åŠ¡ä¼šæ›¿æ¢ä¸º ContextAssembler

        yield AgentEvent.phase_end(
            "context_assembly",
            tokens_used=self._count_tokens(system_prompt)
        )

        # Phase 2: RAG retrieval (if enabled)
        if self.context_retriever:
            yield AgentEvent(type=AgentEventType.RETRIEVAL_START)

            retrieved_docs = await self.context_retriever.retrieve(
                messages[-1].content
            )

            for doc in retrieved_docs:
                yield AgentEvent(
                    type=AgentEventType.RETRIEVAL_PROGRESS,
                    metadata={
                        "doc_title": doc.metadata.get("title", "Unknown"),
                        "relevance_score": doc.metadata.get("score", 0.0)
                    }
                )

            yield AgentEvent(type=AgentEventType.RETRIEVAL_COMPLETE)

            # TODO: æ­£ç¡®æ³¨å…¥ RAG ä¸Šä¸‹æ–‡ï¼ˆTask 1.3ï¼‰

        # Phase 3: LLM call
        yield AgentEvent(type=AgentEventType.LLM_START)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯
        full_messages = [
            Message(role="system", content=system_prompt),
            *messages
        ]

        # æµå¼è°ƒç”¨ LLM
        llm_response = ""
        tool_calls = []

        async for chunk in self.llm.stream(full_messages, tools=self.tools):
            if chunk.get("type") == "text_delta":
                text = chunk["content"]
                llm_response += text
                yield AgentEvent.llm_delta(text)

            elif chunk.get("type") == "tool_calls":
                tool_calls = chunk["tool_calls"]
                yield AgentEvent(
                    type=AgentEventType.LLM_TOOL_CALLS,
                    metadata={"tool_count": len(tool_calls)}
                )

        yield AgentEvent(type=AgentEventType.LLM_COMPLETE)

        # Phase 4: Tool execution (if needed)
        if tool_calls:
            yield AgentEvent(type=AgentEventType.TOOL_CALLS_START)

            tool_results = []

            for tool_call in tool_calls:
                # TODO: åç»­ä¼šä½¿ç”¨ ToolOrchestratorï¼ˆTask 2.1ï¼‰
                # ç°åœ¨ç®€å•é¡ºåºæ‰§è¡Œ

                tool = self.tools[tool_call.name]

                yield AgentEvent(
                    type=AgentEventType.TOOL_EXECUTION_START,
                    tool_call=ToolCall(
                        id=tool_call.id,
                        name=tool_call.name,
                        arguments=tool_call.arguments
                    )
                )

                try:
                    result_content = await tool.execute(tool_call.arguments)

                    result = ToolResult(
                        tool_call_id=tool_call.id,
                        tool_name=tool_call.name,
                        content=result_content,
                        is_error=False
                    )

                    yield AgentEvent.tool_result(result)
                    tool_results.append(result)

                except Exception as e:
                    result = ToolResult(
                        tool_call_id=tool_call.id,
                        tool_name=tool_call.name,
                        content=str(e),
                        is_error=True
                    )

                    yield AgentEvent(
                        type=AgentEventType.TOOL_ERROR,
                        tool_result=result,
                        error=e
                    )
                    tool_results.append(result)

            # Phase 5: Recursion (if tools were executed)
            # åˆ›å»ºæ–°æ¶ˆæ¯åŒ…å«å·¥å…·ç»“æœ
            new_messages = [
                *messages,
                Message(role="assistant", content=llm_response, tool_calls=tool_calls),
                *[Message(role="tool", content=r.content, tool_call_id=r.tool_call_id)
                  for r in tool_results]
            ]

            # é€’å½’è°ƒç”¨
            new_turn_state = TurnState(
                turn_counter=turn_state.turn_counter + 1,
                turn_id=turn_state.turn_id
            )

            async for event in self.execute_stream(new_messages, new_turn_state):
                yield event

        else:
            # Phase 5: Finish (no tools)
            yield AgentEvent.agent_finish(llm_response)

    # ä¿ç•™å‘åå…¼å®¹æ–¹æ³•
    async def execute(self, user_input: str) -> str:
        """Legacy method - wraps execute_stream"""
        messages = [Message(role="user", content=user_input)]
        turn_state = TurnState(turn_counter=0, turn_id=str(uuid.uuid4()))

        final_response = ""
        async for event in self.execute_stream(messages, turn_state):
            if event.type == AgentEventType.AGENT_FINISH:
                return event.content or final_response
            elif event.type == AgentEventType.LLM_DELTA:
                final_response += event.content or ""

        return final_response
```

---

### Step 3: ä¿®æ”¹ LLM æ¥å£ï¼ˆå¯é€‰ï¼‰

**æ–‡ä»¶**: `loom/interfaces/llm.py`

å¦‚æœ LLM æ¥å£ä¸æ”¯æŒæµå¼å·¥å…·è°ƒç”¨ï¼Œå¯ä»¥æ·»åŠ  fallbackï¼š

```python
class BaseLLM(ABC):
    # ç°æœ‰æ–¹æ³•...

    async def stream(
        self,
        messages: List[Dict],
        tools: List[Dict] = None
    ) -> AsyncGenerator[Dict, None]:
        """
        Stream LLM response.

        Yields:
            Dict with one of:
            - {"type": "text_delta", "content": "..."}
            - {"type": "tool_calls", "tool_calls": [...]}
        """
        # Default implementation: fallback to non-streaming
        response = await self.generate_with_tools(messages, tools)

        # Yield as single chunk
        if "tool_calls" in response:
            yield {"type": "tool_calls", "tool_calls": response["tool_calls"]}
        else:
            yield {"type": "text_delta", "content": response["content"]}
```

---

## ğŸ§ª æµ‹è¯•è¦æ±‚

### å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `tests/unit/test_streaming_api.py`

æµ‹è¯•ç”¨ä¾‹ï¼š

1. âœ… `test_agent_execute_returns_generator` - éªŒè¯è¿”å›ç±»å‹
2. âœ… `test_agent_run_backward_compatible` - éªŒè¯å‘åå…¼å®¹
3. âœ… `test_llm_delta_events` - éªŒè¯ LLM æµå¼äº‹ä»¶
4. âœ… `test_tool_execution_events` - éªŒè¯å·¥å…·æ‰§è¡Œäº‹ä»¶
5. âœ… `test_iteration_events` - éªŒè¯è¿­ä»£äº‹ä»¶
6. âœ… `test_error_propagation` - éªŒè¯é”™è¯¯å¤„ç†

```python
import pytest
from loom import Agent
from loom.core.events import AgentEventType, EventCollector

@pytest.mark.asyncio
async def test_agent_execute_returns_generator():
    """Test that execute() returns AsyncGenerator"""
    agent = Agent(llm=mock_llm, tools=[])

    result = agent.execute("test")

    # Should be async generator
    assert hasattr(result, '__aiter__')

@pytest.mark.asyncio
async def test_agent_run_backward_compatible():
    """Test that run() still works"""
    agent = Agent(llm=mock_llm, tools=[])

    result = await agent.run("test")

    # Should return string
    assert isinstance(result, str)

@pytest.mark.asyncio
async def test_llm_delta_events():
    """Test LLM streaming produces delta events"""
    agent = Agent(llm=streaming_mock_llm, tools=[])
    collector = EventCollector()

    async for event in agent.execute("test"):
        collector.add(event)

    # Should have LLM_START, LLM_DELTA, LLM_COMPLETE
    assert any(e.type == AgentEventType.LLM_START for e in collector.events)
    assert any(e.type == AgentEventType.LLM_DELTA for e in collector.events)
    assert any(e.type == AgentEventType.LLM_COMPLETE for e in collector.events)

    # Reconstructed content should match
    llm_content = collector.get_llm_content()
    assert len(llm_content) > 0
```

### é›†æˆæµ‹è¯•

**æ–‡ä»¶**: `tests/integration/test_agent_streaming.py`

æµ‹è¯•çœŸå®åœºæ™¯ï¼š

1. âœ… End-to-end æµå¼æ‰§è¡Œ
2. âœ… å·¥å…·è°ƒç”¨ + é€’å½’
3. âœ… RAG é›†æˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
4. âœ… é”™è¯¯æ¢å¤

---

## âœ… éªŒæ”¶æ ‡å‡†

| æ ‡å‡† | è¦æ±‚ | æ£€æŸ¥ |
|------|------|------|
| API ä¿®æ”¹ | `execute()` è¿”å› `AsyncGenerator[AgentEvent]` | [ ] |
| å‘åå…¼å®¹ | `run()` æ–¹æ³•ä»å·¥ä½œ | [ ] |
| äº‹ä»¶äº§ç”Ÿ | äº§ç”Ÿæ‰€æœ‰å¿…éœ€äº‹ä»¶ç±»å‹ | [ ] |
| æµ‹è¯•è¦†ç›– | â‰¥ 80% è¦†ç›–ç‡ | [ ] |
| æ‰€æœ‰æµ‹è¯•é€šè¿‡ | å•å…ƒ + é›†æˆæµ‹è¯• | [ ] |
| æ–‡æ¡£æ›´æ–° | æ›´æ–° API æ–‡æ¡£å’Œç¤ºä¾‹ | [ ] |
| æ€§èƒ½ | æ— æ˜æ˜¾æ€§èƒ½ä¸‹é™ | [ ] |

---

## ğŸ“‹ å®æ–½æ£€æŸ¥æ¸…å•

### ä»£ç ä¿®æ”¹

- [ ] ä¿®æ”¹ `loom/components/agent.py`
  - [ ] æ–°å¢ `execute()` æ–¹æ³•ï¼ˆè¿”å› AsyncGeneratorï¼‰
  - [ ] ä¿®æ”¹ `run()` ä¸ºåŒ…è£…æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
  - [ ] æ·»åŠ  `TurnState` æ•°æ®ç±»

- [ ] ä¿®æ”¹ `loom/core/agent_executor.py`
  - [ ] æ–°å¢ `execute_stream()` æ–¹æ³•
  - [ ] äº§ç”Ÿæ‰€æœ‰å¿…éœ€äº‹ä»¶
  - [ ] ä¿ç•™ `execute()` å‘åå…¼å®¹

- [ ] ä¿®æ”¹ `loom/interfaces/llm.py` ï¼ˆå¯é€‰ï¼‰
  - [ ] æ·»åŠ  `stream()` æ–¹æ³•

### æµ‹è¯•

- [ ] åˆ›å»º `tests/unit/test_streaming_api.py`
  - [ ] 6+ ä¸ªå•å…ƒæµ‹è¯•
  - [ ] Mock LLM å’Œ Tools

- [ ] åˆ›å»º `tests/integration/test_agent_streaming.py`
  - [ ] End-to-end æµ‹è¯•
  - [ ] çœŸå® LLM é›†æˆï¼ˆå¯é€‰ï¼‰

- [ ] è¿è¡Œæ‰€æœ‰æµ‹è¯•
  ```bash
  pytest tests/unit/test_streaming_api.py -v
  pytest tests/integration/test_agent_streaming.py -v
  pytest tests/ -v  # ç¡®ä¿æ²¡æœ‰ç ´åç°æœ‰æµ‹è¯•
  ```

### æ–‡æ¡£

- [ ] æ›´æ–° `docs/api_reference.md`
  - [ ] è®°å½•æ–°çš„ `execute()` API
  - [ ] è®°å½•äº‹ä»¶æµæ¨¡å¼

- [ ] æ›´æ–° `README.md`
  - [ ] æ·»åŠ æµå¼ API ç¤ºä¾‹

- [ ] åˆ›å»º `examples/streaming_example.py`
  - [ ] åŸºç¡€æµå¼ç¤ºä¾‹
  - [ ] å·¥å…·æ‰§è¡Œç¤ºä¾‹
  - [ ] é”™è¯¯å¤„ç†ç¤ºä¾‹

### å®Œæˆ

- [ ] åˆ›å»º `docs/TASK_1.2_COMPLETION_SUMMARY.md`
- [ ] æ›´æ–° `LOOM_2.0_DEVELOPMENT_PLAN.md`
- [ ] æ›´æ–° `loom/tasks/README.md`
- [ ] ä»£ç å®¡æŸ¥
- [ ] åˆå¹¶åˆ°ä¸»åˆ†æ”¯

---

## ğŸ”— å‚è€ƒèµ„æº

- [Task 1.1: AgentEvent æ¨¡å‹](task_1.1_agent_events.md)
- [AgentEvent ä½¿ç”¨æŒ‡å—](../../../docs/agent_events_guide.md)
- [Claude Code æ§åˆ¶æµç¨‹](../../../ccåˆ†æ/Control%20Flow.md)

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### å…³é”®å†³ç­–

1. **é€’å½’ vs å¾ªç¯**: å½“å‰ä½¿ç”¨é€’å½’å®ç°å¤šè½®å¯¹è¯ï¼Œåç»­å¯èƒ½æ”¹ä¸ºå¾ªç¯ï¼ˆTask 3.3ï¼‰
2. **å·¥å…·æ‰§è¡Œ**: æš‚æ—¶é¡ºåºæ‰§è¡Œï¼ŒTask 2.1 ä¼šæ”¹ä¸ºæ™ºèƒ½å¹¶è¡Œ
3. **RAG æ³¨å…¥**: æš‚æ—¶ä¿ç•™åŸæœ‰é€»è¾‘ï¼ŒTask 1.3 ä¼šä¿®å¤

### æ½œåœ¨é—®é¢˜

1. **æ€§èƒ½**: æµå¼å¯èƒ½å¼•å…¥è½»å¾®å»¶è¿Ÿï¼Œéœ€è¦æ€§èƒ½æµ‹è¯•
2. **é”™è¯¯å¤„ç†**: ç¡®ä¿é”™è¯¯æ­£ç¡®ä¼ æ’­åˆ°äº‹ä»¶æµ
3. **å†…å­˜**: å¤§é‡äº‹ä»¶å¯èƒ½å ç”¨å†…å­˜ï¼Œéœ€è¦è€ƒè™‘äº‹ä»¶é™æµ

---

**åˆ›å»ºæ—¥æœŸ**: 2025-10-25
**é¢„è®¡å¼€å§‹**: 2025-10-26
**é¢„è®¡å®Œæˆ**: 2025-10-27
