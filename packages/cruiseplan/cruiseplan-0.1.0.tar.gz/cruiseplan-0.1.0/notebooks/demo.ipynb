{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Check netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1920f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "test_dir = Path('../tests_output/netcdf/all_fixtures')\n",
    "\n",
    "dir_prefix = {'cruise_mixed_ops': 'Mixed_Operations_Test_2028',\n",
    "              #'cruise_multi_leg': 'Multi_Leg_Expedition_2028',\n",
    "\n",
    "              #'cruise_simple': 'Simple_Test_Cruise_2028'\n",
    "              }\n",
    "\n",
    "print(\"Checking for NetCDF output files...\")\n",
    "print(f\"Looking in directory: {test_dir.absolute()}\")\n",
    "print(f\"Directory exists: {test_dir.exists()}\")\n",
    "print()\n",
    "\n",
    "for sd, prefix in dir_prefix.items():\n",
    "    nc_file = test_dir / sd / f'{prefix}_schedule.nc'\n",
    "    print(f\"Checking for {sd}: {nc_file}\")\n",
    "\n",
    "    if nc_file.exists():\n",
    "        try:\n",
    "            ds = xr.open_dataset(nc_file)\n",
    "            cruise_name = ds.attrs.get('cruise_name', 'Unknown Cruise')\n",
    "            print(f\"✓ Found cruise: {cruise_name}\")\n",
    "            print(f\"  Dataset shape: {ds.dims}\")\n",
    "            print(f\"  Variables: {list(ds.data_vars.keys())}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error opening {nc_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"✗ File not found: {nc_file}\")\n",
    "        print(\"  (This is expected in documentation builds - run tests to generate output files)\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"Note: NetCDF output files are generated during testing.\")\n",
    "print(\"Run 'pytest' to generate sample output files for exploration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e038dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset if it was loaded\n",
    "try:\n",
    "    ds\n",
    "except NameError:\n",
    "    print(\"No dataset loaded - run tests to generate sample NetCDF files\")\n",
    "else:\n",
    "    ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432da19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display leg assignments if dataset was loaded\n",
    "try:\n",
    "    ds.leg_assignment.values\n",
    "except NameError:\n",
    "    print(\"No dataset loaded - run tests to generate sample NetCDF files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path('../tests_output')\n",
    "\n",
    "subdir = 'pangaea'\n",
    "fname = 'pangaea_list_NAtl_pangaea_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(test_dir / subdir / fname, 'rb') as f:\n",
    "    pangaea_data = pickle.load(f)\n",
    "\n",
    "\n",
    "for i, entry in enumerate(pangaea_data):\n",
    "    lat_vec = entry['latitude']\n",
    "    lbl = entry['label']\n",
    "    print(f\"  {i+1:2d}. {lbl:<20}: {len(lat_vec):3d} stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca204e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
