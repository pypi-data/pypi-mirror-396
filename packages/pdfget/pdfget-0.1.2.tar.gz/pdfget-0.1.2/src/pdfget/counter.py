#!/usr/bin/env python3
"""PMCIDç»Ÿè®¡å™¨ - å¹¶è¡Œç»Ÿè®¡å¼€æ”¾è·å–æ–‡çŒ®æ•°é‡"""

import random
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests

from . import config
from .config import AVG_PDF_SIZE_MB, PUBMED_MAX_RESULTS
from .logger import get_logger


class PMCIDCounter:
    """PMCIDç»Ÿè®¡å™¨"""

    def __init__(self, email: str | None = None, api_key: str | None = None):
        """åˆå§‹åŒ–è®¡æ•°å™¨

        Args:
            email: NCBI APIé‚®ç®±ï¼ˆå¯é€‰ï¼‰
            api_key: NCBI APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
        """
        self.email = email
        self.api_key = api_key
        self.logger = get_logger(__name__)
        self.session = requests.Session()

        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update(config.HEADERS)

        # NCBI APIåŸºç¡€URL
        self.ncbi_base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"

    def _fetch_batch_pmcid(
        self, batch_pmids: list[str], batch_num: int, total_batches: int
    ) -> tuple[int, int]:
        """è·å–ä¸€æ‰¹PMIDsä¸­æ˜¯å¦æœ‰PMCIDçš„ç»Ÿè®¡

        Args:
            batch_pmids: PMIDsåˆ—è¡¨
            batch_num: æ‰¹æ¬¡å·
            total_batches: æ€»æ‰¹æ¬¡æ•°

        Returns:
            (æœ‰PMCIDçš„æ–‡çŒ®æ•°, æ€»æ–‡çŒ®æ•°)
        """
        fetch_url = f"{self.ncbi_base_url}efetch.fcgi"

        params = {
            "db": "pubmed",
            "id": ",".join(batch_pmids),
            "retmode": "xml",
            "rettype": "full",
        }

        if self.email:
            params["email"] = self.email
        if self.api_key:
            params["api_key"] = self.api_key

        # éšæœºå»¶è¿Ÿï¼Œé¿å…æ‰€æœ‰çº¿ç¨‹åŒæ—¶è¯·æ±‚
        time.sleep(random.uniform(0.05, 0.15))

        try:
            response = self.session.get(
                fetch_url, params=params, timeout=config.TIMEOUT
            )
            response.raise_for_status()
            xml = response.text

            # æŒ‰ PubmedArticle åˆ†å‰²
            article_pattern = r"<PubmedArticle>(.*?)</PubmedArticle>"
            articles = re.findall(article_pattern, xml, re.DOTALL)

            # ç»Ÿè®¡è¿™æ‰¹ä¸­æœ‰å¤šå°‘æ–‡ç« æœ‰PMCID
            batch_with_pmcid = sum(
                1 for article in articles if '<ArticleId IdType="pmc">' in article
            )

            self.logger.debug(
                f"æ‰¹æ¬¡ {batch_num:2d}/{total_batches} - æœ‰PMCID: {batch_with_pmcid:3d}/{len(articles):3d}"
            )

            return batch_with_pmcid, len(articles)

        except Exception as e:
            self.logger.warning(
                f"æ‰¹æ¬¡ {batch_num:2d}/{total_batches} é”™è¯¯: {str(e)[:50]}..."
            )
            return 0, len(batch_pmids)

    def _rate_limit(self) -> None:
        """PubMed APIé€Ÿç‡é™åˆ¶"""
        # å…è´¹ç”¨æˆ·ï¼š3è¯·æ±‚/ç§’
        # æœ‰APIå¯†é’¥ï¼š10è¯·æ±‚/ç§’
        if self.api_key:
            time.sleep(0.1)  # 10è¯·æ±‚/ç§’
        else:
            time.sleep(0.34)  # çº¦3è¯·æ±‚/ç§’

    def count_pmcid(self, query: str, limit: int = 5000) -> dict:
        """ç»Ÿè®¡æŸ¥è¯¢ç»“æœä¸­æœ‰PMCIDçš„æ–‡çŒ®æ•°é‡

        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: æœ€å¤§ç»“æœæ•°

        Returns:
            ç»Ÿè®¡ç»“æœå­—å…¸
        """
        self.logger.info(f"ğŸ” ç»Ÿè®¡PMCID: {query}")

        # 1. è·å–PMIDåˆ—è¡¨
        search_url = f"{self.ncbi_base_url}esearch.fcgi"
        search_params: dict[str, str | int] = {
            "db": "pubmed",
            "term": query,
            "retmode": "json",
            "retmax": min(limit, PUBMED_MAX_RESULTS),  # PubMedå•æ¬¡æœ€å¤šè¿”å›10000æ¡
        }

        if self.email:
            search_params["email"] = self.email
        if self.api_key:
            search_params["api_key"] = self.api_key

        response = self.session.get(
            search_url,
            params=search_params,
            timeout=config.TIMEOUT,  # type: ignore[arg-type]
        )
        response.raise_for_status()

        search_data = response.json()
        pmids = search_data.get("esearchresult", {}).get("idlist", [])
        total_available = int(search_data.get("esearchresult", {}).get("count", 0))

        self.logger.info(f"ğŸ“Š æ€»æ–‡çŒ®æ•°: {total_available}")
        self.logger.info(f"   è·å–çš„PMIDæ•°: {len(pmids)}")

        if not pmids:
            return {
                "query": query,
                "total": 0,
                "checked": 0,
                "with_pmcid": 0,
                "without_pmcid": 0,
                "rate": 0.0,
                "estimated_size_mb": 0,
                "elapsed_seconds": 0,
            }

        # 2. åˆ†æ‰¹å¹¶è¡Œå¤„ç†
        batch_size = config.COUNT_BATCH_SIZE
        max_workers = config.COUNT_MAX_WORKERS
        batches = [pmids[i : i + batch_size] for i in range(0, len(pmids), batch_size)]

        self.logger.info(
            f"ğŸš€ ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼Œå…± {len(batches)} æ‰¹ï¼Œæ¯æ‰¹ {batch_size} ä¸ªPMID"
        )
        self.logger.info(f"   ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†")

        start_time = time.time()
        total_with_pmcid = 0
        total_checked = 0

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_batch = {
                executor.submit(self._fetch_batch_pmcid, batch, i + 1, len(batches)): i
                + 1
                for i, batch in enumerate(batches)
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_batch):
                batch_num = future_to_batch[future]
                try:
                    batch_count, batch_articles = future.result()
                    total_with_pmcid += batch_count
                    total_checked += batch_articles
                except Exception as e:
                    self.logger.error(f"æ‰¹æ¬¡ {batch_num} å¤„ç†å¼‚å¸¸: {e}")

        elapsed = time.time() - start_time

        # 3. è®¡ç®—ç»“æœ
        rate = (total_with_pmcid / total_checked) * 100 if total_checked > 0 else 0
        avg_pdf_size = AVG_PDF_SIZE_MB  # MB
        estimated_size_mb = total_with_pmcid * avg_pdf_size

        # è¿”å›ç»Ÿè®¡ä¿¡æ¯
        return {
            "query": query,
            "total": total_available,
            "checked": total_checked,
            "with_pmcid": total_with_pmcid,
            "without_pmcid": total_checked - total_with_pmcid,
            "rate": rate,
            "estimated_size_mb": estimated_size_mb,
            "elapsed_seconds": elapsed,
            "processing_speed": total_checked / elapsed if elapsed > 0 else 0,
        }
