"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel
from enum import Enum
import pydantic
from typing import Any, Dict, List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class FunctionAggregationID(str, Enum):
    AGGREGATION = "aggregation"


class FunctionAggregationAddTypedDict(TypedDict):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""
    name: NotRequired[str]


class FunctionAggregationAdd(BaseModel):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""

    name: Optional[str] = None


class FunctionAggregationSchemaTypedDict(TypedDict):
    aggregations: List[str]
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""
    passthrough: NotRequired[bool]
    r"""Pass through the original events along with the aggregation events"""
    preserve_group_bys: NotRequired[bool]
    r"""Preserve the structure of the original aggregation event's groupby fields"""
    sufficient_stats_only: NotRequired[bool]
    r"""Output only statistics that are sufficient for the supplied aggregations"""
    metrics_mode: NotRequired[bool]
    r"""Enable to output the aggregates as metrics. When disabled, aggregates are output as events."""
    prefix: NotRequired[str]
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""
    time_window: NotRequired[str]
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""
    groupbys: NotRequired[List[str]]
    r"""Optional: One or more fields to group aggregates by. Supports wildcard expressions. Warning: Using wildcard '*' causes all fields in the event to be included, which can result in high cardinality and increased memory usage. Exclude fields that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""
    flush_event_limit: NotRequired[float]
    r"""The maximum number of events to include in any given aggregation event"""
    flush_mem_limit: NotRequired[str]
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""
    cumulative: NotRequired[bool]
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""
    search_agg_mode: NotRequired[str]
    r"""Allows Cribl Search-specific aggregation configuration"""
    add: NotRequired[List[FunctionAggregationAddTypedDict]]
    r"""Set of key-value pairs to evaluate and add/set"""
    should_treat_dots_as_literals: NotRequired[bool]
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""
    flush_on_input_close: NotRequired[bool]
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class FunctionAggregationSchema(BaseModel):
    aggregations: List[str]
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""

    passthrough: Optional[bool] = False
    r"""Pass through the original events along with the aggregation events"""

    preserve_group_bys: Annotated[
        Optional[bool], pydantic.Field(alias="preserveGroupBys")
    ] = False
    r"""Preserve the structure of the original aggregation event's groupby fields"""

    sufficient_stats_only: Annotated[
        Optional[bool], pydantic.Field(alias="sufficientStatsOnly")
    ] = False
    r"""Output only statistics that are sufficient for the supplied aggregations"""

    metrics_mode: Annotated[Optional[bool], pydantic.Field(alias="metricsMode")] = False
    r"""Enable to output the aggregates as metrics. When disabled, aggregates are output as events."""

    prefix: Optional[str] = None
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = "10s"
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""

    groupbys: Optional[List[str]] = None
    r"""Optional: One or more fields to group aggregates by. Supports wildcard expressions. Warning: Using wildcard '*' causes all fields in the event to be included, which can result in high cardinality and increased memory usage. Exclude fields that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""

    flush_event_limit: Annotated[
        Optional[float], pydantic.Field(alias="flushEventLimit")
    ] = None
    r"""The maximum number of events to include in any given aggregation event"""

    flush_mem_limit: Annotated[Optional[str], pydantic.Field(alias="flushMemLimit")] = (
        None
    )
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""

    cumulative: Optional[bool] = False
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""

    search_agg_mode: Annotated[Optional[str], pydantic.Field(alias="searchAggMode")] = (
        None
    )
    r"""Allows Cribl Search-specific aggregation configuration"""

    add: Optional[List[FunctionAggregationAdd]] = None
    r"""Set of key-value pairs to evaluate and add/set"""

    should_treat_dots_as_literals: Annotated[
        Optional[bool], pydantic.Field(alias="shouldTreatDotsAsLiterals")
    ] = False
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""

    flush_on_input_close: Annotated[
        Optional[bool], pydantic.Field(alias="flushOnInputClose")
    ] = True
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class FunctionAggregationTypedDict(TypedDict):
    filename: str
    group: str
    id: FunctionAggregationID
    load_time: float
    mod_time: float
    name: str
    uischema: Dict[str, Any]
    version: str
    async_timeout: NotRequired[float]
    cribl_version: NotRequired[str]
    disabled: NotRequired[bool]
    handle_signals: NotRequired[bool]
    sync: NotRequired[bool]
    schema_: NotRequired[FunctionAggregationSchemaTypedDict]


class FunctionAggregation(BaseModel):
    filename: Annotated[str, pydantic.Field(alias="__filename")]

    group: str

    id: FunctionAggregationID

    load_time: Annotated[float, pydantic.Field(alias="loadTime")]

    mod_time: Annotated[float, pydantic.Field(alias="modTime")]

    name: str

    uischema: Dict[str, Any]

    version: str

    async_timeout: Annotated[Optional[float], pydantic.Field(alias="asyncTimeout")] = (
        None
    )

    cribl_version: Optional[str] = None

    disabled: Optional[bool] = None

    handle_signals: Annotated[Optional[bool], pydantic.Field(alias="handleSignals")] = (
        None
    )

    sync: Optional[bool] = None

    schema_: Annotated[
        Optional[FunctionAggregationSchema], pydantic.Field(alias="schema")
    ] = None
