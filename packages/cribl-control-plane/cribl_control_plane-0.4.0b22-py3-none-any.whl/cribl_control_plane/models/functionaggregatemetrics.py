"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane import models, utils
from cribl_control_plane.types import BaseModel
from cribl_control_plane.utils import validate_open_enum
from enum import Enum
import pydantic
from pydantic import field_serializer
from pydantic.functional_validators import PlainValidator
from typing import Any, Dict, List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class FunctionAggregateMetricsID(str, Enum):
    AGGREGATE_METRICS = "aggregate_metrics"


class FunctionAggregateMetricsMetricType(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""The output metric type"""

    AUTOMATIC = "automatic"
    COUNTER = "counter"
    DISTRIBUTION = "distribution"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    TIMER = "timer"


class AggregationTypedDict(TypedDict):
    agg: str
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""
    metric_type: NotRequired[FunctionAggregateMetricsMetricType]
    r"""The output metric type"""


class Aggregation(BaseModel):
    agg: str
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""

    metric_type: Annotated[
        Annotated[
            Optional[FunctionAggregateMetricsMetricType],
            PlainValidator(validate_open_enum(False)),
        ],
        pydantic.Field(alias="metricType"),
    ] = FunctionAggregateMetricsMetricType.AUTOMATIC
    r"""The output metric type"""

    @field_serializer("metric_type")
    def serialize_metric_type(self, value):
        if isinstance(value, str):
            try:
                return models.FunctionAggregateMetricsMetricType(value)
            except ValueError:
                return value
        return value


class FunctionAggregateMetricsAddTypedDict(TypedDict):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""
    name: NotRequired[str]


class FunctionAggregateMetricsAdd(BaseModel):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""

    name: Optional[str] = None


class FunctionAggregateMetricsSchemaTypedDict(TypedDict):
    aggregations: List[AggregationTypedDict]
    r"""Combination of Aggregation function and output metric type"""
    passthrough: NotRequired[bool]
    r"""Pass through the original events along with the aggregation events"""
    preserve_group_bys: NotRequired[bool]
    r"""Preserve the structure of the original aggregation event's groupby fields"""
    sufficient_stats_only: NotRequired[bool]
    r"""Output only statistics that are sufficient for the supplied aggregations"""
    prefix: NotRequired[str]
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""
    time_window: NotRequired[str]
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""
    groupbys: NotRequired[List[str]]
    r"""Optional: One or more dimensions to group aggregates by. Supports wildcard expressions. Wrap dimension names in quotes if using literal identifiers, such as 'service.name'. Warning: Using wildcard '*' causes all dimensions in the event to be included, which can result in high cardinality and increased memory usage. Exclude dimensions that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""
    flush_event_limit: NotRequired[float]
    r"""The maximum number of events to include in any given aggregation event"""
    flush_mem_limit: NotRequired[str]
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""
    cumulative: NotRequired[bool]
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""
    should_treat_dots_as_literals: NotRequired[bool]
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""
    add: NotRequired[List[FunctionAggregateMetricsAddTypedDict]]
    r"""Set of key-value pairs to evaluate and add/set"""
    flush_on_input_close: NotRequired[bool]
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class FunctionAggregateMetricsSchema(BaseModel):
    aggregations: List[Aggregation]
    r"""Combination of Aggregation function and output metric type"""

    passthrough: Optional[bool] = False
    r"""Pass through the original events along with the aggregation events"""

    preserve_group_bys: Annotated[
        Optional[bool], pydantic.Field(alias="preserveGroupBys")
    ] = False
    r"""Preserve the structure of the original aggregation event's groupby fields"""

    sufficient_stats_only: Annotated[
        Optional[bool], pydantic.Field(alias="sufficientStatsOnly")
    ] = False
    r"""Output only statistics that are sufficient for the supplied aggregations"""

    prefix: Optional[str] = None
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = "10s"
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""

    groupbys: Optional[List[str]] = None
    r"""Optional: One or more dimensions to group aggregates by. Supports wildcard expressions. Wrap dimension names in quotes if using literal identifiers, such as 'service.name'. Warning: Using wildcard '*' causes all dimensions in the event to be included, which can result in high cardinality and increased memory usage. Exclude dimensions that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""

    flush_event_limit: Annotated[
        Optional[float], pydantic.Field(alias="flushEventLimit")
    ] = None
    r"""The maximum number of events to include in any given aggregation event"""

    flush_mem_limit: Annotated[Optional[str], pydantic.Field(alias="flushMemLimit")] = (
        None
    )
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""

    cumulative: Optional[bool] = False
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""

    should_treat_dots_as_literals: Annotated[
        Optional[bool], pydantic.Field(alias="shouldTreatDotsAsLiterals")
    ] = True
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""

    add: Optional[List[FunctionAggregateMetricsAdd]] = None
    r"""Set of key-value pairs to evaluate and add/set"""

    flush_on_input_close: Annotated[
        Optional[bool], pydantic.Field(alias="flushOnInputClose")
    ] = True
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class FunctionAggregateMetricsTypedDict(TypedDict):
    filename: str
    group: str
    id: FunctionAggregateMetricsID
    load_time: float
    mod_time: float
    name: str
    uischema: Dict[str, Any]
    version: str
    async_timeout: NotRequired[float]
    cribl_version: NotRequired[str]
    disabled: NotRequired[bool]
    handle_signals: NotRequired[bool]
    sync: NotRequired[bool]
    schema_: NotRequired[FunctionAggregateMetricsSchemaTypedDict]


class FunctionAggregateMetrics(BaseModel):
    filename: Annotated[str, pydantic.Field(alias="__filename")]

    group: str

    id: FunctionAggregateMetricsID

    load_time: Annotated[float, pydantic.Field(alias="loadTime")]

    mod_time: Annotated[float, pydantic.Field(alias="modTime")]

    name: str

    uischema: Dict[str, Any]

    version: str

    async_timeout: Annotated[Optional[float], pydantic.Field(alias="asyncTimeout")] = (
        None
    )

    cribl_version: Optional[str] = None

    disabled: Optional[bool] = None

    handle_signals: Annotated[Optional[bool], pydantic.Field(alias="handleSignals")] = (
        None
    )

    sync: Optional[bool] = None

    schema_: Annotated[
        Optional[FunctionAggregateMetricsSchema], pydantic.Field(alias="schema")
    ] = None
