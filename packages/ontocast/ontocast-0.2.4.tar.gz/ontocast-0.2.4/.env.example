# ===========================================
# OntoCast Environment Configuration
# Copy this file to .env and update with your values
# ===========================================

# Domain Configuration
# Used for URI generation in the knowledge graph
CURRENT_DOMAIN=https://example.com

# Server Configuration
PORT=8999
RECURSION_LIMIT=1000
ESTIMATED_CHUNKS=30
MAX_VISITS=3

# LLM Configuration
# Choose your LLM provider and configure accordingly

# OpenAI Configuration (Default)
# Available providers: openai, ollama
LLM_PROVIDER=openai
# Available OpenAI models: gpt-4o, gpt-4o-mini etc
LLM_MODEL_NAME=gpt-4o-mini
LLM_TEMPERATURE=0.0
LLM_API_KEY=your_openai_api_key_here

# Ollama Configuration (Alternative)
# LLM_PROVIDER=ollama
# Available Ollama models: qwen2.5, qwen2.5:72b, llama3.1, llama3.1:70b
# LLM_MODEL_NAME=llama3.1
# LLM_BASE_URL=http://localhost:11434
# LLM_TEMPERATURE=0.0

# Chunking Configuration
 CHUNK_BREAKPOINT_THRESHOLD_TYPE=percentile
 CHUNK_BREAKPOINT_THRESHOLD_AMOUNT=95.0
 CHUNK_BUFFER_SIZE=5
 CHUNK_MIN_SIZE=2000
 CHUNK_MAX_SIZE=20000

# Triple Store Configuration
# Fuseki is preferred over Neo4j when both are configured
# If no triple store is configured, OntoCast will use filesystem storage

# Fuseki Configuration (Recommended)
FUSEKI_URI=http://localhost:3030/test
FUSEKI_AUTH=admin/admin
FUSEKI_DATASET=dataset_name
# FUSEKI_ONTOLOGIES_DATASET=ontologies  # Defaults to "ontologies" from constants

# Neo4j Configuration (Alternative)
NEO4J_URI=bolt://localhost:7687
NEO4J_AUTH=neo4j/test
NEO4J_PORT=7476
NEO4J_BOLT_PORT=7689

# Path Configuration
ONTOCAST_WORKING_DIRECTORY=/path/to/working/directory
ONTOCAST_ONTOLOGY_DIRECTORY=/path/to/ontology/files
ONTOCAST_CACHE_DIR=/path/to/cache/directory

# Additional Configuration
# Set to true to clean triple store on startup
CLEAN=false
# Set to true to skip ontology critique
SKIP_ONTOLOGY_DEVELOPMENT=false
# Maximum number of triples allowed in ontology graph (set to empty for unlimited)
ONTOLOGY_MAX_TRIPLES=10000
# Set logging level (debug, info, warning, error)
LOGGING_LEVEL=info