# Cache Analysis: Final Architecture

**Date:** 2025-11-23
**Status:** ‚úÖ **COMPLETE**

---

## üéØ Overview

Cache analysis uses **temporary source modification** to test `@lru_cache` decorators. This document describes the final architecture after addressing:
1. Subprocess visibility issues
2. Parallel sub-server conflicts
3. Write access requirements
4. Concurrent modification detection

---

## üîß Core Approach: Source Modification

### Why Source Modification?

**Monkey-patching doesn't work with subprocesses:**

```python
# ‚ùå BROKEN: Monkey-patching
setattr(module, "func", cached_func)  # Modifies parent's memory
subprocess.run(["pytest"])             # Subprocess imports from DISK!
# ‚îî‚îÄ> Cache never used!

# ‚úÖ WORKING: Source modification
file_path.write_text(modified_source)  # Writes to DISK
subprocess.run(["pytest"])              # Subprocess sees modification!
# ‚îî‚îÄ> Cache active!
```

**Key insight:** `subprocess.run()` creates fresh Python interpreter that imports from **disk**, not parent's memory.

---

## üèóÔ∏è Architecture Components

### 1. SourcePatcher - File Modification Utility

**Location:** `src/glintefy/subservers/review/cache/source_patcher.py`

**Responsibilities:**
- Backup source files (`.cache_backup`)
- Add `@lru_cache` decorators via AST parsing
- Detect concurrent modifications (SHA256 hashing)
- Restore original files

**API:**
```python
patcher = SourcePatcher()

# Check write access
has_access, error = SourcePatcher.check_write_access(repo_path)

# Apply decorator
success = patcher.apply_cache_decorator(
    file_path=Path("src/my_module.py"),
    function_name="expensive_function",
    cache_size=128,
)

# Check for concurrent modifications
files_modified, modified_list = patcher.check_concurrent_modifications()

# Restore originals
patcher.restore_all()
```

### 2. BatchScreener - Batch Hit Rate Testing

**Applies ALL caches at once, single test run:**

```python
# Apply caches to ALL candidates
for candidate in candidates:
    patcher.apply_cache_decorator(...)

# Run tests ONCE
subprocess.run(["pytest", "tests/"])

# Check concurrent modifications
if patcher.check_concurrent_modifications():
    abort()

# Collect cache stats
for candidate in candidates:
    module = importlib.import_module(candidate.module_path)
    importlib.reload(module)  # Force reload from disk
    cache_info = module.func.cache_info()
```

### 3. IndividualValidator - Precise Speedup Measurement

**Tests each candidate individually:**

```python
for candidate in survivors:
    # Baseline (no cache)
    baseline_time = run_tests_without_cache()

    # With cache
    patcher.apply_cache_decorator(...)
    cached_time = run_tests_with_cache()
    patcher.restore_all()

    speedup = (baseline_time - cached_time) / baseline_time * 100
```

---

## üîí Safety Mechanisms

### 1. Write Access Check

**Before modifying any files:**

```python
has_access, error = SourcePatcher.check_write_access(repo_path)
if not has_access:
    return error_result(f"Cannot modify source files: {error}")
```

**Handles:**
- Read-only mounts
- Permission denied errors
- File system errors

### 2. Concurrent Modification Detection

**Tracks file hashes to detect changes:**

```python
# After modifying file:
self.file_hashes[file_path] = hashlib.sha256(file_path.read_bytes()).hexdigest()

# Before collecting stats:
current_hash = hashlib.sha256(file_path.read_bytes()).hexdigest()
if current_hash != expected_hash:
    abort("File modified concurrently!")
```

**Protects against:**
- User editing files during analysis
- Other MCP tools modifying files
- LLM making concurrent changes

### 3. Sequential Execution

**Cache runs AFTER parallel sub-servers:**

```python
def run_all(self):
    # Step 1: Scope (sequential)
    run_scope()

    # Step 2: Quality, security, deps, docs, perf (PARALLEL)
    with ThreadPoolExecutor() as executor:
        executor.submit(run_quality)
        executor.submit(run_security)
        ...

    # Step 3: Cache (SEQUENTIAL, after parallel completes)
    run_cache()  # ‚Üê No conflicts with other sub-servers

    # Step 4: Report (sequential)
    run_report()
```

**Why sequential:**
- Git branches are process-wide (threads share same branch)
- File modifications affect all threads
- Prevents interference with other sub-servers

---

## üìä Execution Flow

### Batch Screening Flow

```
1. Check write access
   ‚îî‚îÄ> FAIL: Abort with error message

2. Apply ALL cache decorators to source files
   ‚îú‚îÄ> Backup original files (.cache_backup)
   ‚îú‚îÄ> Parse AST to verify function exists
   ‚îú‚îÄ> Add "from functools import lru_cache"
   ‚îú‚îÄ> Add "@lru_cache(maxsize=128)" decorator
   ‚îî‚îÄ> Track file hash (concurrent detection)

3. Run test suite ONCE
   ‚îî‚îÄ> subprocess.run(["pytest", "tests/"])

4. Check concurrent modifications
   ‚îî‚îÄ> MODIFIED: Abort (files changed during tests)

5. Import modified modules and collect stats
   ‚îú‚îÄ> importlib.reload(module)  # Get version from disk
   ‚îî‚îÄ> cache_info = module.func.cache_info()

6. Restore original files (always)
   ‚îú‚îÄ> Copy backups over modified files
   ‚îî‚îÄ> Delete .cache_backup files
```

### Individual Validation Flow

```
For each survivor from batch screening:

1. Measure baseline (no cache)
   ‚îî‚îÄ> Run tests 3 times, average timing

2. Measure with cache
   ‚îú‚îÄ> Apply decorator to source file
   ‚îú‚îÄ> Run tests 3 times
   ‚îú‚îÄ> Check concurrent modifications
   ‚îú‚îÄ> Import module, get cache_info()
   ‚îî‚îÄ> Restore original

3. Calculate speedup
   ‚îî‚îÄ> (baseline - cached) / baseline * 100%

4. Make recommendation
   ‚îú‚îÄ> APPLY: hit_rate >= 20%, speedup >= 5%
   ‚îî‚îÄ> REJECT: below thresholds
```

---

## ‚ö†Ô∏è Limitations

### 1. Requires Write Access

**Cache analysis cannot run on:**
- Read-only file systems
- Files without write permissions
- Protected directories

**Detection:**
- Checks write access before starting
- Returns clear error message if blocked

### 2. Not Safe for Parallel Execution

**Cache cannot run concurrently with:**
- Other sub-servers (quality, security, docs)
- Other MCP tools (Edit, Write)
- User file edits

**Mitigation:**
- Runs sequentially after parallel sub-servers
- Detects concurrent modifications
- Aborts if files changed during analysis

### 3. Temporary File System State

**During execution:**
- Source files are modified on disk
- Git status shows modified files
- Imports see decorated versions

**Duration:** ~1-5 minutes (depends on test suite size)

**Cleanup:** Always restored in `finally` blocks

---

## üîç Edge Cases Handled

### Case 1: User Edits File During Analysis

```
T0: Cache analysis starts
T1: Modifies utils.py, adds @lru_cache
T2: Runs tests (60 seconds)
T3: User edits utils.py concurrently  ‚Üê DETECTED!
T4: Hash check fails
T5: Aborts, restores backup
```

**Result:** Cache analysis fails gracefully, no corruption

### Case 2: LLM Makes Concurrent Changes

```
Request 1: review_cache (running)
Request 2: edit_file utils.py (concurrent)

Cache analysis detects hash mismatch
‚îî‚îÄ> Aborts before corrupting edits
```

### Case 3: Read-Only Mount

```
$ mount | grep /repo
/dev/sda1 on /repo (ro)

Cache analysis checks write access
‚îî‚îÄ> Fails with clear error: "No write permission to repository"
```

### Case 4: Git Dirty State

**Not a problem!** Cache uses simple backup/restore, not git.

- Works with uncommitted changes
- Works without git
- No git state pollution

---

## üìà Performance

### Overhead from Source Modification

**Batch Screening:**
```
Without source mod: N/A (monkey-patching doesn't work)
With source mod:    Single test run + file I/O
File I/O overhead:  ~10-50ms per file
Total overhead:     Negligible (<1% of test time)
```

**Individual Validation:**
```
Per candidate: 2 test runs (baseline + cached)
File I/O:      ~50ms backup + modify + restore
Test runtime:  10-60 seconds typical
Overhead:      <0.5% of total time
```

**Conclusion:** Source modification overhead is negligible compared to test execution time.

---

## ‚úÖ Final Implementation Status

| Component | Status | LOC | Description |
|-----------|--------|-----|-------------|
| **SourcePatcher** | ‚úÖ Complete | 310 | Backup/modify/restore utility |
| **BatchScreener** | ‚úÖ Complete | 170 | Batch hit rate testing |
| **IndividualValidator** | ‚úÖ Complete | 200 | Precise speedup measurement |
| **Write Access Check** | ‚úÖ Complete | 15 | Permission validation |
| **Concurrent Mod Detection** | ‚úÖ Complete | 30 | Hash-based change detection |
| **Sequential Execution** | ‚úÖ Complete | 15 | run_all() integration |

**Total:** ~740 LOC for safe, reliable cache analysis

---

## üéì Key Lessons Learned

### Lesson 1: User Questions Reveal Hidden Assumptions

**Questions that changed the implementation:**
1. "but the other tests are running already in separate subprocesses?" ‚Üí Revealed monkey-patching doesn't work
2. "can we do all of that just on a different branch?" ‚Üí Led to git approach (later simplified)
3. "in that case - do we even need the branching?" ‚Üí Simplified to backup/restore
4. "can this copy approach work when running as mcp server?" ‚Üí Added write access check
5. "can the calling llm change files in the meantime?" ‚Üí Added concurrent modification detection

**Each question uncovered a critical flaw or edge case!**

### Lesson 2: Subprocess Isolation is Two-Way

- ‚úÖ Protects parent from subprocess contamination
- ‚ùå Prevents subprocess from seeing parent's changes
- üí° Need disk-based modifications, not memory-based

### Lesson 3: Sequential > Branching (for This Use Case)

**Git branching seemed clever but:**
- Threads share same working directory
- Branch switching affects all threads
- Adds complexity for no benefit

**Simple backup/restore wins:**
- Works with sequential execution
- No git dependency
- Easier to understand
- Same safety guarantees

---

## üìù User Warnings

### In MCP Tool Description

```
review_cache: Identify caching opportunities

WARNING: Do not modify source files while cache analysis is running.
This process temporarily modifies source files for testing. Any
concurrent edits will cause the analysis to abort.

Requires: Write access to repository
Duration: 1-5 minutes (depends on test suite)
```

### In Error Messages

```
"Cache analysis aborted: Files were modified concurrently during testing"
"Cache analysis failed: No write permission to repository"
"Cache analysis requires test suite to pass (current status: FAILED)"
```

---

## üöÄ Future Enhancements

### Optional: In-Memory Filesystem

Use tmpfs or similar for even faster backup/restore:

```python
import tempfile
with tempfile.TemporaryDirectory() as tmpdir:
    # Copy files to tmpfs
    # Modify in tmpfs
    # Run tests
    # Restore from tmpfs
```

**Benefit:** Faster I/O, no disk writes
**Trade-off:** More complexity

### Optional: Fine-Grained Locking

Implement file-level locking for parallel-safe execution:

```python
with FileLock(file_path):
    modify_file()
    run_tests()
    restore_file()
```

**Benefit:** Could run in parallel
**Trade-off:** Requires other MCP tools to also use locks

---

## ‚úÖ Conclusion

Cache analysis is **production-ready** with:
- ‚úÖ Reliable source modification approach
- ‚úÖ Subprocess visibility guaranteed
- ‚úÖ Sequential execution (no conflicts)
- ‚úÖ Write access validation
- ‚úÖ Concurrent modification detection
- ‚úÖ Clear error messages
- ‚úÖ Automatic cleanup

**All user questions have been addressed!**
