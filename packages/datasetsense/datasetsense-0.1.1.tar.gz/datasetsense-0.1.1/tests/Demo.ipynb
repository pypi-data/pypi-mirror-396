{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLm8KqJ9wX7YzN2hF3vRtK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LexusMaximus/Automated-EDA-Narrator-Data-Quality-Scoring-Tool/blob/main/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header-title"
      },
      "source": [
        "# DatasetSense: Automated EDA Narrator + Data Quality Scoring Tool\n",
        "\n",
        "This notebook demonstrates the DatasetSense tool with various quality scoring weight configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## Setup: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in current Colab environment\n",
        "!ls\n",
        "\n",
        "# Remove old repo folder (replace with your repo name)\n",
        "!rm -rf Automated-EDA-Narrator-Data-Quality-Scoring-Tool"
      ],
      "metadata": {
        "id": "sGcfNT4icCSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LexusMaximus/Automated-EDA-Narrator-Data-Quality-Scoring-Tool.git"
      ],
      "metadata": {
        "id": "BkdGRidycDvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Automated-EDA-Narrator-Data-Quality-Scoring-Tool\")\n",
        "!ls"
      ],
      "metadata": {
        "id": "27DsmOAvcFTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example1-header"
      },
      "source": [
        "## Example 1: Default Weights\n",
        "\n",
        "Run the pipeline with default quality scoring weights:\n",
        "- Missing: 35%\n",
        "- Duplicates: 15%\n",
        "- Outliers: 25%\n",
        "- Balance: 25%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import importlib\n",
        "sys.path.insert(0, '/content/Automated-EDA-Narrator-Data-Quality-Scoring-Tool/src')\n",
        "\n",
        "# Import the module first, then reload it to ensure latest changes are picked up\n",
        "import orchestrator\n",
        "importlib.reload(orchestrator)\n",
        "from orchestrator import DatasetPipeline\n",
        "\n",
        "# Initialize pipeline with default weights\n",
        "pipeline = DatasetPipeline(\"data/sample.csv\")\n",
        "\n",
        "# Run pipeline and print report\n",
        "report = pipeline.run()\n",
        "print(report)"
      ],
      "metadata": {
        "id": "V25uDNvIcWgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example2-header"
      },
      "source": [
        "## Example 2: Custom Weights - Prioritize Missing Values\n",
        "\n",
        "Use custom weights that prioritize missing value detection:\n",
        "- Missing: 50% (high priority)\n",
        "- Duplicates: 10%\n",
        "- Outliers: 20%\n",
        "- Balance: 20%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom weights focusing on missing values\n",
        "custom_weights_missing = {\n",
        "    'missing': 0.50,\n",
        "    'duplicates': 0.10,\n",
        "    'outliers': 0.20,\n",
        "    'balance': 0.20\n",
        "}\n",
        "\n",
        "pipeline_custom = DatasetPipeline(\"data/sample.csv\", custom_weights=custom_weights_missing)\n",
        "report_custom = pipeline_custom.run()\n",
        "print(report_custom)"
      ],
      "metadata": {
        "id": "custom-weights-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example3-header"
      },
      "source": [
        "## Example 3: Custom Weights - Prioritize Outliers and Duplicates\n",
        "\n",
        "Use custom weights that prioritize outlier and duplicate detection:\n",
        "- Missing: 20%\n",
        "- Duplicates: 30% (high priority)\n",
        "- Outliers: 40% (high priority)\n",
        "- Balance: 10%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom weights focusing on outliers and duplicates\n",
        "custom_weights_outliers = {\n",
        "    'missing': 0.20,\n",
        "    'duplicates': 0.30,\n",
        "    'outliers': 0.40,\n",
        "    'balance': 0.10\n",
        "}\n",
        "\n",
        "pipeline_outliers = DatasetPipeline(\"data/sample.csv\", custom_weights=custom_weights_outliers)\n",
        "report_outliers = pipeline_outliers.run()\n",
        "print(report_outliers)"
      ],
      "metadata": {
        "id": "custom-weights-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example4-header"
      },
      "source": [
        "## Example 4: Equal Weights for All Metrics\n",
        "\n",
        "Treat all quality metrics equally:\n",
        "- Missing: 25%\n",
        "- Duplicates: 25%\n",
        "- Outliers: 25%\n",
        "- Balance: 25%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal weights for all metrics\n",
        "equal_weights = {\n",
        "    'missing': 0.25,\n",
        "    'duplicates': 0.25,\n",
        "    'outliers': 0.25,\n",
        "    'balance': 0.25\n",
        "}\n",
        "\n",
        "pipeline_equal = DatasetPipeline(\"data/sample.csv\", custom_weights=equal_weights)\n",
        "report_equal = pipeline_equal.run()\n",
        "print(report_equal)"
      ],
      "metadata": {
        "id": "custom-weights-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison-header"
      },
      "source": [
        "## Example 5: Compare Overall Scores Across Different Weights\n",
        "\n",
        "Run multiple configurations and compare the overall quality scores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define different weight configurations\n",
        "weight_configs = {\n",
        "    'Default': {'missing': 0.35, 'duplicates': 0.15, 'outliers': 0.25, 'balance': 0.25},\n",
        "    'Missing Focus': {'missing': 0.50, 'duplicates': 0.10, 'outliers': 0.20, 'balance': 0.20},\n",
        "    'Outlier Focus': {'missing': 0.20, 'duplicates': 0.30, 'outliers': 0.40, 'balance': 0.10},\n",
        "    'Equal Weights': {'missing': 0.25, 'duplicates': 0.25, 'outliers': 0.25, 'balance': 0.25},\n",
        "    'Balance Focus': {'missing': 0.20, 'duplicates': 0.20, 'outliers': 0.20, 'balance': 0.40}\n",
        "}\n",
        "\n",
        "# Run pipeline with each configuration\n",
        "results = []\n",
        "for name, weights in weight_configs.items():\n",
        "    pipeline = DatasetPipeline(\"data/sample.csv\", custom_weights=weights)\n",
        "    pipeline.run()\n",
        "    results.append({\n",
        "        'Configuration': name,\n",
        "        'Overall Score': round(pipeline.scores['overall'], 2),\n",
        "        'Missing Weight': weights['missing'],\n",
        "        'Duplicates Weight': weights['duplicates'],\n",
        "        'Outliers Weight': weights['outliers'],\n",
        "        'Balance Weight': weights['balance']\n",
        "    })\n",
        "\n",
        "# Display comparison table\n",
        "comparison_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON OF DIFFERENT WEIGHT CONFIGURATIONS\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "comparison-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "error-handling-header"
      },
      "source": [
        "## Example 6: Error Handling - Invalid Weights\n",
        "\n",
        "Demonstrate the validation that prevents invalid weight configurations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing error handling for invalid weights...\\n\")\n",
        "\n",
        "# Test 1: Weights don't sum to 1.0\n",
        "print(\"Test 1: Weights sum > 1.0\")\n",
        "try:\n",
        "    invalid_weights = {\n",
        "        'missing': 0.50,\n",
        "        'duplicates': 0.30,\n",
        "        'outliers': 0.30,\n",
        "        'balance': 0.10\n",
        "    }\n",
        "    pipeline = DatasetPipeline(\"data/sample.csv\", custom_weights=invalid_weights)\n",
        "    pipeline.run()\n",
        "except ValueError as e:\n",
        "    print(f\"✓ Error correctly caught: {e}\\n\")\n",
        "\n",
        "# Test 2: Missing required keys\n",
        "print(\"Test 2: Missing required keys\")\n",
        "try:\n",
        "    incomplete_weights = {\n",
        "        'missing': 0.50,\n",
        "        'duplicates': 0.50\n",
        "    }\n",
        "    pipeline = DatasetPipeline(\"data/sample.csv\", custom_weights=incomplete_weights)\n",
        "    pipeline.run()\n",
        "except ValueError as e:\n",
        "    print(f\"✓ Error correctly caught: {e}\\n\")\n",
        "\n",
        "# Test 3: Negative weights\n",
        "print(\"Test 3: Negative weights\")\n",
        "try:\n",
        "    negative_weights = {\n",
        "        'missing': 0.50,\n",
        "        'duplicates': -0.10,\n",
        "        'outliers': 0.40,\n",
        "        'balance': 0.20\n",
        "    }\n",
        "    pipeline = DatasetPipeline(\"data/sample.csv\", custom_weights=negative_weights)\n",
        "    pipeline.run()\n",
        "except ValueError as e:\n",
        "    print(f\"✓ Error correctly caught: {e}\\n\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"All error handling tests passed! ✓\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "error-handling-code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary-header"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Default weights**: Standard balanced approach\n",
        "2. **Custom weights**: Flexibility to prioritize specific metrics\n",
        "3. **Multiple configurations**: Comparing different weight strategies\n",
        "4. **Error handling**: Validation prevents invalid configurations\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- Weights must sum to **1.0** (100%)\n",
        "- All four metrics must be specified: `missing`, `duplicates`, `outliers`, `balance`\n",
        "- All weights must be **non-negative**\n",
        "- Different weights can significantly impact the overall quality score\n",
        "- Choose weights based on your data quality priorities\n",
        "\n",
        "### OOP Concepts Demonstrated:\n",
        "\n",
        "- **Encapsulation**: Weights are validated internally\n",
        "- **Default parameters**: Optional custom weights with sensible defaults\n",
        "- **Composition**: Pipeline orchestrates multiple classes\n",
        "- **Error handling**: Proper validation with meaningful error messages"
      ]
    }
  ]
}
