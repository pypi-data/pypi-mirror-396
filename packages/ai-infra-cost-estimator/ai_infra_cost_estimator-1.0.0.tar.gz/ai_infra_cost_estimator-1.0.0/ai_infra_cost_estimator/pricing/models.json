{
  "models": {
    "gpt-4o": {
      "provider": "openai",
      "input_per_1k": 0.0025,
      "output_per_1k": 0.01,
      "context_window": 128000,
      "description": "GPT-4o - OpenAI's flagship model"
    },
    "gpt-4o-mini": {
      "provider": "openai",
      "input_per_1k": 0.00015,
      "output_per_1k": 0.0006,
      "context_window": 128000,
      "description": "GPT-4o Mini - Cost-effective option"
    },
    "gpt-4-turbo": {
      "provider": "openai",
      "input_per_1k": 0.01,
      "output_per_1k": 0.03,
      "context_window": 128000,
      "description": "GPT-4 Turbo - High performance"
    },
    "gpt-3.5-turbo": {
      "provider": "openai",
      "input_per_1k": 0.0005,
      "output_per_1k": 0.0015,
      "context_window": 16385,
      "description": "GPT-3.5 Turbo - Fast and economical"
    },
    "claude-3-5-sonnet": {
      "provider": "anthropic",
      "input_per_1k": 0.003,
      "output_per_1k": 0.015,
      "context_window": 200000,
      "description": "Claude 3.5 Sonnet - Balanced performance"
    },
    "claude-3-opus": {
      "provider": "anthropic",
      "input_per_1k": 0.015,
      "output_per_1k": 0.075,
      "context_window": 200000,
      "description": "Claude 3 Opus - Most capable Claude model"
    },
    "claude-3-haiku": {
      "provider": "anthropic",
      "input_per_1k": 0.00025,
      "output_per_1k": 0.00125,
      "context_window": 200000,
      "description": "Claude 3 Haiku - Fastest and most compact"
    },
    "gemini-1.5-pro": {
      "provider": "google",
      "input_per_1k": 0.00125,
      "output_per_1k": 0.005,
      "context_window": 2000000,
      "description": "Gemini 1.5 Pro - Long context support"
    },
    "gemini-1.5-flash": {
      "provider": "google",
      "input_per_1k": 0.000075,
      "output_per_1k": 0.0003,
      "context_window": 1000000,
      "description": "Gemini 1.5 Flash - Fast and efficient"
    },
    "llama-3.1-70b": {
      "provider": "meta",
      "input_per_1k": 0.00079,
      "output_per_1k": 0.00079,
      "context_window": 131072,
      "description": "Llama 3.1 70B - Open source large model"
    },
    "llama-3.1-8b": {
      "provider": "meta",
      "input_per_1k": 0.00018,
      "output_per_1k": 0.00018,
      "context_window": 131072,
      "description": "Llama 3.1 8B - Efficient open source"
    },
    "mistral-large": {
      "provider": "mistral",
      "input_per_1k": 0.002,
      "output_per_1k": 0.006,
      "context_window": 128000,
      "description": "Mistral Large - Enterprise grade"
    },
    "mistral-small": {
      "provider": "mistral",
      "input_per_1k": 0.0002,
      "output_per_1k": 0.0006,
      "context_window": 32000,
      "description": "Mistral Small - Cost effective"
    }
  },
  "infra": {
    "compute": {
      "small": {
        "vcpu": 2,
        "memory_gb": 4,
        "cost_per_hour_usd": 0.05,
        "max_concurrent_requests": 20,
        "description": "Small instance - Light workloads"
      },
      "medium": {
        "vcpu": 4,
        "memory_gb": 8,
        "cost_per_hour_usd": 0.10,
        "max_concurrent_requests": 50,
        "description": "Medium instance - Standard workloads"
      },
      "large": {
        "vcpu": 8,
        "memory_gb": 16,
        "cost_per_hour_usd": 0.20,
        "max_concurrent_requests": 100,
        "description": "Large instance - Heavy workloads"
      },
      "xlarge": {
        "vcpu": 16,
        "memory_gb": 32,
        "cost_per_hour_usd": 0.40,
        "max_concurrent_requests": 200,
        "description": "XLarge instance - Enterprise workloads"
      },
      "gpu_t4": {
        "vcpu": 4,
        "memory_gb": 16,
        "gpu": "NVIDIA T4",
        "cost_per_hour_usd": 0.50,
        "max_concurrent_requests": 30,
        "description": "GPU T4 - ML inference"
      },
      "gpu_a100": {
        "vcpu": 12,
        "memory_gb": 85,
        "gpu": "NVIDIA A100",
        "cost_per_hour_usd": 3.00,
        "max_concurrent_requests": 80,
        "description": "GPU A100 - High-performance inference"
      }
    },
    "regions": {
      "us-east-1": {
        "name": "US East (N. Virginia)",
        "multiplier": 1.0
      },
      "us-west-2": {
        "name": "US West (Oregon)",
        "multiplier": 1.0
      },
      "eu-west-1": {
        "name": "Europe (Ireland)",
        "multiplier": 1.1
      },
      "eu-central-1": {
        "name": "Europe (Frankfurt)",
        "multiplier": 1.15
      },
      "ap-south-1": {
        "name": "Asia Pacific (Mumbai)",
        "multiplier": 0.9
      },
      "ap-southeast-1": {
        "name": "Asia Pacific (Singapore)",
        "multiplier": 1.05
      },
      "ap-northeast-1": {
        "name": "Asia Pacific (Tokyo)",
        "multiplier": 1.2
      }
    },
    "defaults": {
      "avg_latency_ms": 500,
      "overhead_multiplier": 1.2,
      "min_replicas": 1,
      "max_replicas": 100
    }
  },
  "metadata": {
    "version": "1.0.0",
    "last_updated": "2024-12-14",
    "currency": "USD",
    "notes": "Prices are estimates and may vary. Check provider documentation for exact pricing."
  }
}
