# chuk-llm Provider Configuration
# ===============================
# Minimal configuration for provider definitions.
# Model lists come from the registry cache.

openai:
  client_class: "chuk_llm.llm.providers.openai_client:OpenAILLMClient"
  api_key_env: "OPENAI_API_KEY"
  api_base: "https://api.openai.com/v1"
  default_model: "gpt-4o-mini"
  models: ["*"]  # Models loaded from registry

anthropic:
  client_class: "chuk_llm.llm.providers.anthropic_client:AnthropicLLMClient"
  api_key_env: "ANTHROPIC_API_KEY"
  api_base: "https://api.anthropic.com"
  default_model: "claude-sonnet-4-5"
  models: ["*"]

gemini:
  client_class: "chuk_llm.llm.providers.gemini_client:GeminiLLMClient"
  api_key_env: "GEMINI_API_KEY"
  api_base: "https://generativelanguage.googleapis.com/v1"
  default_model: "gemini-2.5-flash"
  models: ["*"]

groq:
  client_class: "chuk_llm.llm.providers.groq_client:GroqAILLMClient"
  api_key_env: "GROQ_API_KEY"
  api_base: "https://api.groq.com/openai/v1"
  default_model: "llama-3.3-70b-versatile"
  models: ["*"]

mistral:
  client_class: "chuk_llm.llm.providers.mistral_client:MistralLLMClient"
  api_key_env: "MISTRAL_API_KEY"
  default_model: "mistral-large-latest"
  models: ["*"]

deepseek:
  client_class: "chuk_llm.llm.providers.openai_client:OpenAILLMClient"
  api_key_env: "DEEPSEEK_API_KEY"
  api_base: "https://api.deepseek.com/v1"
  default_model: "deepseek-chat"
  models: ["*"]

moonshot:
  client_class: "chuk_llm.llm.providers.openai_client:OpenAILLMClient"
  api_key_env: "MOONSHOT_API_KEY"
  api_base: "https://api.moonshot.ai/v1"
  default_model: "kimi-k2-turbo-preview"
  models: ["*"]

ollama:
  client_class: "chuk_llm.llm.providers.ollama_client:OllamaLLMClient"
  api_base: "http://localhost:11434"
  default_model: "llama3.2"
  models: ["*"]

llamacpp:
  client_class: "chuk_llm.llm.providers.llamacpp_client:LlamaCppLLMClient"
  api_base: "http://localhost:8080"
  default_model: "llama-3.1-8b-instruct"
  models: ["*"]

watsonx:
  client_class: "chuk_llm.llm.providers.watsonx_client:WatsonXLLMClient"
  api_key_env: "WATSONX_API_KEY"
  default_model: "ibm/granite-3-3-8b-instruct"
  models: ["*"]

azure_openai:
  client_class: "chuk_llm.llm.providers.azure_openai_client:AzureOpenAILLMClient"
  api_key_env: "AZURE_OPENAI_API_KEY"
  models: ["*"]

perplexity:
  client_class: "chuk_llm.llm.providers.perplexity_client:PerplexityLLMClient"
  api_key_env: "PERPLEXITY_API_KEY"
  api_base: "https://api.perplexity.ai"
  default_model: "llama-3.1-sonar-small-128k-online"
  models: ["*"]

openai_compatible:
  client_class: "chuk_llm.llm.providers.openai_client:OpenAILLMClient"
  api_key_env: "OPENAI_API_KEY"
  models: ["*"]

advantage:
  client_class: "chuk_llm.llm.providers.advantage_client:AdvantageLLMClient"
  api_key_env: "ADVANTAGE_API_KEY"
  api_base_env: "ADVANTAGE_API_BASE"
  default_model: "global/gpt-5-chat"
  models: ["*"]

openrouter:
  client_class: "chuk_llm.llm.providers.openrouter_client:OpenRouterLLMClient"
  api_key_env: "OPENROUTER_API_KEY"
  api_base: "https://openrouter.ai/api/v1"
  default_model: "anthropic/claude-3.5-sonnet"
  models: ["*"]
