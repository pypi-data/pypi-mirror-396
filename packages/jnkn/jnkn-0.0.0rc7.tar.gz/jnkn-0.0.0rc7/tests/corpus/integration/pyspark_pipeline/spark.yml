job_name: user_metrics_pipeline
schedule: "0 6 * * *"
entry_point: etl_job.py

dependencies:
  - raw_data_ingestion

environment:
  DATABASE_HOST: ${PROD_DB_HOST}
  S3_BUCKET: ${DATA_LAKE_BUCKET}

inputs:
  - warehouse.dim_users
  
outputs:
  - warehouse.daily_metrics
