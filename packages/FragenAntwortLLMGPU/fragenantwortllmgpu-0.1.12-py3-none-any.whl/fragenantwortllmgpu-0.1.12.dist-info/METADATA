Metadata-Version: 2.4
Name: FragenAntwortLLMGPU
Version: 0.1.12
Summary: A package for processing documents and generating questions and answers using LLMs on GPU and CPU.
Author: Mehrdad Almasi, Demival Vasques, and Lars Wieneke
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: PyMuPDF
Requires-Dist: tokenizers
Requires-Dist: semantic-text-splitter==0.13.3
Requires-Dist: langchain
Requires-Dist: langchain_community
Requires-Dist: torchvision
Requires-Dist: torchaudio
Requires-Dist: ctransformers
Requires-Dist: transformers>=4.37.0
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary


# FragenAntwortLLMGPU (Generating efficient Question and Answer Pairs for LLM Fine-Tuning with FragenAntwortLLMGPU)
[![Downloads](https://static.pepy.tech/badge/FragenAntwortLLMGPU)](https://pepy.tech/project/FragenAntwortLLMGPU)

Incorporating question and answer pairs is crucial for creating accurate, context-aware, and user-friendly Large Language Models. 
FragenAntwortLLMGPU is a Python package designed for processing PDF documents and generating efficient Q&A pairs using large language models (LLMs) on CPU and GPU. 
This package can be used to fine-tune an LLM. 
It leverages various NLP libraries and local/hosted LLM backends (e.g., Mistral and Qwen) (https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF) to achieve this.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Contributing](#contributing)
- [License](#license)
- [Authors](#authors)
- [Contact](#contact)

## Installation

To install the required dependencies, follow these steps:


### For Linux Users

1. **Install the required version of `torch` manually**:

    ```bash
    pip install torch==2.0.0+cu118 -f https://download.pytorch.org/whl/cu118/torch_stable.html
    ```

2. **Then, install the package using pip**:

    ```bash
    pip install FragenAntwortLLMGPU
    ```

## Usage
Here's an example of how to use the Document Processor:

```python
from FragenAntwortLLMGPU import DocumentProcessor

processor = DocumentProcessor(
    book_path="/path/to/your/book/",  # Directory path without "NAME_OF_BOOK.pdf" term
    temp_folder="/path/to/temp/folder",
    output_file="/path/to/output/QA.jsonl",
    book_name="example.pdf",
    start_page=9,
    end_page=77,
	gpu_layers=100, 
    number_Q_A="five",  # This should be a written number like "one", "two", etc.
    target_information="foods and locations", 
    max_new_tokens=1000,
    temperature=0.1,
    context_length=2100,
    max_tokens_chunk=800,
    arbitrary_prompt=""
)

processor.process_book()
processor.generate_prompts()
processor.save_to_jsonl()
```

**Model selection**

- Default (GGUF via CTransformers): `model="mistral"`
- Qwen (Hugging Face Transformers): `model="qwen"`

Example:

```python
processor = DocumentProcessor(
    ... ,
    model="qwen",
    # optionally override the HF model id
    hf_model_id="Qwen/Qwen2.5-7B-Instruct",
)
```


### Features

- Extracts text from PDF documents
- Splits text into manageable chunks for processing
- Generates efficient question and answer pairs based on specific target information
- Supports custom prompts for question generation
- **Runs on CPU and GPU**: The code can be executed on CPU and GPU.
- **Uses Mistral Model (https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)**: Utilizes the CTransformers version of the Mistral v1 model.
- **Multilingual Input**: Accepts PDF books in French, German, or English and generates Q&A pairs in English.

### Contributing

Contributions are welcome! Please fork this repository and submit pull requests.

### License

This project is licensed under the MIT License. See the LICENSE file for details.

### Authors

- Mehrdad Almasi, Lars Wieneke, and Demival VASQUES FILHO
